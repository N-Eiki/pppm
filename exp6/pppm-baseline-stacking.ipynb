{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024515,
     "end_time": "2022-03-22T09:40:01.460332",
     "exception": false,
     "start_time": "2022-03-22T09:40:01.435817",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Directory settings\n",
    "funnel-transformer-largeを追加\n",
    "\n",
    "https://www.kaggle.com/competitions/us-patent-phrase-to-phrase-matching/discussion/327288"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T16:03:18.971545Z",
     "iopub.status.busy": "2022-06-07T16:03:18.970763Z",
     "iopub.status.idle": "2022-06-07T16:03:19.004296Z",
     "shell.execute_reply": "2022-06-07T16:03:19.003249Z",
     "shell.execute_reply.started": "2022-06-07T16:03:18.971418Z"
    },
    "id": "fa3b873b",
    "papermill": {
     "duration": 0.041313,
     "end_time": "2022-03-22T09:40:01.526545",
     "exception": false,
     "start_time": "2022-03-22T09:40:01.485232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Directory settings\n",
    "# ====================================================\n",
    "import os\n",
    "\n",
    "INPUT_DIR = '../input/us-patent-phrase-to-phrase-matching/'\n",
    "OUTPUT_DIR = './'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1d0c4430",
    "papermill": {
     "duration": 0.024609,
     "end_time": "2022-03-22T09:40:01.576366",
     "exception": false,
     "start_time": "2022-03-22T09:40:01.551757",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T16:03:19.006760Z",
     "iopub.status.busy": "2022-06-07T16:03:19.006302Z",
     "iopub.status.idle": "2022-06-07T16:03:19.022540Z",
     "shell.execute_reply": "2022-06-07T16:03:19.021679Z",
     "shell.execute_reply.started": "2022-06-07T16:03:19.006724Z"
    },
    "id": "48dd82bb",
    "papermill": {
     "duration": 0.033949,
     "end_time": "2022-03-22T09:40:01.634977",
     "exception": false,
     "start_time": "2022-03-22T09:40:01.601028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# CFG\n",
    "# ====================================================\n",
    "class CFG_exp016:\n",
    "    num_workers=4\n",
    "    path=\"../input/pppm-baseline-016/\"\n",
    "    config_path=path+'config.pth'\n",
    "    model=\"microsoft/deberta-v3-large\"\n",
    "    batch_size=32\n",
    "    fc_dropout=0.2\n",
    "    target_size=1\n",
    "    max_len=133\n",
    "    seed=42\n",
    "    n_fold=5\n",
    "    trn_fold=[0, 1, 2, 3, 4]\n",
    "\n",
    "class CFG_exp026:\n",
    "    num_workers=4\n",
    "    path=\"../input/pppm-baseline-026/\"\n",
    "    config_path=path+'config.pth'\n",
    "    model=\"microsoft/deberta-v3-large\"\n",
    "    batch_size=32\n",
    "    fc_dropout=0.2\n",
    "    target_size=1\n",
    "    max_len=134\n",
    "    seed=42\n",
    "    n_fold=5\n",
    "    trn_fold=[0, 1, 2, 3, 4]\n",
    "    \n",
    "class CFG_exp020:\n",
    "    num_workers=4\n",
    "    path=\"../input/pppm-baseline-020/\"\n",
    "    config_path=path+'config.pth'\n",
    "    model=\"roberta-large\"\n",
    "    batch_size=32\n",
    "    fc_dropout=0.2\n",
    "    target_size=1\n",
    "    max_len=175\n",
    "    seed=42\n",
    "    n_fold=5\n",
    "    trn_fold=[0, 1, 2, 3, 4]\n",
    "\n",
    "    \n",
    "class CFG_exp011:\n",
    "    num_workers=4\n",
    "    path=\"../input/pppm-baseline-011/\"\n",
    "    config_path=path+'config.pth'\n",
    "    model=\"microsoft/deberta-v3-base\"\n",
    "    batch_size=32\n",
    "    fc_dropout=0.2\n",
    "    target_size=1\n",
    "    max_len=133\n",
    "    seed=42\n",
    "    n_fold=5\n",
    "    trn_fold=[0, 1, 2, 3, 4]\n",
    "\n",
    "class CFG_exp018:\n",
    "    num_workers=4\n",
    "    path=\"../input/pppm-baseline-018/\"\n",
    "    config_path=path+'config.pth'\n",
    "    model=\"anferico/bert-for-patents\"\n",
    "    batch_size=32\n",
    "    fc_dropout=0.2\n",
    "    target_size=1\n",
    "    max_len=117\n",
    "    seed=42\n",
    "    n_fold=5\n",
    "    trn_fold=[0, 1, 2, 3, 4]\n",
    "    \n",
    "\n",
    "class CFG_exp032:\n",
    "    num_workers=4\n",
    "    path=\"../input/pppm-baseline-032/\"\n",
    "    config_path=path+'config.pth'\n",
    "    model=\"funnel-transformer/large\"\n",
    "    batch_size=32\n",
    "    fc_dropout=0.2\n",
    "    target_size=1\n",
    "    max_len=125\n",
    "    seed=42\n",
    "    n_fold=5\n",
    "    trn_fold=[0, 1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2ed8ef2",
    "papermill": {
     "duration": 0.038261,
     "end_time": "2022-03-22T09:40:10.626926",
     "exception": false,
     "start_time": "2022-03-22T09:40:10.588665",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T16:03:19.024563Z",
     "iopub.status.busy": "2022-06-07T16:03:19.024263Z",
     "iopub.status.idle": "2022-06-07T16:04:08.804336Z",
     "shell.execute_reply": "2022-06-07T16:04:08.803124Z",
     "shell.execute_reply.started": "2022-06-07T16:03:19.024533Z"
    },
    "executionInfo": {
     "elapsed": 20123,
     "status": "ok",
     "timestamp": 1644920080956,
     "user": {
      "displayName": "Yasufumi Nakama",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17486303986134302670"
     },
     "user_tz": -540
    },
    "id": "35916341",
    "outputId": "06fa0ab8-a380-4f54-a98d-b7015b79d9e2",
    "papermill": {
     "duration": 26.143536,
     "end_time": "2022-03-22T09:40:36.798853",
     "exception": false,
     "start_time": "2022-03-22T09:40:10.655317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "import ast\n",
    "import sys\n",
    "import copy\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import shutil\n",
    "import string\n",
    "import pickle\n",
    "import random\n",
    "import joblib\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "import torch\n",
    "print(f\"torch.__version__: {torch.__version__}\")\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "os.system('pip uninstall -y transformers')\n",
    "os.system('pip uninstall -y tokenizers')\n",
    "os.system('pip uninstall -y pytorch-tabnet')\n",
    "\n",
    "os.system('python -m pip install --no-index --find-links=../input/pppm-pip-wheels-dataset transformers')\n",
    "os.system('python -m pip install --no-index --find-links=../input/pppm-pip-wheels-dataset tokenizers')\n",
    "os.system('python -m pip install --no-index --find-links=../input/pytorchtabnet/pytorch-tabnet  pytorch-tabnet')\n",
    "\n",
    "import tokenizers\n",
    "import transformers\n",
    "print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n",
    "print(f\"transformers.__version__: {transformers.__version__}\")\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "%env TOKENIZERS_PARALLELISM=true\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fd586614",
    "papermill": {
     "duration": 0.032888,
     "end_time": "2022-03-22T09:40:36.865209",
     "exception": false,
     "start_time": "2022-03-22T09:40:36.832321",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T16:04:08.806587Z",
     "iopub.status.busy": "2022-06-07T16:04:08.806339Z",
     "iopub.status.idle": "2022-06-07T16:04:08.822223Z",
     "shell.execute_reply": "2022-06-07T16:04:08.821002Z",
     "shell.execute_reply.started": "2022-06-07T16:04:08.806556Z"
    },
    "id": "d5c0ccc6",
    "papermill": {
     "duration": 0.21551,
     "end_time": "2022-03-22T09:40:37.116848",
     "exception": false,
     "start_time": "2022-03-22T09:40:36.901338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Utils\n",
    "# ====================================================\n",
    "def get_score(y_true, y_pred):\n",
    "    score = sp.stats.pearsonr(y_true, y_pred)[0]\n",
    "    return score\n",
    "\n",
    "\n",
    "def get_logger(filename=OUTPUT_DIR+'train'):\n",
    "    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=f\"{filename}.log\")\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = get_logger()\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T16:04:08.824706Z",
     "iopub.status.busy": "2022-06-07T16:04:08.823945Z",
     "iopub.status.idle": "2022-06-07T16:04:10.095514Z",
     "shell.execute_reply": "2022-06-07T16:04:10.094011Z",
     "shell.execute_reply.started": "2022-06-07T16:04:08.824658Z"
    }
   },
   "outputs": [],
   "source": [
    "## 別ver\n",
    "# https://www.kaggle.com/code/jellyz9/tips-for-ensambling\n",
    "from sklearn.preprocessing import MinMaxScaler #Scaler\n",
    "from sklearn.linear_model import LinearRegression #重回帰分析\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "\n",
    "use_models =[\n",
    "    \"../input/pppm-baseline-026\",\n",
    "    \"../input/pppm-baseline-020\",\n",
    "    \"../input/pppm-baseline-018\",\n",
    "    \"../input/pppm-baseline-011\",\n",
    "    \"../input/pppm-baseline-032\"\n",
    "]\n",
    "\n",
    "train_df = pd.read_csv(\"../input/us-patent-phrase-to-phrase-matching/train.csv\")\n",
    "ens_df = train_df[[\"id\", \"score\"]]\n",
    "\n",
    "for model in use_models:\n",
    "  _df = pd.read_pickle(os.path.join(model, \"preds\", \"oof_df.pkl\"))\n",
    "  if len(_df) > len(ens_df):\n",
    "    print(model)\n",
    "    _df = _df[_df[\"flag\"]==1]\n",
    "    df = _df[[\"id\", \"pred\"]]\n",
    "    \n",
    "    MMscaler = MinMaxScaler()\n",
    "    df[\"pred\"] = MMscaler.fit_transform(df[\"pred\"].values.reshape(-1,1)).reshape(-1)\n",
    "\n",
    "    df.rename(columns={\"pred\":model.split(\"/\")[-1]},inplace=True)\n",
    "    ens_df = pd.merge(ens_df, df, on=\"id\", how=\"left\")\n",
    "\n",
    "  else:\n",
    "    df = _df[[\"id\", \"pred\"]]\n",
    "\n",
    "    MMscaler = MinMaxScaler()\n",
    "    df[\"pred\"] = MMscaler.fit_transform(df[\"pred\"].values.reshape(-1,1)).reshape(-1)\n",
    "\n",
    "    df.rename(columns={\"pred\":model.split(\"/\")[-1]},inplace=True)\n",
    "    ens_df = pd.merge(ens_df, df, on=\"id\", how=\"left\")\n",
    "\n",
    "ens_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T16:04:10.098238Z",
     "iopub.status.busy": "2022-06-07T16:04:10.097235Z",
     "iopub.status.idle": "2022-06-07T16:04:10.859222Z",
     "shell.execute_reply": "2022-06-07T16:04:10.858117Z",
     "shell.execute_reply.started": "2022-06-07T16:04:10.098176Z"
    }
   },
   "outputs": [],
   "source": [
    "# アンサンブル\n",
    "\n",
    "Y = ens_df[\"score\"]\n",
    "X = ens_df.drop([\"score\",\"id\"], axis=1)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "colormap = plt.cm.RdBu\n",
    "sns.heatmap(ens_df.drop(\"id\",axis=1).astype(float).corr(),linewidths=0.1,vmax=1.0, \n",
    "            square=True, cmap=colormap, linecolor='white', annot=True)\n",
    "\n",
    "# mdoel\n",
    "models = []\n",
    "ens_scores = []\n",
    "va_idxes = []\n",
    "preds = []\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for i, (tr_idx, val_idx) in enumerate(list(kf.split(X, Y))):\n",
    "    tr_x, tr_y = X.values[tr_idx], Y.values[tr_idx]\n",
    "    val_x, val_y = X.values[val_idx], Y.values[val_idx]\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(tr_x, tr_y)\n",
    "    pred = model.predict(val_x)\n",
    "    score = get_score(pred, val_y)\n",
    "    \n",
    "    \n",
    "    models.append(model)\n",
    "    ens_scores.append(score)\n",
    "    va_idxes.append(val_idx)\n",
    "    preds.append(pred)\n",
    "\n",
    "va_idxes = np.concatenate(va_idxes)\n",
    "order = np.argsort(va_idxes)\n",
    "preds = np.concatenate(preds, axis=0)\n",
    "preds = preds[order]\n",
    "\n",
    "final_score = get_score(Y, preds)\n",
    "print(final_score)\n",
    "LOGGER.info(f'CV Score: {final_score:<.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stacking oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T16:04:10.862790Z",
     "iopub.status.busy": "2022-06-07T16:04:10.861405Z",
     "iopub.status.idle": "2022-06-07T16:04:13.237433Z",
     "shell.execute_reply": "2022-06-07T16:04:13.236096Z",
     "shell.execute_reply.started": "2022-06-07T16:04:10.862730Z"
    }
   },
   "outputs": [],
   "source": [
    "stacking_dir = \"../input/5model-linear-stacking/5model_kfsky_linear\"\n",
    "dirs = os.listdir(stacking_dir)\n",
    "ens_df = []\n",
    "\n",
    "for dir in dirs:\n",
    "    path = os.path.join(stacking_dir, dir, \"oof_df.csv\")\n",
    "    print(path)\n",
    "    df = pd.read_csv(path)\n",
    "    ens_df.append(df[\"score\"].values)\n",
    "    \n",
    "ens_df = pd.DataFrame(ens_df).T\n",
    "ens_df[[\"id\", \"score\"]] =  train_df[[\"id\", \"score\"]]\n",
    "print(ens_df.shape)\n",
    "ens_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T16:04:13.238772Z",
     "iopub.status.busy": "2022-06-07T16:04:13.238536Z",
     "iopub.status.idle": "2022-06-07T16:04:13.337311Z",
     "shell.execute_reply": "2022-06-07T16:04:13.335738Z",
     "shell.execute_reply.started": "2022-06-07T16:04:13.238744Z"
    }
   },
   "outputs": [],
   "source": [
    "# アンサンブル\n",
    "\n",
    "# Y = ens_df[\"score\"]\n",
    "X = ens_df.drop([\"score\",\"id\"], axis=1)\n",
    "\n",
    "# plt.figure(figsize=(8,8))\n",
    "# colormap = plt.cm.RdBu\n",
    "# sns.heatmap(ens_df.drop(\"id\",axis=1).astype(float).corr(),linewidths=0.1,vmax=1.0, \n",
    "#             square=True, cmap=colormap, linecolor='white', annot=True)\n",
    "\n",
    "# mdoel\n",
    "models = []\n",
    "ens_scores = []\n",
    "va_idxes = []\n",
    "preds = []\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for i, (tr_idx, val_idx) in enumerate(list(kf.split(X, Y))):\n",
    "    tr_x, tr_y = X.values[tr_idx], Y.values[tr_idx]\n",
    "    val_x, val_y = X.values[val_idx], Y.values[val_idx]\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(tr_x, tr_y)\n",
    "    pred = model.predict(val_x)\n",
    "    score = get_score(pred, val_y)\n",
    "    \n",
    "    \n",
    "    models.append(model)\n",
    "    ens_scores.append(score)\n",
    "    va_idxes.append(val_idx)\n",
    "    preds.append(pred)\n",
    "\n",
    "va_idxes = np.concatenate(va_idxes)\n",
    "order = np.argsort(va_idxes)\n",
    "preds = np.concatenate(preds, axis=0)\n",
    "preds = preds[order]\n",
    "\n",
    "final_score = get_score(Y, preds)\n",
    "print(final_score)\n",
    "LOGGER.info(f'CV Score: {final_score:<.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cb3d8e1e",
    "papermill": {
     "duration": 0.032614,
     "end_time": "2022-03-22T09:40:37.184739",
     "exception": false,
     "start_time": "2022-03-22T09:40:37.152125",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T16:04:13.341609Z",
     "iopub.status.busy": "2022-06-07T16:04:13.340162Z",
     "iopub.status.idle": "2022-06-07T16:04:13.405790Z",
     "shell.execute_reply": "2022-06-07T16:04:13.404622Z",
     "shell.execute_reply.started": "2022-06-07T16:04:13.341538Z"
    },
    "executionInfo": {
     "elapsed": 2627,
     "status": "ok",
     "timestamp": 1644920084001,
     "user": {
      "displayName": "Yasufumi Nakama",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17486303986134302670"
     },
     "user_tz": -540
    },
    "id": "bef012d3",
    "outputId": "d4d60dbc-510c-4f34-8d64-dd1d88c4808c",
    "papermill": {
     "duration": 0.154829,
     "end_time": "2022-03-22T09:40:37.374453",
     "exception": false,
     "start_time": "2022-03-22T09:40:37.219624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Data Loading\n",
    "# ====================================================\n",
    "test = pd.read_csv(INPUT_DIR+'test.csv')\n",
    "submission = pd.read_csv(INPUT_DIR+'sample_submission.csv')\n",
    "print(f\"test.shape: {test.shape}\")\n",
    "print(f\"submission.shape: {submission.shape}\")\n",
    "display(test.head())\n",
    "display(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T16:04:13.421118Z",
     "iopub.status.busy": "2022-06-07T16:04:13.417892Z",
     "iopub.status.idle": "2022-06-07T16:04:13.461773Z",
     "shell.execute_reply": "2022-06-07T16:04:13.460937Z",
     "shell.execute_reply.started": "2022-06-07T16:04:13.421050Z"
    },
    "papermill": {
     "duration": 0.848818,
     "end_time": "2022-03-22T09:40:38.260255",
     "exception": false,
     "start_time": "2022-03-22T09:40:37.411437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# CPC Data\n",
    "# ====================================================\n",
    "\n",
    "def omit_char(x):\n",
    "  x = x.replace(\";\", \"\") # ; を削除\n",
    "  x = x.replace(\"[\", \"\") # [] を削除\n",
    "  x = x.replace(\"]\", \"\") # [] を削除\n",
    "  x = x.lower() # すべて小文字に変換\n",
    "  return x\n",
    "\n",
    "cpc_texts = torch.load(os.path.join(CFG_exp016.path, \"cpc_texts.pth\"))\n",
    "test['context_text'] = test['context'].map(cpc_texts)\n",
    "test['anchor'].replace(\"dry coating composition1\", \"dry coating composition\", inplace=True)\n",
    "\n",
    "\n",
    "test['context_text'] = test['context_text'].map(omit_char)\n",
    "test['context_text'] = test['context_text'].replace(\"human necessities. griculture forestry animal husbandry hunting trapping fishing\", \n",
    "                                                      \"human necessities. agriculture forestry animal husbandry hunting trapping fishing\")\n",
    "test['context_text'] = test['context_text'].str.replace(\"hemistry\", \"chemistry\")\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T16:04:13.463814Z",
     "iopub.status.busy": "2022-06-07T16:04:13.463371Z",
     "iopub.status.idle": "2022-06-07T16:04:13.599240Z",
     "shell.execute_reply": "2022-06-07T16:04:13.598087Z",
     "shell.execute_reply.started": "2022-06-07T16:04:13.463781Z"
    },
    "papermill": {
     "duration": 0.084831,
     "end_time": "2022-03-22T09:40:38.384239",
     "exception": false,
     "start_time": "2022-03-22T09:40:38.299408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exp026"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "918a28aa",
    "papermill": {
     "duration": 0.039494,
     "end_time": "2022-03-22T09:40:39.374931",
     "exception": false,
     "start_time": "2022-03-22T09:40:39.335437",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T16:04:13.602884Z",
     "iopub.status.busy": "2022-06-07T16:04:13.602176Z",
     "iopub.status.idle": "2022-06-07T16:04:14.711167Z",
     "shell.execute_reply": "2022-06-07T16:04:14.709496Z",
     "shell.execute_reply.started": "2022-06-07T16:04:13.602842Z"
    },
    "papermill": {
     "duration": 5.198604,
     "end_time": "2022-03-22T09:40:44.612849",
     "exception": false,
     "start_time": "2022-03-22T09:40:39.414245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# tokenizer\n",
    "# ====================================================\n",
    "CFG_exp026.tokenizer = AutoTokenizer.from_pretrained(CFG_exp026.path+'tokenizer/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "14da40cf",
    "papermill": {
     "duration": 0.04897,
     "end_time": "2022-03-22T09:40:44.706931",
     "exception": false,
     "start_time": "2022-03-22T09:40:44.657961",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T16:04:14.714180Z",
     "iopub.status.busy": "2022-06-07T16:04:14.713023Z",
     "iopub.status.idle": "2022-06-07T16:04:14.727868Z",
     "shell.execute_reply": "2022-06-07T16:04:14.726487Z",
     "shell.execute_reply.started": "2022-06-07T16:04:14.714100Z"
    },
    "id": "9f791a19",
    "papermill": {
     "duration": 0.055528,
     "end_time": "2022-03-22T09:40:52.072178",
     "exception": false,
     "start_time": "2022-03-22T09:40:52.01665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Dataset\n",
    "# ====================================================\n",
    "def prepare_input(cfg, text):\n",
    "    inputs = cfg.tokenizer(text,\n",
    "                           add_special_tokens=True,\n",
    "                           max_length=cfg.max_len,\n",
    "                           padding=\"max_length\",\n",
    "                           return_offsets_mapping=False)\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = torch.tensor(v, dtype=torch.long)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.texts = df['text'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        inputs = prepare_input(self.cfg, self.texts[item])\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e04d6363",
    "papermill": {
     "duration": 0.044161,
     "end_time": "2022-03-22T09:40:52.262022",
     "exception": false,
     "start_time": "2022-03-22T09:40:52.217861",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T16:04:14.732836Z",
     "iopub.status.busy": "2022-06-07T16:04:14.731725Z",
     "iopub.status.idle": "2022-06-07T16:04:14.808496Z",
     "shell.execute_reply": "2022-06-07T16:04:14.807719Z",
     "shell.execute_reply.started": "2022-06-07T16:04:14.732779Z"
    },
    "id": "4c5bab44",
    "papermill": {
     "duration": 0.066203,
     "end_time": "2022-03-22T09:40:52.37203",
     "exception": false,
     "start_time": "2022-03-22T09:40:52.305827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Model\n",
    "# ====================================================\n",
    "class CustomModel_exp026(nn.Module):\n",
    "    def __init__(self, cfg, config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        if config_path is None:\n",
    "            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n",
    "        else:\n",
    "            self.config = torch.load(config_path)\n",
    "        if pretrained:\n",
    "            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n",
    "        else:\n",
    "            self.model = AutoModel.from_config(self.config)\n",
    "        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n",
    "        self.fc = nn.Linear(self.config.hidden_size, self.cfg.target_size)\n",
    "        self._init_weights(self.fc)\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(self.config.hidden_size, self.config.hidden_size),\n",
    "            nn.LayerNorm(self.config.hidden_size),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(self.config.hidden_size, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        self.fc_dropout1 = nn.Dropout(0.1)\n",
    "        self.fc_dropout2 = nn.Dropout(0.2)\n",
    "        self.fc_dropout3 = nn.Dropout(0.3)\n",
    "        self.fc_dropout4 = nn.Dropout(0.4)\n",
    "        self.fc_dropout5 = nn.Dropout(0.5)\n",
    "        \n",
    "        self._init_weights(self.attention)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "        \n",
    "    def feature(self, inputs):\n",
    "        outputs = self.model(**inputs)\n",
    "        last_hidden_states = outputs[0]\n",
    "        # feature = torch.mean(last_hidden_states, 1)\n",
    "        weights = self.attention(last_hidden_states)\n",
    "        feature = torch.sum(weights * last_hidden_states, dim=1)\n",
    "        return feature\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        feature = self.feature(inputs)\n",
    "\n",
    "        feature1 = self.fc_dropout1(feature)\n",
    "        feature2 = self.fc_dropout2(feature)\n",
    "        feature3 = self.fc_dropout3(feature)\n",
    "        feature4 = self.fc_dropout4(feature)\n",
    "        feature5 = self.fc_dropout5(feature)\n",
    "\n",
    "        feature_all = (feature1+feature2+feature3+feature4+feature5)/5\n",
    "        output = self.fc(feature_all)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T16:04:14.810902Z",
     "iopub.status.busy": "2022-06-07T16:04:14.810250Z",
     "iopub.status.idle": "2022-06-07T16:04:14.832348Z",
     "shell.execute_reply": "2022-06-07T16:04:14.830883Z",
     "shell.execute_reply.started": "2022-06-07T16:04:14.810854Z"
    }
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# inference\n",
    "# ====================================================\n",
    "def inference_fn(test_loader, model, device):\n",
    "    preds = []\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    tk0 = tqdm(test_loader, total=len(test_loader))\n",
    "    for inputs in tk0:\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(inputs)\n",
    "        preds.append(y_preds.sigmoid().to('cpu').numpy())\n",
    "    predictions = np.concatenate(preds)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-06-07T16:04:14.834919Z",
     "iopub.status.busy": "2022-06-07T16:04:14.834292Z"
    }
   },
   "outputs": [],
   "source": [
    "test_dataset = TestDataset(CFG_exp026, test)\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=CFG_exp026.batch_size,\n",
    "                         shuffle=False,\n",
    "                         num_workers=CFG_exp026.num_workers, pin_memory=True, drop_last=False)\n",
    "predictions = []\n",
    "for fold in CFG_exp026.trn_fold:\n",
    "    model = CustomModel_exp026(CFG_exp026, config_path=CFG_exp026.config_path, pretrained=False)\n",
    "    state = torch.load(os.path.join(CFG_exp026.path,\"model\" , f\"{CFG_exp026.model.replace('/', '-')}_fold{fold}_best.pth\"),\n",
    "                       map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(state['model'])\n",
    "    prediction = inference_fn(test_loader, model, device)\n",
    "    predictions.append(prediction)\n",
    "    del model, state, prediction; gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "predictions_exp026 = np.mean(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exp020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# tokenizer\n",
    "# ====================================================\n",
    "CFG_exp020.tokenizer = AutoTokenizer.from_pretrained(CFG_exp020.path+'tokenizer/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Model\n",
    "# ====================================================\n",
    "class CustomModel_exp020(nn.Module):\n",
    "    def __init__(self, cfg, config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        if config_path is None:\n",
    "            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n",
    "        else:\n",
    "            self.config = torch.load(config_path)\n",
    "        if pretrained:\n",
    "            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n",
    "        else:\n",
    "            self.model = AutoModel.from_config(self.config)\n",
    "        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n",
    "        self.fc = nn.Linear(self.config.hidden_size, self.cfg.target_size)\n",
    "        self._init_weights(self.fc)\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(self.config.hidden_size, self.config.hidden_size),\n",
    "            nn.LayerNorm(self.config.hidden_size),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(self.config.hidden_size, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        self.fc_dropout1 = nn.Dropout(0.1)\n",
    "        self.fc_dropout2 = nn.Dropout(0.2)\n",
    "        self.fc_dropout3 = nn.Dropout(0.3)\n",
    "        self.fc_dropout4 = nn.Dropout(0.4)\n",
    "        self.fc_dropout5 = nn.Dropout(0.5)\n",
    "        \n",
    "        self._init_weights(self.attention)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "        \n",
    "    def feature(self, inputs):\n",
    "        outputs = self.model(**inputs)\n",
    "        last_hidden_states = outputs[0]\n",
    "        # feature = torch.mean(last_hidden_states, 1)\n",
    "        weights = self.attention(last_hidden_states)\n",
    "        feature = torch.sum(weights * last_hidden_states, dim=1)\n",
    "        return feature\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        feature = self.feature(inputs)\n",
    "\n",
    "        feature1 = self.fc_dropout1(feature)\n",
    "        feature2 = self.fc_dropout2(feature)\n",
    "        feature3 = self.fc_dropout3(feature)\n",
    "        feature4 = self.fc_dropout4(feature)\n",
    "        feature5 = self.fc_dropout5(feature)\n",
    "\n",
    "        feature_all = (feature1+feature2+feature3+feature4+feature5)/5\n",
    "        output = self.fc(feature_all)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TestDataset(CFG_exp020, test)\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=CFG_exp020.batch_size,\n",
    "                         shuffle=False,\n",
    "                         num_workers=CFG_exp020.num_workers, pin_memory=True, drop_last=False)\n",
    "predictions = []\n",
    "for fold in CFG_exp020.trn_fold:\n",
    "    model = CustomModel_exp020(CFG_exp020, config_path=CFG_exp020.config_path, pretrained=False)\n",
    "    state = torch.load(os.path.join(CFG_exp020.path,\"model\" , f\"{CFG_exp020.model.replace('/', '-')}_fold{fold}_best.pth\"),\n",
    "                       map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(state['model'])\n",
    "    prediction = inference_fn(test_loader, model, device)\n",
    "    predictions.append(prediction)\n",
    "    del model, state, prediction; gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "predictions_exp020 = np.mean(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exp011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# tokenizer\n",
    "# ====================================================\n",
    "CFG_exp011.tokenizer = AutoTokenizer.from_pretrained(CFG_exp011.path+'tokenizer/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Model\n",
    "# ====================================================\n",
    "class CustomModel_exp011(nn.Module):\n",
    "    def __init__(self, cfg, config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        if config_path is None:\n",
    "            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n",
    "        else:\n",
    "            self.config = torch.load(config_path)\n",
    "        if pretrained:\n",
    "            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n",
    "        else:\n",
    "            self.model = AutoModel.from_config(self.config)\n",
    "        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n",
    "        self.fc = nn.Linear(self.config.hidden_size, self.cfg.target_size)\n",
    "        self._init_weights(self.fc)\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(self.config.hidden_size, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        self.fc_dropout1 = nn.Dropout(0.1)\n",
    "        self.fc_dropout2 = nn.Dropout(0.2)\n",
    "        self.fc_dropout3 = nn.Dropout(0.3)\n",
    "        self.fc_dropout4 = nn.Dropout(0.4)\n",
    "        self.fc_dropout5 = nn.Dropout(0.5)\n",
    "        \n",
    "        self._init_weights(self.attention)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "        \n",
    "    def feature(self, inputs):\n",
    "        outputs = self.model(**inputs)\n",
    "        last_hidden_states = outputs[0]\n",
    "        # feature = torch.mean(last_hidden_states, 1)\n",
    "        weights = self.attention(last_hidden_states)\n",
    "        feature = torch.sum(weights * last_hidden_states, dim=1)\n",
    "        return feature\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        feature = self.feature(inputs)\n",
    "\n",
    "        feature1 = self.fc_dropout1(feature)\n",
    "        feature2 = self.fc_dropout2(feature)\n",
    "        feature3 = self.fc_dropout3(feature)\n",
    "        feature4 = self.fc_dropout4(feature)\n",
    "        feature5 = self.fc_dropout5(feature)\n",
    "\n",
    "        feature_all = (feature1+feature2+feature3+feature4+feature5)/5\n",
    "        output = self.fc(feature_all)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TestDataset(CFG_exp011, test)\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=CFG_exp011.batch_size,\n",
    "                         shuffle=False,\n",
    "                         num_workers=CFG_exp011.num_workers, pin_memory=True, drop_last=False)\n",
    "predictions = []\n",
    "for fold in CFG_exp011.trn_fold:\n",
    "    model = CustomModel_exp011(CFG_exp011, config_path=CFG_exp011.config_path, pretrained=False)\n",
    "    state = torch.load(os.path.join(CFG_exp011.path,\"model\" , f\"{CFG_exp011.model.replace('/', '-')}_fold{fold}_best.pth\"),\n",
    "                       map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(state['model'])\n",
    "    prediction = inference_fn(test_loader, model, device)\n",
    "    predictions.append(prediction)\n",
    "    del model, state, prediction; gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "predictions_exp011 = np.mean(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exp018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# tokenizer\n",
    "# ====================================================\n",
    "CFG_exp018.tokenizer = AutoTokenizer.from_pretrained(CFG_exp018.path+'tokenizer/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Model\n",
    "# ====================================================\n",
    "class CustomModel_exp018(nn.Module):\n",
    "    def __init__(self, cfg, config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        if config_path is None:\n",
    "            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n",
    "        else:\n",
    "            self.config = torch.load(config_path)\n",
    "        if pretrained:\n",
    "            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n",
    "        else:\n",
    "            self.model = AutoModel.from_config(self.config)\n",
    "        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n",
    "        self.fc = nn.Linear(self.config.hidden_size, self.cfg.target_size)\n",
    "        self._init_weights(self.fc)\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(self.config.hidden_size, self.config.hidden_size),\n",
    "            nn.LayerNorm(self.config.hidden_size),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(self.config.hidden_size, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        self.fc_dropout1 = nn.Dropout(0.1)\n",
    "        self.fc_dropout2 = nn.Dropout(0.2)\n",
    "        self.fc_dropout3 = nn.Dropout(0.3)\n",
    "        self.fc_dropout4 = nn.Dropout(0.4)\n",
    "        self.fc_dropout5 = nn.Dropout(0.5)\n",
    "        \n",
    "        self._init_weights(self.attention)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "        \n",
    "    def feature(self, inputs):\n",
    "        outputs = self.model(**inputs)\n",
    "        last_hidden_states = outputs[0]\n",
    "        # feature = torch.mean(last_hidden_states, 1)\n",
    "        weights = self.attention(last_hidden_states)\n",
    "        feature = torch.sum(weights * last_hidden_states, dim=1)\n",
    "        return feature\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        feature = self.feature(inputs)\n",
    "\n",
    "        feature1 = self.fc_dropout1(feature)\n",
    "        feature2 = self.fc_dropout2(feature)\n",
    "        feature3 = self.fc_dropout3(feature)\n",
    "        feature4 = self.fc_dropout4(feature)\n",
    "        feature5 = self.fc_dropout5(feature)\n",
    "\n",
    "        feature_all = (feature1+feature2+feature3+feature4+feature5)/5\n",
    "        output = self.fc(feature_all)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TestDataset(CFG_exp018, test)\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=CFG_exp018.batch_size,\n",
    "                         shuffle=False,\n",
    "                         num_workers=CFG_exp018.num_workers, pin_memory=True, drop_last=False)\n",
    "predictions = []\n",
    "for fold in CFG_exp018.trn_fold:\n",
    "    model = CustomModel_exp018(CFG_exp018, config_path=CFG_exp018.config_path, pretrained=False)\n",
    "    state = torch.load(os.path.join(CFG_exp018.path,\"model\" , f\"{CFG_exp018.model.replace('/', '-')}_fold{fold}_best.pth\"),\n",
    "                       map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(state['model'])\n",
    "    prediction = inference_fn(test_loader, model, device)\n",
    "    predictions.append(prediction)\n",
    "    del model, state, prediction; gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "predictions_exp018 = np.mean(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exp032"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# tokenizer\n",
    "# ====================================================\n",
    "CFG_exp032.tokenizer = AutoTokenizer.from_pretrained(CFG_exp032.path+'tokenizer/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Model\n",
    "# ====================================================\n",
    "class CustomModel_exp032(nn.Module):\n",
    "    def __init__(self, cfg, config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        if config_path is None:\n",
    "            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n",
    "        else:\n",
    "            self.config = torch.load(config_path)\n",
    "        if pretrained:\n",
    "            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n",
    "        else:\n",
    "            self.model = AutoModel.from_config(self.config)\n",
    "        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n",
    "        self.fc = nn.Linear(self.config.hidden_size, self.cfg.target_size)\n",
    "        self._init_weights(self.fc)\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(self.config.hidden_size, self.config.hidden_size),\n",
    "            nn.LayerNorm(self.config.hidden_size),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(self.config.hidden_size, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        self.fc_dropout1 = nn.Dropout(0.1)\n",
    "        self.fc_dropout2 = nn.Dropout(0.2)\n",
    "        self.fc_dropout3 = nn.Dropout(0.3)\n",
    "        self.fc_dropout4 = nn.Dropout(0.4)\n",
    "        self.fc_dropout5 = nn.Dropout(0.5)\n",
    "        \n",
    "        self._init_weights(self.attention)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "        \n",
    "    def feature(self, inputs):\n",
    "        outputs = self.model(**inputs)\n",
    "        last_hidden_states = outputs[0]\n",
    "        # feature = torch.mean(last_hidden_states, 1)\n",
    "        weights = self.attention(last_hidden_states)\n",
    "        feature = torch.sum(weights * last_hidden_states, dim=1)\n",
    "        return feature\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        feature = self.feature(inputs)\n",
    "\n",
    "        feature1 = self.fc_dropout1(feature)\n",
    "        feature2 = self.fc_dropout2(feature)\n",
    "        feature3 = self.fc_dropout3(feature)\n",
    "        feature4 = self.fc_dropout4(feature)\n",
    "        feature5 = self.fc_dropout5(feature)\n",
    "\n",
    "        feature_all = (feature1+feature2+feature3+feature4+feature5)/5\n",
    "        output = self.fc(feature_all)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TestDataset(CFG_exp032, test)\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=CFG_exp032.batch_size,\n",
    "                         shuffle=False,\n",
    "                         num_workers=CFG_exp032.num_workers, pin_memory=True, drop_last=False)\n",
    "predictions = []\n",
    "for fold in CFG_exp032.trn_fold:\n",
    "    model = CustomModel_exp032(CFG_exp032, config_path=CFG_exp032.config_path, pretrained=False)\n",
    "    state = torch.load(os.path.join(CFG_exp032.path,\"model\" , f\"{CFG_exp032.model.replace('/', '-')}_fold{fold}_best.pth\"),\n",
    "                       map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(state['model'])\n",
    "    prediction = inference_fn(test_loader, model, device)\n",
    "    predictions.append(prediction)\n",
    "    del model, state, prediction; gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "predictions_exp032 = np.mean(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensamble\n",
    "\n",
    "MMscaler = MinMaxScaler()\n",
    "\n",
    "predictions_exp026 = MMscaler.fit_transform(predictions_exp026.reshape(-1,1)).reshape(-1)\n",
    "predictions_exp020 = MMscaler.fit_transform(predictions_exp020.reshape(-1,1)).reshape(-1)\n",
    "predictions_exp011 = MMscaler.fit_transform(predictions_exp011.reshape(-1,1)).reshape(-1)\n",
    "predictions_exp018 = MMscaler.fit_transform(predictions_exp018.reshape(-1,1)).reshape(-1)\n",
    "predictions_exp032 = MMscaler.fit_transform(predictions_exp032.reshape(-1,1)).reshape(-1)\n",
    "\n",
    "use_models =[\n",
    "    \"../input/pppm-baseline-026\",\n",
    "    \"../input/pppm-baseline-020\",\n",
    "    \"../input/pppm-baseline-018\",\n",
    "    \"../input/pppm-baseline-011\",\n",
    "    \"../input/pppm-baseline-032\"\n",
    "]\n",
    "\n",
    "prediction_lists = [\n",
    "    predictions_exp026,\n",
    "    predictions_exp020,\n",
    "    predictions_exp018,\n",
    "    predictions_exp011,\n",
    "    predictions_exp032\n",
    "]\n",
    "\n",
    "data_dir = {}\n",
    "for model_name, p in zip(use_models, prediction_lists):\n",
    "    data_dir[model_name.split(\"/\")[-1]] = p\n",
    "    \n",
    "\n",
    "prediction_df = pd.DataFrame(data_dir)\n",
    "# final_predictions = []\n",
    "# # 回帰モデル\n",
    "# for model in models:\n",
    "#     prediction = model.predict(prediction_df)\n",
    "#     final_predictions.append(prediction)\n",
    "# final_prediction = np.mean(final_predictions,axis=0)\n",
    "# final_prediction\n",
    "# #final_predictions =  predictions_deberta * round(deberta_weight, 2) + predictions_bert_patents * round(bert_patents_weight, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(prediction_df)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = pd.DataFrame(final_predictions).T\n",
    "test_data = pd.DataFrame(final_predictions).T\n",
    "\n",
    "test_data.columns = [f\"pred{i}\" for i in range(len(test_data.columns))]\n",
    "features = test_data.columns\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class stacking_CFG:\n",
    "    max_grad_norm=1000\n",
    "    gradient_accumulation_steps=1\n",
    "    hidden_size=256\n",
    "    dropout=0.3\n",
    "    lr=1e-4\n",
    "    batch_size=128\n",
    "    epochs=50\n",
    "    weight_decay=1e-5\n",
    "    n_fold = 5\n",
    "    features = test.columns\n",
    "    model_dir = \"../input/5model-linear-stacking/5model_kfsky_linear/\"\n",
    "    model_path = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackingDataset(Dataset):\n",
    "    def __init__(self, df, features, labels=None, model_name=None):\n",
    "        self.df = df[features].values\n",
    "        if model_name == \"2dcnn\":\n",
    "            # [N, Models, Labels, Channel] -> [N, Channel, Models, Labels]\n",
    "            self.df = self.df.reshape(-1, len(features), 1, 1)\n",
    "            self.df = self.df.transpose(0,3,1,2)\n",
    "        if not labels is None:\n",
    "            self.labels = labels.values\n",
    "        else:\n",
    "            self.labels = labels\n",
    "        \n",
    "    def __len__(self, ):\n",
    "        return len(self.df)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        inputs =  torch.FloatTensor(self.df[item]).float()\n",
    "        \n",
    "        if self.labels is None:\n",
    "            return inputs\n",
    "        labels = torch.tensor(self.labels[item]).float()\n",
    "        return inputs, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1dcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class oneDCNN(nn.Module):\n",
    "\n",
    "        def __init__(self, num_features, num_targets, hidden_size, cfg=None):\n",
    "            self. model_name=\"1dcnn\"\n",
    "            super(oneDCNN, self).__init__()\n",
    "            hidden_size = 1024\n",
    "            cha_1 = 256\n",
    "            cha_2 = 512\n",
    "            cha_3 = 512\n",
    "\n",
    "            cha_1_reshape = int(hidden_size/cha_1)\n",
    "            cha_po_1 = int(hidden_size/cha_1/2)\n",
    "            cha_po_2 = int(hidden_size/cha_1/2/2) * cha_3\n",
    "\n",
    "            self.cha_1 = cha_1\n",
    "            self.cha_2 = cha_2\n",
    "            self.cha_3 = cha_3\n",
    "            self.cha_1_reshape = cha_1_reshape\n",
    "            self.cha_po_1 = cha_po_1\n",
    "            self.cha_po_2 = cha_po_2\n",
    "\n",
    "            self.batch_norm1 = nn.BatchNorm1d(num_features)\n",
    "            self.dropout1 = nn.Dropout(0.1)\n",
    "            self.dense1 = nn.utils.weight_norm(nn.Linear(num_features, hidden_size))\n",
    "\n",
    "            self.batch_norm_c1 = nn.BatchNorm1d(cha_1)\n",
    "            self.dropout_c1 = nn.Dropout(0.1)\n",
    "            self.conv1 = nn.utils.weight_norm(nn.Conv1d(cha_1,cha_2, kernel_size = 5, stride = 1, padding=2,  bias=False),dim=None)\n",
    "\n",
    "            self.ave_po_c1 = nn.AdaptiveAvgPool1d(output_size = cha_po_1)\n",
    "\n",
    "            self.batch_norm_c2 = nn.BatchNorm1d(cha_2)\n",
    "            self.dropout_c2 = nn.Dropout(0.1)\n",
    "            self.conv2 = nn.utils.weight_norm(nn.Conv1d(cha_2,cha_2, kernel_size = 3, stride = 1, padding=1, bias=True),dim=None)\n",
    "\n",
    "            self.batch_norm_c2_1 = nn.BatchNorm1d(cha_2)\n",
    "            self.dropout_c2_1 = nn.Dropout(0.3)\n",
    "            self.conv2_1 = nn.utils.weight_norm(nn.Conv1d(cha_2,cha_2, kernel_size = 3, stride = 1, padding=1, bias=True),dim=None)\n",
    "\n",
    "            self.batch_norm_c2_2 = nn.BatchNorm1d(cha_2)\n",
    "            self.dropout_c2_2 = nn.Dropout(0.2)\n",
    "            self.conv2_2 = nn.utils.weight_norm(nn.Conv1d(cha_2,cha_3, kernel_size = 5, stride = 1, padding=2, bias=True),dim=None)\n",
    "\n",
    "            self.max_po_c2 = nn.MaxPool1d(kernel_size=4, stride=2, padding=1)\n",
    "\n",
    "            self.flt = nn.Flatten()\n",
    "\n",
    "            self.batch_norm3 = nn.BatchNorm1d(cha_po_2)\n",
    "            self.dropout3 = nn.Dropout(0.2)\n",
    "            self.dense3 = nn.utils.weight_norm(nn.Linear(cha_po_2, num_targets))\n",
    "\n",
    "        def forward(self, x):\n",
    "\n",
    "            x = self.batch_norm1(x)\n",
    "            x = self.dropout1(x)\n",
    "            x = F.celu(self.dense1(x), alpha=0.06)\n",
    "\n",
    "            x = x.reshape(x.shape[0],self.cha_1,\n",
    "                          self.cha_1_reshape)\n",
    "\n",
    "            x = self.batch_norm_c1(x)\n",
    "            x = self.dropout_c1(x)\n",
    "            x = F.relu(self.conv1(x))\n",
    "\n",
    "            x = self.ave_po_c1(x)\n",
    "\n",
    "            x = self.batch_norm_c2(x)\n",
    "            x = self.dropout_c2(x)\n",
    "            x = F.relu(self.conv2(x))\n",
    "            x_s = x\n",
    "\n",
    "            x = self.batch_norm_c2_1(x)\n",
    "            x = self.dropout_c2_1(x)\n",
    "            x = F.relu(self.conv2_1(x))\n",
    "\n",
    "            x = self.batch_norm_c2_2(x)\n",
    "            x = self.dropout_c2_2(x)\n",
    "            x = F.relu(self.conv2_2(x))\n",
    "            x =  x * x_s\n",
    "\n",
    "            x = self.max_po_c2(x)\n",
    "\n",
    "            x = self.flt(x)\n",
    "\n",
    "            x = self.batch_norm3(x)\n",
    "            x = self.dropout3(x)\n",
    "            x = self.dense3(x)\n",
    "\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_fn(test_loader, model, device):\n",
    "\n",
    "    model.eval()\n",
    "    preds = []\n",
    "\n",
    "    for step, (x) in enumerate(test_loader):\n",
    "\n",
    "        x = x.to(device, non_blocking=True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = model(x)\n",
    "\n",
    "        preds.append(pred.sigmoid().detach().cpu().numpy())\n",
    "#         preds.append(pred.tanh().detach().cpu().numpy())\n",
    "\n",
    "    preds = np.concatenate(preds)\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import zipfile\n",
    "def run_single_nn(cfg, test, features, device, fold_num, seed, MODEL,save_dir,like_sklearn=False):\n",
    "    seed_everything(seed=seed)\n",
    "    \n",
    "    if like_sklearn:\n",
    "        model = MODEL()\n",
    "        model_path = io.BytesIO()\n",
    "        with zipfile.ZipFile(model_path, \"w\") as z:\n",
    "            z.write(f\"{save_dir}tabnet_fold{fold_num}_seed{seed}/model_params.json\", arcname=\"model_params.json\")\n",
    "            z.write(f\"{save_dir}tabnet_fold{fold_num}_seed{seed}/network.pt\", arcname=\"network.pt\")\n",
    "        model.load_model(model_path)\n",
    "\n",
    "        predictions = model.predict(test[features].values)\n",
    "    else:\n",
    "        model = MODEL(\n",
    "                num_features=len(features), num_targets=1, hidden_size=cfg.hidden_size, cfg=cfg\n",
    "        )\n",
    "\n",
    "        model.load_state_dict(torch.load(f\"{save_dir}{model.model_name}_fold{fold_num}_seed{seed}.pth\",map_location=\"cpu\"), )\n",
    "        model.to(device, non_blocking=True)\n",
    "\n",
    "        test_dataset = StackingDataset(test, features, None, model.model_name)\n",
    "\n",
    "        test_loader = DataLoader(test_dataset, batch_size=cfg.batch_size, shuffle=False, \n",
    "                                  num_workers=4, pin_memory=False, drop_last=False)\n",
    "\n",
    "\n",
    "        # inference\n",
    "        predictions = inference_fn(test_loader, model, device)     \n",
    "    return predictions\n",
    "                          \n",
    "\n",
    "def run_kfold_nn(cfg, test, features, device, n_fold, seed,MODEL, save_dir, like_sklearn=False):\n",
    "    oof = np.zeros((len(test), 1))\n",
    "    for fold_num in range(n_fold):\n",
    "        LOGGER.info(f\"fold {fold_num}\")\n",
    "        _oof = run_single_nn(cfg, test, features, device, fold_num, seed, MODEL,save_dir,like_sklearn)\n",
    "        oof += _oof\n",
    "    return oof/n_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_CFG.model_path = stacking_CFG.model_dir+\"1dcnn/\"\n",
    "predictions = np.zeros((len(test), 1))\n",
    "SEED = [42, 1999, 2022]\n",
    "for i, seed in enumerate(SEED):\n",
    "    print(seed)\n",
    "    _pred = run_kfold_nn(stacking_CFG, test_data, features, device,\n",
    "                        n_fold=5, seed=seed, MODEL=oneDCNN, save_dir=stacking_CFG.model_path,\n",
    "                         )\n",
    "    predictions += _pred/len(SEED)\n",
    "    \n",
    "predictions_1dcnn = predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2dcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class twoDCNN(nn.Module):#input5\n",
    "    def __init__(self, num_features, num_targets, hidden_size, cfg):\n",
    "        self.model_name = \"2dcnn\"\n",
    "        self.num_features = num_features\n",
    "        self.num_targets = num_targets\n",
    "        super(twoDCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(3, 1), bias=False)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(2, 1), bias=False)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        # self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(2, 1), bias=False)\n",
    "        # self.relu3 = nn.ReLU()\n",
    "        # self.conv4 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 1), bias=False)\n",
    "        # self.relu4 = nn.ReLU()\n",
    "        \n",
    "#         self.conv5 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(2, 1), bias=False)\n",
    "#         self.relu5 = nn.ReLU()\n",
    "#         self.conv6 = nn.Conv2d(in_channels=128, out_channels=1024, kernel_size=(1, 1), bias=False)\n",
    "#         self.relu6 = nn.ReLU()\n",
    "            \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(in_features=32, out_features=512)\n",
    "        # self.fc1 = nn.Linear(in_features=80, out_features=512)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(in_features=512, out_features=num_targets)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        \n",
    "#         x = self.conv3(x)\n",
    "#         x = self.relu3(x)\n",
    "#         x = self.conv4(x)\n",
    "#         x = self.relu4(x)\n",
    "        \n",
    "#         x = self.conv5(x)\n",
    "#         x = self.relu5(x)\n",
    "#         x = self.conv6(x)\n",
    "#         x = self.relu6(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_CFG.model_path = stacking_CFG.model_dir+\"2dcnn/\"\n",
    "predictions = np.zeros((len(test), 1))\n",
    "SEED = [42, 1999, 2022]\n",
    "for i, seed in enumerate(SEED):\n",
    "    print(seed)\n",
    "    _pred = run_kfold_nn(stacking_CFG, test_data, features, device,\n",
    "                        n_fold=5, seed=seed, MODEL=twoDCNN, save_dir=stacking_CFG.model_path,\n",
    "                         )\n",
    "    predictions += _pred/len(SEED)\n",
    "    \n",
    "predictions_2dcnn = predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackingMLP(nn.Module):\n",
    "    def __init__(self, num_features, num_targets, hidden_size, cfg):\n",
    "        super().__init__()\n",
    "        self.model_name = \"mlp\"\n",
    "        cfg.num_features = num_features\n",
    "        cfg.hidden_size = hidden_size\n",
    "    \n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.BatchNorm1d((num_features)),\n",
    "            nn.Dropout(cfg.dropout),\n",
    "            nn.utils.weight_norm(nn.Linear((cfg.num_features), cfg.hidden_size)),\n",
    "            nn.PReLU(),\n",
    "\n",
    "            \n",
    "            nn.BatchNorm1d(cfg.hidden_size),\n",
    "            nn.Dropout(cfg.dropout),\n",
    "            nn.utils.weight_norm(nn.Linear(cfg.hidden_size, cfg.hidden_size)),\n",
    "            nn.PReLU(),\n",
    "\n",
    "                        \n",
    "            nn.BatchNorm1d(cfg.hidden_size),\n",
    "            nn.Dropout(cfg.dropout),\n",
    "            nn.utils.weight_norm(nn.Linear(cfg.hidden_size, num_targets)),\n",
    "\n",
    "        )\n",
    "        \n",
    "        self.shallow_mlp = nn.Sequential(\n",
    "        \n",
    "                          nn.Linear((cfg.num_features), cfg.hidden_size),\n",
    "                          nn.BatchNorm1d(cfg.hidden_size),\n",
    "                          nn.Dropout(cfg.dropout),\n",
    "                          nn.PReLU(),\n",
    "                          nn.Linear(cfg.hidden_size, cfg.hidden_size),\n",
    "                          nn.BatchNorm1d(cfg.hidden_size),\n",
    "                          nn.Dropout(cfg.dropout),\n",
    "                          nn.PReLU(),\n",
    "                          nn.Linear(cfg.hidden_size, num_targets),\n",
    "                          )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # if \"shallow\" in  stacking_exp_name:\n",
    "        x = self.shallow_mlp(x)\n",
    "        # else:\n",
    "        #     x = self.mlp(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_CFG.model_path = stacking_CFG.model_dir+\"mlp/\"\n",
    "predictions = np.zeros((len(test), 1))\n",
    "stacking_exp_name=\"shallow\"\n",
    "SEED = [42, 1999, 2022]\n",
    "for i, seed in enumerate(SEED):\n",
    "    print(seed)\n",
    "    _pred = run_kfold_nn(stacking_CFG, test_data, features, device,\n",
    "                        n_fold=5, seed=seed, MODEL=StackingMLP, save_dir=stacking_CFG.model_path,\n",
    "                         )\n",
    "    predictions += _pred/len(SEED)\n",
    "predictions_mlp = predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as tp\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"Stacked Dense layers\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, n_features_list: tp.List[int], use_tail_as_out: bool=False,\n",
    "        drop_rate: float=0.0, use_bn: bool=False, use_wn: bool=False,\n",
    "        activ:str=\"relu\", block_name: str=\"LBAD\"\n",
    "    ):\n",
    "        \"\"\"\"\"\"\n",
    "        super(MLP, self).__init__()\n",
    "        n_layers = len(n_features_list) - 1\n",
    "        block_class = {\n",
    "            \"LBAD\": LBAD, \"BDLA\": BDLA, \"LABD\": LABD}[block_name]\n",
    "        layers = []\n",
    "        for i in range(n_layers):\n",
    "            in_feats, out_feats = n_features_list[i: i + 2]\n",
    "            if i == n_layers - 1 and use_tail_as_out:\n",
    "                if block_name in [\"BDLA\"]:\n",
    "                    layer = block_class(in_feats, out_feats, drop_rate, use_bn,  use_wn, \"identity\")\n",
    "                else:\n",
    "                    layer = nn.Linear(in_feats, out_feats)\n",
    "                    if use_wn:\n",
    "                        layer = nn.utils.weight_norm(layer)\n",
    "            else:\n",
    "                layer = block_class(in_feats, out_feats, drop_rate, use_bn,  use_wn, activ)\n",
    "            layers.append(layer)\n",
    "                \n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\"\"\"\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "class CNNStacking1d(nn.Module):\n",
    "    \"\"\"1D-CNN for Stacking.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, n_models: int,\n",
    "        n_channels_list: tp.List[int], use_bias: bool=False,\n",
    "        kwargs_head: tp.Dict={},\n",
    "    ):\n",
    "        \"\"\"\"\"\"\n",
    "        super(CNNStacking1d, self).__init__()\n",
    "        self.n_conv_layers = len(n_channels_list) - 1\n",
    "        for i in range(self.n_conv_layers):\n",
    "            in_ch = n_channels_list[i]\n",
    "            out_ch = n_channels_list[i + 1]\n",
    "            layer = nn.Sequential(\n",
    "                nn.Conv1d(\n",
    "                    in_ch, out_ch, kernel_size=3, stride=1, padding=0, bias=use_bias),\n",
    "                # nn.BatchNorm1d(out_ch),\n",
    "                nn.ReLU(inplace=True))\n",
    "            setattr(self, \"conv{}\".format(i + 1), layer)\n",
    "        \n",
    "        kwargs_head[\"n_features_list\"][0] = (n_models - 2 * self.n_conv_layers) * n_channels_list[-1]\n",
    "        self.head = MLP(**kwargs_head)\n",
    "    \n",
    "    def forward(self, x: torch.FloatTensor) -> torch.Tensor:\n",
    "        \"\"\"\"\"\"\n",
    "        bs = x.shape[0]\n",
    "        h = x  # shape: (bs, n_classes, n_models)\n",
    "        for i in range(self.n_conv_layers):\n",
    "            h = getattr(self, \"conv{}\".format(i + 1))(h)\n",
    "            \n",
    "        h = torch.reshape(h, (bs, -1))\n",
    "        h = self.head(h)\n",
    "        return h\n",
    "    \n",
    "    \n",
    "    \n",
    "def get_activation(activ_name: str=\"relu\"):\n",
    "    \"\"\"\"\"\"\n",
    "    act_dict = {\n",
    "        \"relu\": nn.ReLU(),\n",
    "        \"tanh\": nn.Tanh(),\n",
    "        \"sigmoid\": nn.Sigmoid(),\n",
    "        \"identity\": nn.Identity()}\n",
    "    if activ_name in act_dict:\n",
    "        return act_dict[activ_name]\n",
    "    elif re.match(r\"^htanh\\_\\d{4}$\", activ_name):\n",
    "        bound = int(activ_name[-4:]) / 1000\n",
    "        return nn.Hardtanh(-bound, bound)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "class LBAD(nn.Module):\n",
    "    \"\"\"Linear (-> BN) -> Activation (-> Dropout)\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, in_features: int, out_features: int, drop_rate: float=0.0,\n",
    "        use_bn: bool=False, use_wn: bool=False, activ: str=\"relu\"\n",
    "    ):\n",
    "        \"\"\"\"\"\"\n",
    "        super(LBAD, self).__init__()\n",
    "        layers = [nn.Linear(in_features, out_features)]\n",
    "        if use_wn:\n",
    "            layers[0] = nn.utils.weight_norm(layers[0])\n",
    "        \n",
    "        if use_bn:\n",
    "            layers.append(nn.BatchNorm1d(out_features))\n",
    "        \n",
    "        layers.append(get_activation(activ))\n",
    "        \n",
    "        if drop_rate > 0:\n",
    "            layers.append(nn.Dropout(drop_rate))\n",
    "        \n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\"\"\"\n",
    "        return self.layers(x)\n",
    "    \n",
    "    \n",
    "class BDLA(nn.Module):\n",
    "    \"\"\"(BN -> Dropout ->) Linear -> Activation\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, in_features: int, out_features: int, drop_rate: float=0.0,\n",
    "        use_bn: bool=False, use_wn: bool=False, activ: str=\"relu\"\n",
    "    ):\n",
    "        \"\"\"\"\"\"\n",
    "        super(BDLA, self).__init__()\n",
    "        layers = []\n",
    "        if use_bn:\n",
    "            layers.append(nn.BatchNorm1d(in_features))\n",
    "            \n",
    "        if drop_rate > 0:\n",
    "            layers.append(nn.Dropout(drop_rate))\n",
    "        \n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        if use_wn:\n",
    "            layers[-1] = nn.utils.weight_norm(layers[-1])\n",
    "            \n",
    "        layers.append(get_activation(activ))\n",
    "        \n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\"\"\"\n",
    "        return self.layers(x)\n",
    "    \n",
    "\n",
    "class LABD(nn.Module):\n",
    "    \"\"\"Linear -> Activation (-> BN -> Dropout) \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, in_features: int, out_features: int, drop_rate: float=0.0,\n",
    "        use_bn: bool=False, use_wn: bool=False, activ: str=\"relu\"\n",
    "    ):\n",
    "        \"\"\"\"\"\"\n",
    "        super(LABD, self).__init__()\n",
    "        layers = [nn.Linear(in_features, out_features), get_activation(activ)]\n",
    "        \n",
    "        if use_wn:\n",
    "            layers[0] = nn.utils.weight_norm(layers[0])\n",
    "        \n",
    "        if use_bn:\n",
    "            layers.append(nn.BatchNorm1d(out_features))\n",
    "        \n",
    "        if drop_rate > 0:\n",
    "            layers.append(nn.Dropout(drop_rate))\n",
    "        \n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\"\"\"\n",
    "        return self.layers(x)\n",
    "# # for GCNs\n",
    "def vector_wise_matmul(X: torch.Tensor, W: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    See input matrixes X as bags of vectors, and multiply corresponding weight matrices by vector.\n",
    "    \n",
    "    Args:\n",
    "        X: Input Tensor, shape: (batch_size, **n_vectors**, in_features)\n",
    "        W: Weight Tensor, shape: (**n_vectors**, out_features, in_features)\n",
    "    \"\"\"\n",
    "\n",
    "    X = torch.transpose(X, 0, 1)  # shape: (n_vectors, batch_size, in_features)\n",
    "    W = torch.transpose(W, 1, 2)  # shape: (n_vectors, in_features, out_features)\n",
    "    H = torch.matmul(X, W)        # shape: (n_vectors, batch_size, out_features)\n",
    "    H = torch.transpose(H, 0, 1)  # shape: (batch_size, n_vectors, out_features)\n",
    "    \n",
    "    return H\n",
    "\n",
    "\n",
    "def vector_wise_shared_matmul(X: torch.Tensor, W: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    See input matrixes X as bags of vectors, and multiply **shared** weight matrices.\n",
    "    \n",
    "    Args:\n",
    "        X: Input Tensor, shape: (batch_size, **n_vectors**, in_features)\n",
    "        W: Weight Tensor, shape: (out_features, in_features)\n",
    "    \"\"\"\n",
    "    # W = torch.transpose(W, 0, 1)  # shape: (in_features, out_features)\n",
    "    # H = torch.matmul(X, W)        # shape: (batch_size, n_vectors, out_features)\n",
    "    \n",
    "    H = nn.functional.linear(X, W)  # shape: (batch_size, n_vectors, out_features)\n",
    "    \n",
    "    return H\n",
    "def _calculate_fan_in_and_fan_out_for_vwl(tensor) -> tp.Tuple[int]:\n",
    "    \"\"\"\n",
    "    Input tensor: (n_vectors, out_features, in_features) or (out_features, in_features)\n",
    "    \"\"\"\n",
    "    dimensions = tensor.dim()\n",
    "    if dimensions < 2:\n",
    "        raise ValueError(\"Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\")\n",
    "\n",
    "    fan_in = tensor.size(-1)\n",
    "    fan_out = tensor.size(-2)\n",
    "\n",
    "    return fan_in, fan_out\n",
    "    \n",
    "\n",
    "def _calculate_correct_fan_for_vwl(tensor, mode) -> int:\n",
    "    \"\"\"\"\"\"\n",
    "    mode = mode.lower()\n",
    "    valid_modes = ['fan_in', 'fan_out']\n",
    "    if mode not in valid_modes:\n",
    "        raise ValueError(\"Mode {} not supported, please use one of {}\".format(mode, valid_modes))\n",
    "\n",
    "    fan_in, fan_out = _calculate_fan_in_and_fan_out_for_vwl(tensor)\n",
    "    return fan_in if mode == 'fan_in' else fan_out\n",
    "\n",
    "\n",
    "def kaiming_uniform_for_vwl(tensor, a=0, mode='fan_in', nonlinearity='leaky_relu'):\n",
    "    \"\"\"\"\"\"\n",
    "    fan = _calculate_correct_fan_for_vwl(tensor, mode)\n",
    "    gain = nn.init.calculate_gain(nonlinearity, a)\n",
    "    std = gain / np.sqrt(fan)\n",
    "    bound = np.sqrt(3.0) * std  # Calculate uniform bounds from standard deviation\n",
    "    with torch.no_grad():\n",
    "        return tensor.uniform_(-bound, bound)\n",
    "class VectorWiseLinear(nn.Module):\n",
    "    \"\"\"\n",
    "    For mini batch which have several matrices,\n",
    "    see as these matrixes as bags of vectors, and multiply weight matrices by vector.\n",
    "    \n",
    "    input    X: (batch_size, **n_vectors**, in_features)\n",
    "    weight W: (**n_vector**, out_features, in_features)\n",
    "    output  Y: (batch_size, **n_vectors**, out_features)\n",
    "\n",
    "    **Note**: For simplicity, bias is not described.\n",
    "    \n",
    "    X and W are can be seen as below.\n",
    "    X: [\n",
    "            [vec_{ 1, 1}, vec_{ 1, 2}, ... vec_{ 1, n_vectors}],\n",
    "            [vec_{ 2, 1}, vec_{ 2, 2}, ... vec_{ 2, n_vectors}],\n",
    "                                            .\n",
    "                                            .\n",
    "            [vec_{bs, 1}, vec_{bs, 2}, ... vec_{bs, n_vectors}]\n",
    "        ]\n",
    "    W: [\n",
    "            Mat_{1}, Mat_{2}, ... , Mat_{n_vectors}\n",
    "        ]\n",
    "    Then Y is calclauted as:\n",
    "    Y: [\n",
    "        [ Mat_{1} vec_{ 1, 1}, Mat_{2} vec_{ 1, 2}, ... Mat_{n_vectors} vec_{ 1, n_vectors}],\n",
    "        [ Mat_{1} vec_{ 2, 1}, Mat_{2} vec_{ 2, 2}, ... Mat_{n_vectors} vec_{ 2, n_vectors}],\n",
    "        .\n",
    "        .\n",
    "        [ Mat_{1} vec_{bs, 1}, Mat_{2} vec_{bs, 2}, ... Mat_{n_vectors} vec_{bs, n_vectors}],\n",
    "    ]\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features: int, out_features: int, n_vectors: int,\n",
    "        bias: bool=True, weight_shared: bool=True\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize.\"\"\"\n",
    "        super(VectorWiseLinear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.n_vectors = n_vectors\n",
    "        self.weight_shared = weight_shared\n",
    "        \n",
    "        if self.weight_shared:\n",
    "            self.weight = nn.Parameter(\n",
    "                torch.Tensor(self.out_features, self.in_features)).to(device)\n",
    "            self.matmul_func = vector_wise_shared_matmul\n",
    "        else:\n",
    "            self.weight = nn.Parameter(\n",
    "                torch.Tensor(self.n_vectors, self.out_features, self.in_features))\n",
    "            self.matmul_func = vector_wise_matmul\n",
    "            \n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "            \n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self) -> None:\n",
    "        \"\"\"Initialize weight and bias.\"\"\"\n",
    "        kaiming_uniform_for_vwl(self.weight, a=np.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = _calculate_fan_in_and_fan_out_for_vwl(self.weight)\n",
    "            bound = 1 / np.sqrt(fan_in)\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "             \n",
    "    def forward(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward.\"\"\"\n",
    "        H = self.matmul_func(X, self.weight)\n",
    "        if self.bias is not None:\n",
    "            H = H + self.bias\n",
    "        \n",
    "        return H\n",
    "class GraphConv(nn.Module):\n",
    "    \"\"\"Basic Graph Convolution Layer.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        in_channels: int, out_channels: int, n_nodes: int, shrare_msg: bool=True,\n",
    "        model_self: bool=True, share_model_self: bool=True,\n",
    "        bias: bool=True, share_bias: bool=True\n",
    "    ) -> None:\n",
    "        \"\"\"Intialize.\"\"\"\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.n_nodes = n_nodes\n",
    "        self.model_self = model_self\n",
    "        super(GraphConv, self).__init__()\n",
    "        \n",
    "        # # message\n",
    "        self.msg = VectorWiseLinear(\n",
    "            in_channels, out_channels, n_nodes, False, shrare_msg)\n",
    "\n",
    "        # # self-modeling\n",
    "        if model_self:\n",
    "            self.model_self = VectorWiseLinear(\n",
    "                in_channels, out_channels, n_nodes, False, share_model_self)\n",
    "        \n",
    "        # # bias\n",
    "        if bias:\n",
    "            if share_bias:\n",
    "                self.bias = nn.Parameter(torch.Tensor(out_channels))\n",
    "            else:\n",
    "                self.bias = nn.Parameter(torch.Tensor(n_nodes, out_channels))\n",
    "            bound = 1 / np.sqrt(out_channels)\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "            \n",
    "    \n",
    "    def forward(self, X: torch.Tensor, A: torch.Tensor, W: torch.Tensor=None) -> torch.Tensor:\n",
    "        \"\"\"Forward.\n",
    "        \n",
    "        Args:\n",
    "            X: (batch_size, n_nodes, n_channels)\n",
    "                Array which represents bags of vectors.\n",
    "                X[:, i, :] are corresponded to feature vectors of node i.\n",
    "            A: (batch_size, n_nodes, n_nodes)\n",
    "                Array which represents adjacency matrices.\n",
    "                A[:, i, j] are corresponded to weights (scalar) of edges from node j to node i.\n",
    "            W: (batch_size, n_nodes, n_nodes)\n",
    "                Array which represents weight matrices between nodes.\n",
    "        \"\"\"\n",
    "        if W is not None:\n",
    "            A = A * W  # shape: (batch_size, n_nodes, n_nodes)\n",
    "        \n",
    "        # # update message\n",
    "        M = X  #  shape: (batch_size, n_nodes, in_channels)\n",
    "        # # # send message\n",
    "        M = self.msg(M)  # shape: (batch_size, n_nodes, out_channels)\n",
    "        # # # aggregate\n",
    "        M = torch.matmul(A, M)  # shape: (batch_size, n_nodes, out_channels)\n",
    "            \n",
    "        # # update node\n",
    "        # # # self-modeling\n",
    "        H = M\n",
    "        if self.model_self:\n",
    "            H = H + self.model_self(X)\n",
    "        if self.bias is not None:\n",
    "            H = H + self.bias\n",
    "        \n",
    "        return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    \"\"\"GCN for Stacking.\"\"\"\n",
    "    \n",
    "    # def __init__(\n",
    "    #     self, n_classes: int,\n",
    "    #     n_channels_list: tp.List[int],\n",
    "    #     add_self_loop: bool=False,\n",
    "    #     kwargs_head: tp.Dict={},\n",
    "    # ):\n",
    "    def __init__(self, num_features, num_targets, hidden_size, cfg):\n",
    "        self.model_name = \"GCN\"\n",
    "        n_classes = 1\n",
    "        n_channels_list =  [5, 16, 16, 16, 16, 16,16]#[8, 16, 16, 16, 16, 16, 16,]\n",
    "        add_self_loop = True\n",
    "        kwargs_head = {\n",
    "            \"n_features_list\": [-1, 768, 1],# [-1, 2048, 1]\n",
    "            \"use_tail_as_out\": True,\n",
    "            \"drop_rate\": 0.8,\n",
    "            \"use_bn\": False,\n",
    "            \"use_wn\": True,\n",
    "            \"block_name\": \"LABD\",\n",
    "        }\n",
    "        \n",
    "        \n",
    "        super().__init__()\n",
    "        self.n_conv_layers = len(n_channels_list) - 1\n",
    "        for i in range(self.n_conv_layers):\n",
    "            in_ch = n_channels_list[i]\n",
    "            out_ch = n_channels_list[i + 1]\n",
    "            # layer = CustomGraphConv(in_ch, out_ch, n_classes)\n",
    "            layer = GraphConv(\n",
    "                in_ch, out_ch, n_classes,\n",
    "                shrare_msg=False, share_model_self=False, share_bias=False)\n",
    "            setattr(self, \"conv{}\".format(i + 1), layer)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        if add_self_loop:\n",
    "            adj_mat = torch.ones(n_classes, n_classes) / n_classes\n",
    "        else:\n",
    "            adj_mat = (1 - torch.eye(n_classes, n_classes)) / (n_classes - 1) \n",
    "        self.register_buffer(\"A\", adj_mat.float())\n",
    "               \n",
    "        kwargs_head[\"n_features_list\"][0] = n_classes * n_channels_list[-1]\n",
    "        self.head = MLP(**kwargs_head)\n",
    "    \n",
    "    def forward(self, X: torch.FloatTensor) -> torch.Tensor:\n",
    "        \"\"\"\"\"\"\n",
    "        X = X.unsqueeze(1)\n",
    "        bs, n_classes = X.shape[:2]\n",
    "        H = X  # shape: (bs, n_classes, n_models)\n",
    "        for i in range(self.n_conv_layers):\n",
    "            H = getattr(self, \"conv{}\".format(i + 1))(H, self.A[None, ...])\n",
    "            H = self.relu(H)\n",
    "        \n",
    "        h = torch.reshape(H, (bs, -1))\n",
    "        h = self.head(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_CFG.model_path = stacking_CFG.model_dir+\"gcn/\"\n",
    "predictions = np.zeros((len(test), 1))\n",
    "\n",
    "SEED = [42, 1999, 2022]\n",
    "device = torch.device(\"cpu\")\n",
    "for i, seed in enumerate(SEED):\n",
    "    print(seed)\n",
    "    _pred = run_kfold_nn(stacking_CFG, test_data, features, device,\n",
    "                        n_fold=5, seed=seed, MODEL=GCN, save_dir=stacking_CFG.model_path,\n",
    "                         )\n",
    "    predictions += _pred/len(SEED)\n",
    "\n",
    "predictions_gcn = predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.system('python -m pip install --no-index --find-links=../input/pytorchtabnet/pytorch-tabnet  pytorch-tabnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetClassifier, TabNetRegressor\n",
    "stacking_CFG.model_path = stacking_CFG.model_dir+\"tabnet/\"\n",
    "predictions = np.zeros((len(test), 1))\n",
    "\n",
    "SEED = [42, 1999, 2022]\n",
    "device = torch.device(\"cpu\")\n",
    "for i, seed in enumerate(SEED):\n",
    "    print(seed)\n",
    "    _pred = run_kfold_nn(stacking_CFG, test_data, features, device,\n",
    "                        n_fold=5, seed=seed, MODEL=TabNetRegressor, save_dir=stacking_CFG.model_path, like_sklearn=True\n",
    "                         )\n",
    "    predictions += _pred/len(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_tabnet = predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df = pd.DataFrame(np.concatenate([\n",
    "    predictions_gcn,predictions_1dcnn, predictions_2dcnn, predictions_mlp, predictions_tabnet\n",
    "], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions = []\n",
    "for model in models:\n",
    "    prediction = model.predict(prediction_df)\n",
    "    final_predictions.append(prediction)\n",
    "final_prediction = np.mean(final_predictions,axis=0)\n",
    "\n",
    "# submission[\"score\"] = final_prediction\n",
    "# submission[[\"id\", \"score\"]].to_csv(f\"submission.csv\",index=False)\n",
    "\n",
    "final_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# postprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "oof_df_exp020 = pd.read_pickle(os.path.join(CFG_exp020.path, \"preds\", \"oof_df.pkl\"))\n",
    "postprocess_df = pd.merge(train_df[[\"id\"]], oof_df_exp020, on=\"id\", how=\"left\")\n",
    "postprocess_df = postprocess_df.drop([\"pred\", \"fold\", \"score_map\", \"anchor_map\"],axis=1)\n",
    "postprocess_df[\"pred\"] = preds\n",
    "\n",
    "\n",
    "print(get_score(postprocess_df[\"score\"], postprocess_df[\"pred\"]))\n",
    "\n",
    "## 残差を算出\n",
    "postprocess_df[\"res\"] = postprocess_df[\"score\"] - postprocess_df[\"pred\"]\n",
    "postprocess_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from contextlib import contextmanager\n",
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD, NMF, LatentDirichletAllocation\n",
    "from sklearn.pipeline import Pipeline\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class BaseBlock(object):\n",
    "    def fit(self, input_df, y=None):\n",
    "        return self.transform(input_df)\n",
    "    \n",
    "    def transform(self, input_df):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "        \n",
    "class ContinuousBlock(BaseBlock):\n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "        \n",
    "    def transform(self, input_df):\n",
    "        return input_df[self.column].copy()\n",
    "\n",
    "\n",
    "# 大元の実装では、whole_df(train_df+test_df)であるが、今回は裏側にいる\n",
    "# これはいいのか？\n",
    "class CountEncodingBlock(BaseBlock):\n",
    "    def __init__(self, column, whole_df):\n",
    "        self.column = column\n",
    "        self.whole_df = whole_df\n",
    "    \n",
    "    def transform(self, input_df):\n",
    "        output_df = pd.DataFrame()\n",
    "        vc = self.whole_df[self.column].value_counts()\n",
    "        output_df[self.column] = input_df[self.column].map(vc)\n",
    "        \n",
    "        return output_df.add_prefix(\"CE_\")\n",
    "\n",
    "\n",
    "class OneHotEncodingBlock(BaseBlock):\n",
    "    def __init__(self, column, count_limit: int):\n",
    "        self.column = column\n",
    "        self.count_limit = count_limit\n",
    "\n",
    "    def fit(self, input_df, y=None):\n",
    "        vc = input_df[self.column].dropna().value_counts()\n",
    "        cats_ = vc[vc > self.count_limit].index\n",
    "        self.cats_ = cats_\n",
    "        return self.transform(input_df)\n",
    "\n",
    "    def transform(self, input_df):\n",
    "        x = pd.Categorical(input_df[self.column], categories=self.cats_)\n",
    "        output_df = pd.get_dummies(x, dummy_na=False)\n",
    "        output_df.columns = output_df.columns.to_list()\n",
    "        return output_df.add_prefix(f'OHE_{self.column}=')\n",
    "    \n",
    "\n",
    "class LabelEncodingBlock(BaseBlock):\n",
    "    def __init__(self, column, whole_df):\n",
    "        self.column = column\n",
    "        self.whole_df = whole_df\n",
    "        self.le = LabelEncoder()\n",
    "        \n",
    "    def fit(self, input_df, y=None):\n",
    "        self.le.fit(self.whole_df[self.column].fillna(\"nan\"))\n",
    "        return self.transform(input_df)\n",
    "    \n",
    "    def transform(self, input_df):\n",
    "        c = self.column\n",
    "        output_df = input_df.copy()\n",
    "        output_df[c] = self.le.transform(input_df[c].fillna(\"nan\")).astype(int)\n",
    "        output_df = output_df[[c]]\n",
    "        return output_df.add_prefix(\"LE_\")\n",
    "    \n",
    "    \n",
    "    class WrapperBlock(BaseBlock):\n",
    "        def __init__(self,function):\n",
    "            self.function = function\n",
    "            \n",
    "        def transform(self, input_df):\n",
    "            return self.function(input_df)\n",
    "\n",
    "\n",
    "class AggregationBlock(BaseBlock):\n",
    "    def __init__(self,\n",
    "                 whole_df: pd.DataFrame,\n",
    "                 key: str,\n",
    "                 agg_column: str,\n",
    "                 agg_funcs: [\"mean\"],\n",
    "                 fillna=None):\n",
    "        self.whole_df = whole_df\n",
    "        self.key = key\n",
    "        self.agg_column = agg_column\n",
    "        self.agg_funcs = agg_funcs\n",
    "        self.fillna = fillna\n",
    "\n",
    "    def fit(self, input_df):\n",
    "        return self.transform(input_df)\n",
    "\n",
    "    def transform(self, input_df):\n",
    "        if self.fillna:\n",
    "            self.whole_df[self.agg_column] = self.whole_df[self.agg_column].fillna(self.fillna)\n",
    "\n",
    "        self.group_df = self.whole_df.groupby(self.key).agg({self.agg_column: self.agg_funcs}).reset_index()\n",
    "        column_names = [f'GP_{self.agg_column}@{self.key}_{agg_func}' for agg_func in self.agg_funcs]\n",
    "\n",
    "        self.group_df.columns = [self.key] + column_names\n",
    "        output_df = pd.merge(input_df[self.key], self.group_df, on=self.key, how=\"left\").drop(columns=[self.key])\n",
    "        return output_df\n",
    "\n",
    "\n",
    "class StringLengthBlock(BaseBlock):\n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "\n",
    "    def transform(self, input_df):\n",
    "        output_df = pd.DataFrame()\n",
    "        output_df[self.column] = input_df[self.column].str.len()\n",
    "        return output_df.add_prefix(\"StringLength_\")\n",
    "\n",
    "\n",
    "class WordCountBlock(BaseBlock):\n",
    "    def __init__(self, column: str):\n",
    "        self.column = column\n",
    "\n",
    "    def transform(self, input_df):\n",
    "        output_df = pd.DataFrame()\n",
    "        output_df[f\"WORDCOUNT_{self.column}\"] = input_df[self.column].astype(str).map(lambda x: len(x.split()))\n",
    "\n",
    "        return output_df\n",
    "    \n",
    "\n",
    "def text_cleaning(text):\n",
    "    '''\n",
    "    Cleans text into a basic form for NLP. Operations include the following:-\n",
    "    1. Remove special charecters like &, #, etc\n",
    "    2. Removes extra spaces\n",
    "    3. Removes embedded URL links\n",
    "    4. Removes HTML tags\n",
    "    5. Removes emojis\n",
    "    \n",
    "    text - Text piece to be cleaned.\n",
    "    '''\n",
    "    template = re.compile(r'https?://\\S+|www\\.\\S+') #Removes website links\n",
    "    text = template.sub(r'', text)\n",
    "    \n",
    "    soup = BeautifulSoup(text, 'lxml') #Removes HTML tags\n",
    "    only_text = soup.get_text()\n",
    "    text = only_text\n",
    "    \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "    \n",
    "    text = re.sub(r\"[^a-zA-Z\\d]\", \" \", text) #Remove special Charecters\n",
    "    text = re.sub(' +', ' ', text) #Remove Extra Spaces\n",
    "    text = text.strip() # remove spaces at the beginning and at the end of string\n",
    "\n",
    "    return text\n",
    "\n",
    "    \n",
    "class TfidfBlock(BaseBlock):\n",
    "    def __init__(self, column: str, whole_df: pd.DataFrame, decomposition: str, n_compose: int):\n",
    "        self.column = column\n",
    "        self.whole_df = whole_df\n",
    "        self.decomposition = decomposition\n",
    "        self.n_compose = n_compose\n",
    "\n",
    "    def fit(self, input_df, y=None):\n",
    "        master_df = self.whole_df\n",
    "        text = self.whole_df[self.column].fillna(\"\")\n",
    "\n",
    "        if self.decomposition == \"svd\":\n",
    "            self.pipeline_ = Pipeline([\n",
    "                (\"tfidf\", TfidfVectorizer(max_features=50000)),\n",
    "                (\"svd\", TruncatedSVD(n_components=self.n_compose, random_state=71))\n",
    "            ])\n",
    "\n",
    "        elif self.decomposition == \"NMF\":\n",
    "            self.pipeline_ = Pipeline([\n",
    "                (\"tfidf\", TfidfVectorizer(max_features=50000)),\n",
    "                (\"NMF\", NMF(n_components=self.n_compose, random_state=71))\n",
    "            ])\n",
    "        elif self.decomposition == \"LDA\":\n",
    "            self.pipeline_ = Pipeline([\n",
    "                (\"tfidf\", TfidfVectorizer(max_features=50000)),\n",
    "                (\"NMF\", LatentDirichletAllocation(n_components=self.n_compose, random_state=71))\n",
    "            ])\n",
    "        else:\n",
    "            self.pipeline_ = Pipeline([\n",
    "                (\"tfidf\", TfidfVectorizer(max_features=50000)),\n",
    "                (\"svd\", TruncatedSVD(n_components=self.n_compose, random_state=71))\n",
    "            ])\n",
    "\n",
    "        self.pipeline_.fit(text)\n",
    "\n",
    "        return self.transform(input_df)\n",
    "\n",
    "    def transform(self, input_df):\n",
    "        text = input_df[self.column].fillna(\"\")\n",
    "        z = self.pipeline_.transform(text)\n",
    "\n",
    "        out_df = pd.DataFrame(z)\n",
    "        return out_df.add_prefix(f'{self.column}_tfidf_{self.decomposition}_')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(logger=None, format_str='{:.3f}[s]', prefix=None, suffix=None):\n",
    "    if prefix: format_str = str(prefix) + format_str\n",
    "    if suffix: format_str = format_str + str(suffix)\n",
    "    start = time()\n",
    "    yield\n",
    "    d = time() - start\n",
    "    out_str = format_str.format(d)\n",
    "    if logger:\n",
    "        logger.info(out_str)\n",
    "    else:\n",
    "        print(out_str)\n",
    "\n",
    "\n",
    "def get_function(block, is_train):\n",
    "    s = mapping = {\n",
    "        True: 'fit',\n",
    "        False: 'transform'\n",
    "    }.get(is_train)\n",
    "    return getattr(block, s)\n",
    "\n",
    "\n",
    "def to_feature(input_df,\n",
    "               blocks,\n",
    "               is_train=False):\n",
    "    out_df = pd.DataFrame()\n",
    "\n",
    "    for block in tqdm(blocks, total=len(blocks)):\n",
    "        func = get_function(block, is_train)\n",
    "\n",
    "        with timer(prefix='create ' + str(block) + ' '):\n",
    "            _df = func(input_df)\n",
    "        assert len(_df) == len(input_df), func.__name__\n",
    "        out_df = pd.concat([out_df, _df], axis=1)\n",
    "    return reduce_mem_usage(out_df)\n",
    "\n",
    "\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    for col in df.columns:\n",
    "        if verbose:\n",
    "            print(col)\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    if verbose:\n",
    "        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'\n",
    "              .format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = '../input/uspppm-debertv3large-5folds/uspppm_0'\n",
    "\n",
    "# トークナイザとモデルのロード\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "#tokenizer = DebertaV2TokenizerFast.from_pretrained(MODEL_NAME)\n",
    "model = AutoModel.from_pretrained(MODEL_NAME)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## testデータの読み込み\n",
    "_test_df = pd.read_csv(\"../input/us-patent-phrase-to-phrase-matching/test.csv\")\n",
    "titles = pd.read_csv('../input/cpc-codes/titles.csv')\n",
    "_test_df = _test_df.merge(titles, left_on='context', right_on='code')\n",
    "_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_test_df['input'] = _test_df['title']+' '+_test_df['anchor']\n",
    "_test_df['input2'] = _test_df[\"input\"] + \" \" + _test_df[\"target\"]\n",
    "\n",
    "max_length = 128\n",
    "sentence_vectors = []\n",
    "\n",
    "for n in range(len(_test_df)):\n",
    "    # 記事から文章を抜き出し、符号化を行う。\n",
    "    text = _test_df[\"input2\"][n]\n",
    "    encoding = tokenizer(\n",
    "        text, \n",
    "        max_length=max_length, \n",
    "        padding='max_length', \n",
    "        truncation=True, \n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    encoding = { k: v.cuda() for k, v in encoding.items() } \n",
    "    attention_mask = encoding['attention_mask']\n",
    "\n",
    "    # 文章ベクトルを計算\n",
    "    # BERTの最終層の出力を平均を計算する。（ただし、[PAD]は除く。）\n",
    "    with torch.no_grad():\n",
    "        output = model(**encoding)\n",
    "        last_hidden_state = output.last_hidden_state \n",
    "        averaged_hidden_state = \\\n",
    "            (last_hidden_state*attention_mask.unsqueeze(-1)).sum(1) \\\n",
    "            / attention_mask.sum(1, keepdim=True) \n",
    "\n",
    "    # 文章ベクトルとラベルを追加\n",
    "    sentence_vectors.append(averaged_hidden_state[0].cpu().numpy())\n",
    "\n",
    "sentence_vectors = np.vstack(sentence_vectors)\n",
    "sentence_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deberta_emb_ts = pd.DataFrame(sentence_vectors)\n",
    "deberta_emb_ts = deberta_emb_ts.add_prefix(\"deberta_v3_large_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deberta_emb_ts = pd.concat([_test_df[[\"id\"]], deberta_emb_ts],axis=1)\n",
    "test = pd.merge(test,deberta_emb_ts,on=\"id\", how=\"left\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocess_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 後処理用に新規でdfを起こしておく\n",
    "new_train = postprocess_df.drop(\"text\", axis=1)\n",
    "new_test = test.drop(\"text\", axis=1)\n",
    "\n",
    "new_test[\"pred\"] = final_prediction\n",
    "\n",
    "# 前処理（context）\n",
    "new_train[\"context2\"] = new_train[\"context\"].str[0]\n",
    "new_train[\"context3\"] = new_train[\"context\"].str[1:].astype(str)\n",
    "\n",
    "new_test[\"context2\"] = new_test[\"context\"].str[0]\n",
    "new_test[\"context3\"] = new_test[\"context\"].str[1:].astype(str)\n",
    "\n",
    "whole_df = pd.concat([new_train, new_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_blocks = [\n",
    "    *[ContinuousBlock(c) for c in [\n",
    "        \"pred\",\n",
    "    ]],\n",
    "    *[CountEncodingBlock(c, whole_df=whole_df) for c in [\n",
    "        \"context\",\n",
    "        \"context2\",\n",
    "        \"context3\"\n",
    "    ]],\n",
    "    *[LabelEncodingBlock(c, whole_df=whole_df) for c in [\n",
    "        \"context\"\n",
    "    ]],\n",
    "    *[StringLengthBlock(c) for c in [\n",
    "        \"anchor\",\n",
    "        \"target\",\n",
    "        \"context_text\"\n",
    "    ]],\n",
    "    *[WordCountBlock(c) for c in [\n",
    "        \"anchor\",\n",
    "        \"target\",\n",
    "        \"context_text\"\n",
    "    ]],\n",
    "    TfidfBlock(\"context_text\" ,whole_df=whole_df, decomposition=\"svd\", n_compose=150)\n",
    "    ]\n",
    "\n",
    "# 今回は残差が目的変数\n",
    "train_y = postprocess_df[\"res\"]\n",
    "train_x = to_feature(new_train, process_blocks, is_train=True)\n",
    "test_x = to_feature(new_test, process_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "\n",
    "def fit_lgbm(X, y, cv, params=None, verbose: int=50):\n",
    "    metric_func = mean_squared_error\n",
    "    \n",
    "    if params is None:\n",
    "        params = dict()\n",
    "        \n",
    "    models = []\n",
    "    \n",
    "    oof_pred = np.zeros_like(y, dtype=np.float)\n",
    "    \n",
    "    for i, (tr_idx, val_idx) in enumerate(cv):\n",
    "        x_train, y_train = X[tr_idx], y[tr_idx]\n",
    "        x_valid, y_valid = X[val_idx], y[val_idx]\n",
    "        \n",
    "        clf = lgb.LGBMRegressor(**params)\n",
    "        \n",
    "        with timer(prefix=\"fit_fold{}\".format(i+1)):\n",
    "            clf.fit(x_train, y_train,\n",
    "                   eval_set=[(x_valid,y_valid)],\n",
    "                   early_stopping_rounds=verbose,\n",
    "                   verbose=-1)\n",
    "        \n",
    "        pred_i = clf.predict(x_valid)\n",
    "        oof_pred[val_idx] = pred_i\n",
    "        models.append(clf)\n",
    "        \n",
    "        print(f'Fold {i} RMSE: {metric_func(y_valid, pred_i)**.5 :.4f}')\n",
    "    score = metric_func(y, oof_pred)**.5 \n",
    "    print('FINISHED | Whole RMSE: {:.4f}'.format(score))\n",
    "    return oof_pred, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "lgm_params = {  \n",
    "    \"n_estimators\": 20000,\n",
    "    \"objective\": 'rmse',\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"num_leaves\": 32,\n",
    "    \"random_state\": 71,\n",
    "    \"n_jobs\": -1,\n",
    "    \"importance_type\": \"gain\",\n",
    "    'colsample_bytree': 0.7,\n",
    "    \"max_depth\":5,\n",
    "    }\n",
    "\n",
    "postprocess_df['score_map'] = postprocess_df['score'].map({0.00: 0, 0.25: 1, 0.50: 2, 0.75: 3, 1.00: 4})\n",
    "encoder = LabelEncoder()\n",
    "postprocess_df['anchor_map'] = encoder.fit_transform(postprocess_df['anchor'])\n",
    "\n",
    "fold_lgbm = Fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=71)\n",
    "cv_lgbm = list(fold_lgbm.split(postprocess_df, postprocess_df['score_map']))\n",
    "\n",
    "oof_lgbm, models_lgbm = fit_lgbm(train_x.values, train_y, cv_lgbm , params=lgm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 追加後処理\n",
    "# https://www.kaggle.com/competitions/us-patent-phrase-to-phrase-matching/discussion/327288\n",
    "# 意味なかったので使用せず\n",
    "def update_label(pred):\n",
    "    if -0.01 < pred <= .01:\n",
    "        return .0\n",
    "    elif .24 <= pred <= .26:\n",
    "        return .25\n",
    "    elif .49 <= pred <= .51:\n",
    "        return .5\n",
    "    elif .74 <= pred <= .76:\n",
    "        return .75\n",
    "    elif .99 <= pred <= 1.01:\n",
    "        return 1.0\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 出力結果が補正値になるので、これを結果に当てはめる\n",
    "postprocess_df[\"res_oof\"] = oof_lgbm\n",
    "postprocess_df[\"pp_pred\"] = postprocess_df[\"res_oof\"] + postprocess_df[\"pred\"]\n",
    "\n",
    "\n",
    "before_pp = get_score(postprocess_df[\"score\"], postprocess_df[\"pred\"])\n",
    "after_pp = get_score(postprocess_df[\"score\"], postprocess_df[\"pp_pred\"])\n",
    "print(f\"before_pp：{round(before_pp,4)}\")\n",
    "print(f\"after_pp：{round(after_pp,4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,4))\n",
    "\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "sns.scatterplot(postprocess_df[\"score\"], postprocess_df[\"pred\"],ax=ax1)\n",
    "ax1.set_ylim(-0.1, 1.1)\n",
    "\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "sns.scatterplot(postprocess_df[\"score\"], postprocess_df[\"pp_pred\"],ax=ax2)\n",
    "ax2.set_ylim(-0.1, 1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_importance(models, feat_train_df):\n",
    "    \"\"\"\n",
    "    args:\n",
    "        models:\n",
    "            List of lightGBM models\n",
    "        feat_train_df:\n",
    "            学習時に使った DataFrame\n",
    "    \"\"\"\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    for i, model in enumerate(models):\n",
    "        _df = pd.DataFrame()\n",
    "        _df['feature_importance'] = model.feature_importances_\n",
    "        _df['column'] = feat_train_df.columns\n",
    "        _df['fold'] = i + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, _df], \n",
    "                                          axis=0, ignore_index=True)\n",
    "\n",
    "    order = feature_importance_df.groupby('column')\\\n",
    "        .sum()[['feature_importance']]\\\n",
    "        .sort_values('feature_importance', ascending=False).index[:50]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, max(6, len(order) * .25)))\n",
    "    sns.boxenplot(data=feature_importance_df, \n",
    "                  x='feature_importance', \n",
    "                  y='column', \n",
    "                  order=order, \n",
    "                  ax=ax, \n",
    "                  palette='viridis', \n",
    "                  orient='h')\n",
    "    ax.tick_params(axis='x', rotation=90)\n",
    "    ax.set_title('Importance')\n",
    "    ax.grid()\n",
    "    fig.tight_layout()\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = visualize_importance(models_lgbm, train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "sns.histplot(train_y, label='Train_y', ax=ax, color='black')\n",
    "sns.histplot(oof_lgbm, label='Out Of Fold', ax=ax, color='C1')\n",
    "ax.legend()\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prediction_pp = np.array([model.predict(test_x.values) for model in models_lgbm])\n",
    "final_prediction_pp = np.mean(final_prediction_pp, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_prediction = np.where(final_prediction < 0, 0, final_prediction)\n",
    "#final_prediction = np.where(final_prediction > 1, 1, final_prediction)\n",
    "submission['score'] = final_prediction + final_prediction_pp\n",
    "\n",
    "# post process2\n",
    "same_ids = test[test[\"anchor\"]==test[\"target\"]][\"id\"].tolist()\n",
    "if len(same_ids) > 0:\n",
    "    submission.loc[submission[\"id\"].isin(same_ids), \"score\"] = 1.0 # 同じphaseが入っているものは1に変換する\n",
    "    \n",
    "display(submission.head())\n",
    "submission[['id', 'score']].to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
