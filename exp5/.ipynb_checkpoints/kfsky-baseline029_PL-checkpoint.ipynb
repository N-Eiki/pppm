{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"colab":{"name":"kfsky-baseline029_PL.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","background_execution":"on","toc_visible":true},"accelerator":"GPU"},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"markdown","source":["# Start"],"metadata":{"id":"m7zwPKq6MzRs"}},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"id":"GKfS1UlkMv3T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## transformer をinstall\n","!pip uninstall -y transformers\n","!pip uninstall -y tokenizers\n","!pip install --quiet torch==1.9.1\n","!pip install --quiet transformers==4.16.2\n","!pip install --quiet tokenizers==0.11.6\n","!pip install --quiet sentencepiece\n","!pip install bitsandbytes-cuda112==0.26.0"],"metadata":{"id":"f8VWbPE5Mv3X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Config"],"metadata":{"id":"C6lypd0rM36v"}},{"cell_type":"code","source":["# ====================================================\n","# CFG\n","# ====================================================\n","\n","class CFG:\n","  name=\"bigpatent_pl\"\n","  max_len=512 # ★★★\n","  wandb=False\n","  competition=\"PPPM\"\n","  _wandb_kernel=\"kunishou\"\n","  debug=False\n","  apex=True\n","  print_freq=100\n","  num_workers=4\n","  model=\"google/bigbird-pegasus-large-bigpatent\"\n","  #model=\"funnel-transformer/xlarge\"\n","  scheduler=\"CosineAnnealingLR\"\n","  batch_scheduler=True\n","  num_cycles=0.5\n","  num_warmup_steps=50 # change\n","  epochs=5\n","  encoder_lr=2e-5 # change\n","  decoder_lr=2e-5 # change\n","  min_lr=1e-7\n","  eps=5e-6\n","  betas=(0.9, 0.999)\n","  #factor=0.2 # ReduceLROnPlateau\n","  #patience=4 # ReduceLROnPlateau\n","  #eps=1e-6 # ReduceLROnPlateau\n","  T_max=50 # CosineAnnealingLR\n","  #T_0=50 # CosineAnnealingWarmRestarts\n","  batch_size=16   # ★★★ https://www.kaggle.com/c/nbme-score-clinical-patient-notes/discussion/308298\n","  fc_dropout=0.2\n","  weight_decay=0.01\n","  target_size=1\n","  gradient_accumulation_steps=4\n","  max_grad_norm=1000\n","  seed=44\n","  n_fold=5\n","  trn_fold=[0, 1, 2, 3, 4]\n","  train=True\n","  wandb_key = \"\" # not good\n","\n","  # Colab Env\n","  upload_from_colab = True\n","  api_path = \"/content/drive/MyDrive/kaggle/kaggle.json\"\n","  drive_path = \"/content/drive/My Drive/uspppm/\"\n","  \n","  # Kaggle Env\n","  kaggle_dataset_path = None\n","    \n","if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.trn_fold = [0]"],"metadata":{"id":"ON1HugHLMv3Z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Import Module"],"metadata":{"id":"pc0660AjM7ED"}},{"cell_type":"code","source":["# ====================================================\n","# Library\n","# ====================================================\n","import os\n","import gc\n","import re\n","import ast\n","import sys\n","import copy\n","import json\n","import time\n","import math\n","import string\n","import pickle\n","import random\n","import joblib\n","import logging\n","import itertools\n","import datetime\n","import warnings\n","import shutil\n","warnings.filterwarnings(\"ignore\")\n","\n","import scipy as sp\n","import numpy as np\n","import pandas as pd\n","pd.set_option('display.max_rows', 500)\n","pd.set_option('display.max_columns', 500)\n","pd.set_option('display.width', 1000)\n","from tqdm.auto import tqdm\n","from sklearn.metrics import f1_score\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold, StratifiedGroupKFold\n","from sklearn.preprocessing import LabelEncoder\n","\n","import torch\n","import torch.nn as nn\n","from torch.nn import Parameter\n","import torch.nn.functional as F\n","from torch.optim import Adam, SGD, AdamW\n","from torch.utils.data import DataLoader, Dataset\n","from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n","\n","#!pip uninstall -y transformers\n","#!pip uninstall -y tokenizers\n","#pip install transformers==4.16.2\n","#!pip install tokenizers==0.11.0\n","\n","import tokenizers\n","import transformers\n","print(f\"torch.__version__: {torch.__version__}\")\n","print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n","print(f\"transformers.__version__: {transformers.__version__}\")\n","from transformers import AutoTokenizer, AutoModel, AutoConfig\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","%env TOKENIZERS_PARALLELISM=true\n","\n","import bitsandbytes as bnb\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"GXct7puPMv3a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# Utils\n","# ====================================================\n","\n","def get_score(y_true, y_pred):\n","  # 今回の評価指標\n","  # sp.stats.pearsonrでは tupleで(相関係数, p値)で返ってくるので[0]で値を取得する\n","  # https://www.st-hakky-blog.com/entry/2018/01/30/004659\n","  score = sp.stats.pearsonr(y_true, y_pred)[0]\n","  return score\n","\n","def seed_everything(seed=CFG.seed):\n","  random.seed(seed)\n","  os.environ[\"PYTHONHASHSEED\"] = str(seed) # ハッシュ生成のランダム化を無効\n","  np.random.seed(seed)\n","  torch.manual_seed(seed) # こっちだけでも一応CUDA側のseedも固定してくれる。複数GPUの場合はmanual_seed_all()\n","  torch.cuda.manual_seed(seed) \n","  torch.backends.cudnn.deterministic=True # 決定論的アルゴリズムを使用する\n","\n","seed_everything(CFG.seed)"],"metadata":{"id":"CrBP7FUIMv3c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["COLAB = \"google.colab\" in sys.modules"],"metadata":{"id":"ST3OClAfMv3e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Logger\n","class Logger:\n","  def __init__(self, path):\n","    self.general_logger = logging.getLogger(path)\n","    stream_handler = logging.StreamHandler()\n","    file_general_handler = logging.FileHandler(os.path.join(path, \"Experiment.log\"))\n","    if len(self.general_logger.handlers) ==0:\n","      self.general_logger.addHandler(stream_handler)\n","      self.general_logger.addHandler(file_general_handler)\n","      self.general_logger.setLevel(logging.INFO)\n","\n","  def info(self, message):\n","        # display time\n","        self.general_logger.info('[{}] - {}'.format(self.now_string(), message))\n","\n","  @staticmethod\n","  def now_string():\n","      return str(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))"],"metadata":{"id":"ZKPL1h5xMv3f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# colab環境での設定\n","if COLAB:\n","    #print(\"This environment is Google Colab\")\n","    \n","    # mount\n","    from google.colab import drive\n","    if not os.path.isdir(\"/content/drive\"):\n","        drive.mount('/content/drive') \n","        \n","    #os.chdir('/content/drive/My Drive/uspppm/notebook')\n","\n","    # import library\n","    ! pip install --quiet wandb\n","\n","    # use kaggle api (need kaggle token)\n","    f = open(CFG.api_path, 'r')\n","    json_data = json.load(f) \n","    os.environ[\"KAGGLE_USERNAME\"] = json_data[\"username\"]\n","    os.environ[\"KAGGLE_KEY\"] = json_data[\"key\"]\n","    \n","    # set dirs\n","    DRIVE = CFG.drive_path\n","    EXP = (CFG.name if CFG.name is not None \n","           else get(\"http://172.28.0.2:9000/api/sessions\").json()[0][\"name\"][:-6])\n","    INPUT = os.path.join(DRIVE, \"Input\")\n","    OUTPUT = os.path.join(DRIVE, \"Output\")\n","    # SUBMISSION = os.path.join(DRIVE, \"Submission\")\n","    OUTPUT_EXP = os.path.join(OUTPUT, EXP) \n","    EXP_MODEL = os.path.join(OUTPUT_EXP, \"model\")\n","    # EXP_FIG = os.path.join(OUTPUT_EXP, \"fig\")\n","    EXP_PREDS = os.path.join(OUTPUT_EXP, \"preds\")\n","    EXP_TOKENIZER = os.path.join(OUTPUT_EXP, \"tokenizer\") # change\n","\n","    # make dirs\n","    for d in [INPUT, EXP_MODEL, EXP_PREDS]:\n","        os.makedirs(d, exist_ok=True)\n","\n","    if not os.path.isfile(os.path.join(INPUT, \"train.csv\")):\n","        # load dataset\n","        ! kaggle competitions download -c us-patent-phrase-to-phrase-matching -p $INPUT\n","        # unzip need\n","    \n","    logger = Logger(OUTPUT_EXP)\n","    print(\"This environment is Google Colab\")\n","\n","else:\n","    print(\"This environment is Kaggle Kernel\")\n","    \n","    # set dirs\n","    INPUT = \"../input/us-patent-phrase-to-phrase-matching/\"\n","    EXP, OUTPUT, SUBMISSION = \"./\", \"./\", \"./\"\n","    EXP_MODEL = os.path.join(EXP, \"model\")\n","    # EXP_FIG = os.path.join(EXP, \"fig\")\n","    EXP_PREDS = os.path.join(EXP, \"preds\")\n","    EXP_TOKENIZER = os.path.join(OUTPUT_EXP, \"tokenizer\") # change\n","    \n","    # copy dirs\n","    if CFG.kaggle_dataset_path is not None:\n","        KD_MODEL = os.path.join(CFG.kaggle_dataset_path, \"model\")\n","        KD_EXP_PREDS = os.path.join(CFG.kaggle_dataset_path, \"preds\")\n","        shutil.copytree(KD_MODEL, EXP_MODEL)\n","        shutil.copytree(KD_EXP_PREDS, EXP_PREDS)\n","\n","    # make dirs\n","    for d in [EXP_MODEL, EXP_PREDS]:\n","        os.makedirs(d, exist_ok=True)\n","        \n","    # utils\n","    logger = Logger(OUTPUT_EXP)"],"metadata":{"id":"dDig989zMv3g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# wandb\n","# ====================================================\n","if CFG.wandb:\n","  import wandb\n","\n","  try:\n","    wandb.login(key=CFG.wandb_key)\n","    anory = None\n","  except:\n","    anory = \"must\"\n","    print(\"please check wandb key\")\n","\n","  def class2dict(f):\n","    return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))\n","\n","  run = wandb.init(project=\"PPPM\",\n","                   name=CFG.model,\n","                   config=class2dict(CFG),\n","                   group=CFG.model,\n","                   job_type=\"train\",\n","                   anonymous=anory)"],"metadata":{"id":"xqpkp6mxMv3i"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Loading"],"metadata":{"id":"xy9mAGtF8d9p"}},{"cell_type":"code","source":["# ====================================================\n","# Data Loading\n","# ====================================================\n","train = pd.read_csv('../input/us-patent-phrase-to-phrase-matching/train_pl2.csv') # ★★★\n","print(f\"train.shape: {train.shape}\")\n","display(train.head())"],"metadata":{"id":"UBPE10ANMv3j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# CPC Data\n","# 追加情報を記載する\n","# ====================================================\n","def get_cpc_texts():\n","  contexts = []\n","  patten = '[A-Z]\\d+'\n","\n","  for file_name in os.listdir(os.path.join(INPUT, 'CPCSchemeXML202105')):\n","    result = re.findall(patten, file_name)\n","    if result:\n","      contexts.append(result)\n","  \"\"\"\n","  入れ子リストをlistに戻す方法\n","  sum(list, [])\n","  \"\"\"\n","  contexts = sorted(set(sum(contexts, [])))\n","  results = {}\n","  for cpc in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'Y']:\n","    with open(os.path.join(INPUT, f'CPCTitleList202202/cpc-section-{cpc}_20220201.txt')) as f:\n","      s = f.read()\n","    pattern = f'{cpc}\\t\\t.+'\n","    result = re.findall(pattern, s)\n","    cpc_result = result[0].lstrip(pattern)\n","    for context in [c for c in contexts if c[0] == cpc]:\n","      pattern = f'{context}\\t\\t.+'\n","      result = re.findall(pattern, s)\n","      results[context] = cpc_result + \". \" + result[0].lstrip(pattern)\n","\n","  return results\n","\n","cpc_texts = get_cpc_texts()    \n","torch.save(cpc_texts, os.path.join(OUTPUT_EXP, \"cpc_texts.pth\"))\n","train['context_text'] = train['context'].map(cpc_texts)\n","display(train.head())"],"metadata":{"id":"c4abIf_RMv3k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# preprocess\n","# https://www.kaggle.com/competitions/us-patent-phrase-to-phrase-matching/discussion/315827\n","# ====================================================\n","\n","def omit_char(x):\n","  x = x.replace(\";\", \"\") # ; を削除\n","  x = x.replace(\"[\", \"\") # [] を削除\n","  x = x.replace(\"]\", \"\") # [] を削除\n","  x = x.lower() # すべて小文字に変換\n","  return x\n","\n","# 数字除外\n","train['anchor'].replace(\"dry coating composition1\", \"dry coating composition\", inplace=True)\n","\n","train['context_text'] = train['context_text'].map(omit_char)\n","\n","train['context_text'] = train['context_text'].replace(\"human necessities. griculture forestry animal husbandry hunting trapping fishing\", \n","                                                      \"human necessities. agriculture forestry animal husbandry hunting trapping fishing\")\n","\n","train['context_text'] = train['context_text'].str.replace(\"hemistry\", \"chemistry\")\n","\n","display(train.head())"],"metadata":{"id":"_8p8J_wCMv3k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# Create text\n","# ====================================================\n","train['text'] = train['anchor'] + '[SEP]' + train['target'] + '[SEP]'  + train['context_text']\n","\n","display(train.head())"],"metadata":{"id":"a30-o9OGMv3l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train['score_map'] = train['score'].map({0.00: 0, 0.25: 1, 0.50: 2, 0.75: 3, 1.00: 4})\n","encoder = LabelEncoder()\n","train['anchor_map'] = encoder.fit_transform(train['anchor'])"],"metadata":{"id":"4td2VKndDyfK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# CV split\n","# StratifiedGroupKFoldに変更\n","# ====================================================\n","\n","train_pl = train[train[\"id\"].isnull()].copy().reset_index()\n","train = train[~train[\"id\"].isnull()].copy()\n","\n","Fold = StratifiedGroupKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n","for n, (train_index, val_index) in enumerate(Fold.split(train, train['score_map'], groups=train[\"anchor_map\"])):\n","  train.loc[val_index, 'fold'] = int(n)\n","\n","for n, (train_index, val_index) in enumerate(Fold.split(train_pl, train_pl['score_map'], groups=train_pl[\"anchor_map\"])):\n","  train_pl.loc[val_index, 'fold'] = int(n)\n","\n","train['fold'] = train['fold'].astype(int)\n","train_pl['fold'] = train_pl['fold'].astype(int)\n","\n","display(train.groupby('fold').size())"],"metadata":{"id":"Cyzg-yJQMv3l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["display(train_pl.groupby('fold').size())"],"metadata":{"id":"G5j-x_VFFWLc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 別々に5foldに分割したtrain,train_plをconcat\n","\n","train0 = train.copy() \n","train = pd.concat([train,train_pl],axis=0,ignore_index=True)\n","train"],"metadata":{"id":"9wVAS1BKFc18"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train.shape"],"metadata":{"id":"3uASun3SF8G7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if CFG.debug:\n","    display(train.groupby('fold').size())\n","    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n","    display(train.groupby('fold').size())"],"metadata":{"id":"_LwpljEmMv3m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# tokenizer\n","# ====================================================\n","\n","# tokenizerに略語を追加していく\n","abbreviations = ['h2o', 'conh2', 'vegfr2', 'her2']\n","\n","tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n","tokenizer.add_tokens(abbreviations, special_tokens=False)\n","tokenizer.save_pretrained(EXP_TOKENIZER)\n","CFG.tokenizer = tokenizer"],"metadata":{"id":"ZByzMMlLMv3m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# Define max_len\n","# ====================================================\n","lengths_dict = {}\n","\n","lengths = []\n","tk0 = tqdm(cpc_texts.values(), total=len(cpc_texts))\n","for text in tk0:\n","  length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n","  lengths.append(length)\n","lengths_dict['context_text'] = lengths\n","\n","for text_col in ['anchor', 'target']:\n","    lengths = []\n","    tk0 = tqdm(train[text_col].fillna(\"\").values, total=len(train))\n","    for text in tk0:\n","        length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n","        lengths.append(length)\n","    lengths_dict[text_col] = lengths\n","    \n","CFG.max_len = max(lengths_dict['anchor']) + max(lengths_dict['target'])\\\n","                + max(lengths_dict['context_text']) + 4 # CLS + SEP + SEP + SEP\n","logger.info(f\"model: {CFG.model}\")\n","logger.info(f\"max_len: {CFG.max_len}\")"],"metadata":{"id":"1zqIZCneMv3n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# Dataset\n","# ====================================================\n","\n","def prepare_input(cfg, text):\n","  inputs = cfg.tokenizer(text,\n","                         add_special_tokens=True,\n","                         max_length=cfg.max_len,\n","                         padding=\"max_length\",\n","                         return_offsets_mapping=False)\n","  for k, v in inputs.items():\n","    inputs[k] = torch.tensor(v, dtype=torch.long)\n","\n","  return inputs\n","\n","\n","class TrainDataset(Dataset):\n","  def __init__(self, cfg, df):\n","    self.cfg = cfg\n","    self.texts = df[\"text\"].values\n","    self.labels = df[\"score\"].values\n","\n","  def __len__(self):\n","    return len(self.labels)\n","\n","  def __getitem__(self, item):\n","    # item は何個とりだすかの設定\n","    inputs = prepare_input(self.cfg, self.texts[item])\n","    label = torch.tensor(self.labels[item], dtype=torch.float)\n","    return inputs, label"],"metadata":{"id":"K6HkKxDDMv3o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Model"],"metadata":{"id":"dMUQge-iPOTa"}},{"cell_type":"code","source":["# ====================================================\n","# Model\n","# ====================================================\n","class CustomModel(nn.Module):\n","    def __init__(self, cfg, config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","        if config_path is None:\n","            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n","        else:\n","            self.config = torch.load(config_path)\n","        if pretrained:\n","            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n","            token_embeddings_size = len(CFG.tokenizer)\n","            self.model.resize_token_embeddings(token_embeddings_size)\n","        else:\n","            self.model = AutoModel.from_config(self.config)\n","\n","        self.fc_dropout1 = nn.Dropout(0.1)\n","        self.fc_dropout2 = nn.Dropout(0.2)\n","        self.fc_dropout3 = nn.Dropout(0.3)\n","        self.fc_dropout4 = nn.Dropout(0.4)\n","        self.fc_dropout5 = nn.Dropout(0.5)\n","\n","        self.fc = nn.Linear(self.config.hidden_size, self.cfg.target_size)\n","        self._init_weights(self.fc)\n","        # これがいわゆるattention pool\n","        # https://www.kaggle.com/competitions/us-patent-phrase-to-phrase-matching/discussion/324330\n","        self.attention = nn.Sequential(\n","            nn.Linear(self.config.hidden_size, self.config.hidden_size),\n","            nn.LayerNorm(self.config.hidden_size),\n","            nn.GELU(),\n","            nn.Linear(self.config.hidden_size, 1),\n","            nn.Softmax(dim=1)\n","        )\n","        self._init_weights(self.attention)\n","        \n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            #module.weight.data.normal_(mean=0.0,std=0.02) # ★★★ bigpatent用\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            #module.weight.data.normal_(mean=0.0, std=0.02) # ★★★ bigpatent用\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","        \n","    def feature(self, inputs):\n","        outputs = self.model(**inputs)\n","        last_hidden_states = outputs[0]\n","        # feature = torch.mean(last_hidden_states, 1)\n","        weights = self.attention(last_hidden_states)\n","        feature = torch.sum(weights * last_hidden_states, dim=1)\n","        return feature\n","\n","    def forward(self, inputs):\n","        feature = self.feature(inputs)\n","\n","        feature1 = self.fc_dropout1(feature)\n","        feature2 = self.fc_dropout2(feature)\n","        feature3 = self.fc_dropout3(feature)\n","        feature4 = self.fc_dropout4(feature)\n","        feature5 = self.fc_dropout5(feature)\n","\n","        feature_all = (feature1+feature2+feature3+feature4+feature5)/5\n","        output = self.fc(feature_all)\n","        \n","        return output"],"metadata":{"id":"qM3kSq0PMv3p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Helper"],"metadata":{"id":"An3TQ61WPRnP"}},{"cell_type":"code","source":["# ====================================================\n","# Helper functions\n","# ====================================================\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))"],"metadata":{"id":"99zfWbUTMv3p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n","    model.train()\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    global_step = 0\n","    for step, (inputs, labels) in enumerate(train_loader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            y_preds = model(inputs)\n","        loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","            global_step += 1\n","            if CFG.batch_scheduler:\n","                scheduler.step()\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n","            print('Epoch: [{0}][{1}/{2}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  'Grad: {grad_norm:.4f}  '\n","                  'LR: {lr:.8f}  '\n","                  .format(epoch+1, step, len(train_loader), \n","                          remain=timeSince(start, float(step+1)/len(train_loader)),\n","                          loss=losses,\n","                          grad_norm=grad_norm,\n","                          lr=scheduler.get_lr()[0]))\n","        if CFG.wandb:\n","            wandb.log({f\"[fold{fold}] loss\": losses.val,\n","                       f\"[fold{fold}] lr\": scheduler.get_lr()[0]})\n","    return losses.avg\n","\n","\n","def valid_fn(valid_loader, model, criterion, device):\n","    losses = AverageMeter()\n","    model.eval()\n","    preds = []\n","    start = end = time.time()\n","    for step, (inputs, labels) in enumerate(valid_loader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","        loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        preds.append(y_preds.sigmoid().to('cpu').numpy())\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n","            print('EVAL: [{0}/{1}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  .format(step, len(valid_loader),\n","                          loss=losses,\n","                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n","    predictions = np.concatenate(preds)\n","    predictions = np.concatenate(predictions)\n","    return losses.avg, predictions\n","\n","\n","def inference_fn(test_loader, model, device):\n","    preds = []\n","    model.eval()\n","    model.to(device)\n","    tk0 = tqdm(test_loader, total=len(test_loader))\n","    for inputs in tk0:\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","        preds.append(y_preds.sigmoid().to('cpu').numpy())\n","    predictions = np.concatenate(preds)\n","    return predictions"],"metadata":{"id":"1uZ64YLjMv3q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Train"],"metadata":{"id":"Fv-WtjJIPGGm"}},{"cell_type":"code","source":["# ====================================================\n","# train loop\n","# ====================================================\n","\n","def train_loop(folds,folds0, fold):\n","  \"\"\"\n","  folds: df\n","  fold: fold\n","  \"\"\"\n","  logger.info(f\"========== fold: {fold} training ==========\")\n","\n","  # ====================================================\n","  # loader\n","  # ====================================================\n","  train_folds = folds[folds['fold']!=fold].reset_index(drop=True)\n","  valid_folds = folds0[folds0['fold']==fold].reset_index(drop=True)\n","  valid_labels = valid_folds[\"score\"].values\n","\n","  train_dataset = TrainDataset(CFG, train_folds)\n","  valid_dataset = TrainDataset(CFG, valid_folds)\n","\n","  train_loader = DataLoader(train_dataset,\n","                            batch_size = CFG.batch_size,\n","                            shuffle=True,\n","                            num_workers=CFG.num_workers,\n","                            pin_memory=True,\n","                            drop_last=True\n","                            )\n","  valid_loader = DataLoader(valid_dataset,\n","                            batch_size=CFG.batch_size,\n","                            shuffle=False,\n","                            num_workers=CFG.num_workers, \n","                            pin_memory=True, \n","                            drop_last=False\n","                            )\n","  # ====================================================\n","  # model\n","  # ====================================================\n","  model = CustomModel(CFG, config_path=None, pretrained=True)\n","  torch.save(model.config, os.path.join(OUTPUT_EXP, 'config.pth'))\n","  model.to(device)\n","\n","  # ====================================================\n","  # optimizer\n","  # ====================================================\n","\n","  def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n","    param_optimizer = list(model.named_parameters())\n","    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","    optimizer_parameters = [\n","        {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n","          'lr': encoder_lr, 'weight_decay': weight_decay},\n","        {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n","          'lr': encoder_lr, 'weight_decay': 0.0},\n","        {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n","          'lr': decoder_lr, 'weight_decay': 0.0}\n","    ]\n","    return optimizer_parameters\n","\n","  optimizer_parameters = get_optimizer_params(model,\n","                                                encoder_lr=CFG.encoder_lr, \n","                                                decoder_lr=CFG.decoder_lr,\n","                                                weight_decay=CFG.weight_decay)\n","  optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n","  #optimizer = bnb.optim.Adam8bit(optimizer_parameters, lr=CFG.encoder_lr, betas=CFG.betas)　★★★\n","\n","  # ====================================================\n","  # scheduler\n","  # ====================================================\n","  def get_scheduler(cfg, optimizer, num_train_steps):\n","    if cfg.scheduler == 'linear':\n","        scheduler = get_linear_schedule_with_warmup(\n","            optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n","        )\n","    elif cfg.scheduler == 'cosine':\n","        scheduler = get_cosine_schedule_with_warmup(\n","            optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n","        )\n","    elif cfg.scheduler=='ReduceLROnPlateau':\n","        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=CFG.factor, patience=CFG.patience, verbose=True, eps=CFG.eps)\n","    elif cfg.scheduler=='CosineAnnealingLR':\n","        scheduler = CosineAnnealingLR(optimizer, T_max=CFG.T_max, eta_min=CFG.min_lr, last_epoch=-1)\n","    elif cfg.scheduler=='CosineAnnealingWarmRestarts':\n","        scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=CFG.T_0, T_mult=1, eta_min=CFG.min_lr, last_epoch=-1)\n","    return scheduler\n","\n","  num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n","  scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n","\n","  # ====================================================\n","  # loop\n","  # ====================================================\n","  criterion = nn.BCEWithLogitsLoss(reduction=\"mean\")\n","  best_score = 0.\n","\n","  for epoch in range(CFG.epochs):\n","    start_time = time.time()\n","    # train\n","    avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n","    # eval\n","    avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n","    # scoring\n","    score = get_score(valid_labels, predictions)\n","    elapsed = time.time() - start_time\n","\n","    logger.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n","    logger.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n","\n","    if CFG.wandb:\n","      wandb.log({f\"[fold{fold}] epoch\": epoch+1, \n","                 f\"[fold{fold}] avg_train_loss\": avg_loss, \n","                 f\"[fold{fold}] avg_val_loss\": avg_val_loss,\n","                 f\"[fold{fold}] score\": score})\n","      \n","    if best_score < score:\n","      best_score = score\n","      logger.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n","      torch.save({'model': model.state_dict(),\n","                  'predictions': predictions},\n","                 os.path.join(EXP_MODEL,f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\"))\n","\n","  predictions = torch.load(os.path.join(EXP_MODEL,f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\"), \n","                             map_location=torch.device('cpu'))['predictions']\n","  valid_folds['pred'] = predictions\n","\n","  torch.cuda.empty_cache()\n","  gc.collect()\n","    \n","  return valid_folds"],"metadata":{"id":"SICI8Z6CMv3s"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Main"],"metadata":{"id":"rqyeIeNqPJ3L"}},{"cell_type":"code","source":["if __name__ == '__main__':\n","    \n","    def get_result(oof_df):\n","        labels = oof_df['score'].values\n","        preds = oof_df['pred'].values\n","        score = get_score(labels, preds)\n","        logger.info(f'Score: {score:<.4f}')\n","    \n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for fold in range(CFG.n_fold):\n","            if fold in CFG.trn_fold:\n","                _oof_df = train_loop(train,train0, fold) # ★★★変更点\n","                oof_df = pd.concat([oof_df, _oof_df])\n","                logger.info(f\"========== fold: {fold} result ==========\")\n","                get_result(_oof_df)\n","        oof_df = oof_df.reset_index(drop=True)\n","        logger.info(f\"========== CV ==========\")\n","        get_result(oof_df)\n","        oof_df.to_pickle(os.path.join(EXP_PREDS, 'oof_df.pkl'))\n","        \n","    if CFG.wandb:\n","        wandb.finish()"],"metadata":{"id":"Vv9pTbCDMJCy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"rj3DCps3MJBT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"9F-AuGVTmG-u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"sHnczi2JQUvK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.cuda.empty_cache()\n","gc.collect()"],"metadata":{"id":"izg37NiWhVrq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# upload output folder to kaggle dataset\n","if CFG.upload_from_colab:\n","    from kaggle.api.kaggle_api_extended import KaggleApi\n","\n","    def dataset_create_new(dataset_name, upload_dir):\n","        dataset_metadata = {}\n","        dataset_metadata['id'] = f'{os.environ[\"KAGGLE_USERNAME\"]}/{dataset_name}'\n","        dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n","        dataset_metadata['title'] = dataset_name\n","        with open(os.path.join(upload_dir, 'dataset-metadata.json'), 'w') as f:\n","            json.dump(dataset_metadata, f, indent=4)\n","        api = KaggleApi()\n","        api.authenticate()\n","        api.dataset_create_new(folder=upload_dir, convert_to_csv=False, dir_mode='tar')\n","\n","    dataset_create_new(dataset_name=CFG.competition + \"-\" + CFG.name, upload_dir=OUTPUT_EXP)"],"metadata":{"id":"prulv4kjMv3u"},"execution_count":null,"outputs":[]}]}