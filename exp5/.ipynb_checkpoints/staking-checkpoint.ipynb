{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39460f4e",
   "metadata": {
    "papermill": {
     "duration": 0.025228,
     "end_time": "2022-04-25T02:02:17.165392",
     "exception": false,
     "start_time": "2022-04-25T02:02:17.140164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "local = True\n",
    "data_transform = False\n",
    "# transform_method = \"standardscaler\"  \n",
    "# transform_method = \"rankgauss\"\n",
    "\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn import datasets\n",
    "from sklearn import model_selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "565ed15b-cdb0-4196-a9f3-4b6100d9cb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Requirement already satisfied: torch==1.9.0+cu111 in /opt/conda/lib/python3.7/site-packages (1.9.0+cu111)\n",
      "Requirement already satisfied: torchvision==0.10.0+cu111 in /opt/conda/lib/python3.7/site-packages (0.10.0+cu111)\n",
      "Requirement already satisfied: torchaudio===0.9.0 in /opt/conda/lib/python3.7/site-packages (0.9.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.9.0+cu111) (4.1.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision==0.10.0+cu111) (1.21.5)\n",
      "Requirement already satisfied: pillow>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision==0.10.0+cu111) (9.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio===0.9.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "# !pip install torch==1.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5eb5c0c-b453-4f3e-938d-5863c4b052e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.9.0+cu111'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b252b70d",
   "metadata": {
    "id": "e460cbb5",
    "papermill": {
     "duration": 0.023676,
     "end_time": "2022-04-25T02:02:17.213513",
     "exception": false,
     "start_time": "2022-04-25T02:02:17.189837",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# About this notebook\n",
    "- Deberta-v3-large starter code\n",
    "- pip wheels is [here](https://www.kaggle.com/code/yasufuminakama/pppm-pip-wheels)\n",
    "- Training notebook is [here](https://www.kaggle.com/code/yasufuminakama/pppm-deberta-v3-large-baseline-w-w-b-train)\n",
    "\n",
    "If this notebook is helpful, feel free to upvote :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc900225-7a36-4a81-a084-41ee6c5a7c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Directory settings\n",
    "# ====================================================\n",
    "exp_names = [\n",
    "    # 'albert-base-v2',\n",
    "    # \"roberta-base\",\n",
    "    # \"microsoft-mpnet-base\",\n",
    "    \"funnel-transformer-large512\",\n",
    "    \"deberta-v3-base\",\n",
    "    \"microsoft-deberta-large\",\n",
    "    \"bert-base-uncased\",\n",
    "    \"microsoft-mpnet-base-attention2\",\n",
    "    # \"microsoft-deberta-large-simple\",\n",
    "    # \"AI-Growth-Lab-PatentSBERTa\",\n",
    "    # \"bert-large-uncased-whole-word-masking-finetuned-squad\", \n",
    "    \n",
    "    # \"AI-Growth-Lab-PatentSBERTa-transformer\",\n",
    "    \n",
    "    # \"xlnet-base-cased\",\n",
    "             \n",
    "            ]\n",
    "\n",
    "# stacking_exp_name = f\"4model_stacking_1dcnn_{transform_method}\"\n",
    "stacking_exp_name = f\"{len(exp_names)}model_stacking/tabnet/\"\n",
    "import os\n",
    "if local:\n",
    "    INPUT_DIR = '../../data/us-patent-phrase-to-phrase-matching/'\n",
    "    \n",
    "    OUTPUT_DIR = f\"./output/{stacking_exp_name}/\"\n",
    "else:\n",
    "    INPUT_DIR = '../input/us-patent-phrase-to-phrase-matching/'\n",
    "    OUTPUT_DIR = './'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8396c0-a1fb-4954-b272-705631163362",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe18acb7-e7c7-4111-8365-4ef0c2afd771",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logger(filename=OUTPUT_DIR+'train'):\n",
    "    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=f\"{filename}.log\")\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = get_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4683d738",
   "metadata": {
    "id": "1d0c4430",
    "papermill": {
     "duration": 0.024634,
     "end_time": "2022-04-25T02:02:17.375954",
     "exception": false,
     "start_time": "2022-04-25T02:02:17.351320",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4608e79b",
   "metadata": {
    "id": "48dd82bb",
    "papermill": {
     "duration": 0.033972,
     "end_time": "2022-04-25T02:02:17.434586",
     "exception": false,
     "start_time": "2022-04-25T02:02:17.400614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# CFG\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    \n",
    "    #######実行ごとに変更必要の可能性あり\n",
    "    # tree_path = \"./output/6model_stacking_lgbm_xgb/\"\n",
    "    EXP_NAMES = exp_names\n",
    "    models=[\n",
    "        # 'albert-base-v2',\n",
    "        #     \"roberta-base\",\n",
    "            # \"microsoft/mpnet-base\",\n",
    "            \"funnel-transformer-large512\",\n",
    "            \"microsoft/deberta-v3-base\",\n",
    "            \"microsoft/deberta-v3-large\",\n",
    "            \"bert-base-uncased\",\n",
    "        \"microsoft/mpnet-base\",\n",
    "        # 'microsoft/deberta-large',\n",
    "        # \"AI-Growth-Lab/PatentSBERTa\",\n",
    "        # \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
    "        \n",
    "\n",
    "        # \"AI-Growth-Lab/PatentSBERTa\",\n",
    "        # \"xlnet-base-cased\"\n",
    "           ]\n",
    "    folder_names = [\n",
    "        # 'albert-base-v2',\n",
    "        #             \"roberta-base\",\n",
    "                   #  \"mpnetbase\",\n",
    "                   #  \"funnellarge512fold4\",\n",
    "                   # \"debertabase\",\n",
    "                   # \"debertalarge\",\n",
    "                    # \"bertbase\"\n",
    "                  ]\n",
    "    \n",
    "    \n",
    "    max_lens = [\n",
    "        133, 133, 133,\n",
    "         125, 125,175,125,125,\n",
    "    ]\n",
    "    pass_folds_flg = False\n",
    "    pass_folds  = [\n",
    "        -1,\n",
    "        -1, -1, -1\n",
    "    ]\n",
    "    \n",
    "    #######\n",
    "    paths = []\n",
    "    config_paths = []\n",
    "    model_paths = []\n",
    "    for EXP_NAME in EXP_NAMES:\n",
    "        if local:\n",
    "            path=f\"../exp4/output/{EXP_NAME}/\"\n",
    "            config_path=path+'config.pth'\n",
    "            model_path=f'../exp4/output/{EXP_NAME}/'\n",
    "            cpc_path = f\"{INPUT_DIR}/cpc_texts.pth\"\n",
    "        else:\n",
    "            path=f\"../input/{folder_name}/{EXP_NAME}/\"\n",
    "            config_path=path+'config.pth'\n",
    "            model_path=f'../input/{folder_name}/'\n",
    "            cpc_path = \"../input/pppm-deberta-v3-large-baseline-w-w-b-train/cpc_texts.pth\"\n",
    "        paths.append(path)\n",
    "        config_paths.append(config_path)\n",
    "        model_paths.append(model_path)\n",
    "        \n",
    "    num_workers=4\n",
    "    hidden_states = []\n",
    "    for model in models:\n",
    "        if \"small\" in model:\n",
    "            hidden_state  = 512\n",
    "        elif \"base\" in model:\n",
    "            hidden_state  = 768\n",
    "        elif \"large\" in model:\n",
    "            hidden_state  = 1024\n",
    "        elif \"xlarge\" in model:\n",
    "            hidden_state =  1536\n",
    "        hidden_states.append(hidden_state)\n",
    "    \n",
    "    batch_size=32\n",
    "    fc_dropout=0.2\n",
    "    target_size=1\n",
    "    max_len=133\n",
    "    seed=42\n",
    "    n_fold=4\n",
    "    trn_fold=[i for i in range(n_fold)]\n",
    "    pass_fold = []\n",
    "#     torch.load(CFG.model_path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17e8fa9",
   "metadata": {
    "id": "f2ed8ef2",
    "papermill": {
     "duration": 0.025102,
     "end_time": "2022-04-25T02:02:17.534162",
     "exception": false,
     "start_time": "2022-04-25T02:02:17.509060",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d3d33fb",
   "metadata": {
    "executionInfo": {
     "elapsed": 20123,
     "status": "ok",
     "timestamp": 1644920080956,
     "user": {
      "displayName": "Yasufumi Nakama",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17486303986134302670"
     },
     "user_tz": -540
    },
    "id": "35916341",
    "outputId": "06fa0ab8-a380-4f54-a98d-b7015b79d9e2",
    "papermill": {
     "duration": 27.447063,
     "end_time": "2022-04-25T02:02:45.006149",
     "exception": false,
     "start_time": "2022-04-25T02:02:17.559086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.__version__: 1.9.0+cu111\n",
      "tokenizers.__version__: 0.11.6\n",
      "transformers.__version__: 4.17.0\n",
      "env: TOKENIZERS_PARALLELISM=true\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "import ast\n",
    "import sys\n",
    "import copy\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import shutil\n",
    "import string\n",
    "import pickle\n",
    "import random\n",
    "import joblib\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "import torch\n",
    "print(f\"torch.__version__: {torch.__version__}\")\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "if not local:\n",
    "    os.system('pip uninstall -y transformers')\n",
    "    os.system('pip uninstall -y tokenizers')\n",
    "    os.system('python -m pip install --no-index --find-links=../input/pppm-pip-wheels-dataset transformers')\n",
    "    os.system('python -m pip install --no-index --find-links=../input/pppm-pip-wheels-dataset tokenizers')\n",
    "import tokenizers\n",
    "import transformers\n",
    "print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n",
    "print(f\"transformers.__version__: {transformers.__version__}\")\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "%env TOKENIZERS_PARALLELISM=true\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d95bd71-7a90-4f76-9a0f-6ba41f08e06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from copy import deepcopy as dp\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn.modules.loss import _WeightedLoss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d07ff1",
   "metadata": {
    "id": "fd586614",
    "papermill": {
     "duration": 0.028595,
     "end_time": "2022-04-25T02:02:45.065141",
     "exception": false,
     "start_time": "2022-04-25T02:02:45.036546",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "686c8cb9",
   "metadata": {
    "id": "d5c0ccc6",
    "papermill": {
     "duration": 0.042377,
     "end_time": "2022-04-25T02:02:45.136354",
     "exception": false,
     "start_time": "2022-04-25T02:02:45.093977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Utils\n",
    "# ====================================================\n",
    "def get_score(y_true, y_pred):\n",
    "    score = sp.stats.pearsonr(y_true.reshape(-1), y_pred.reshape(-1))[0]\n",
    "    return score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ec4f5c",
   "metadata": {
    "papermill": {
     "duration": 0.028469,
     "end_time": "2022-04-25T02:02:45.193745",
     "exception": false,
     "start_time": "2022-04-25T02:02:45.165276",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# OOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bc19b30",
   "metadata": {
    "papermill": {
     "duration": 0.136189,
     "end_time": "2022-04-25T02:02:45.358748",
     "exception": false,
     "start_time": "2022-04-25T02:02:45.222559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Score: 0.8485\n",
      "CV Score: 0.8422\n",
      "CV Score: 0.8574\n",
      "CV Score: 0.8072\n",
      "CV Score: 0.8276\n"
     ]
    }
   ],
   "source": [
    "# oof_df = pd.read_pickle(CFG.path+'oof_df.pkl')\n",
    "# labels = oof_df['score'].values\n",
    "# preds = oof_df['pred'].values\n",
    "# score = get_score(labels, preds)\n",
    "# LOGGER.info(f'CV Score: {score:<.4f}')\n",
    "oof_dfs = pd.DataFrame()\n",
    "for path in CFG.paths:\n",
    "    oof_file = [f for f in os.listdir(path) if \"oof_df.pkl\" in f][0]\n",
    "    oof_df = pd.read_pickle(path+oof_file)\n",
    "    labels = oof_df['score'].values\n",
    "    preds = oof_df[[\"id\",'pred']]\n",
    "    score = get_score(labels, preds[\"pred\"].values)\n",
    "    LOGGER.info(f'CV Score: {score:<.4f}')\n",
    "    oof_dfs = pd.concat([oof_dfs, oof_df[[\"pred\"]]],axis=1)\n",
    "# oof_dfs.columns = [c+str(i) for i, c in enumerate(oof_dfs.columns)]\n",
    "# oof_dfs[\"id\"] = preds[\"id\"?]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4453934d-0586-48a4-8fa8-b3df4c151cc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cce07dd2-1f88-47b7-8980-56911a83ec8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# xgb_df = pd.read_csv(CFG.tree_path+\"oof_xgb_df.csv\")[[\"score\"]]\n",
    "# lgbm_df = pd.read_csv(CFG.tree_path+\"oof_lgbm_df.csv\")[[\"score\"]]\n",
    "# oof_dfs = pd.concat([oof_dfs, xgb_df, lgbm_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cbc6bfe",
   "metadata": {
    "papermill": {
     "duration": 0.062291,
     "end_time": "2022-04-25T02:02:45.475346",
     "exception": false,
     "start_time": "2022-04-25T02:02:45.413055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred0</th>\n",
       "      <th>pred1</th>\n",
       "      <th>pred2</th>\n",
       "      <th>pred3</th>\n",
       "      <th>pred4</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000880</td>\n",
       "      <td>0.003149</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.003350</td>\n",
       "      <td>0.009445</td>\n",
       "      <td>54c1e3b9184cb5b6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.236394</td>\n",
       "      <td>0.247720</td>\n",
       "      <td>0.241680</td>\n",
       "      <td>0.315298</td>\n",
       "      <td>0.285991</td>\n",
       "      <td>ef2d4c2e6bbb208d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.428095</td>\n",
       "      <td>0.501632</td>\n",
       "      <td>0.503771</td>\n",
       "      <td>0.448882</td>\n",
       "      <td>0.504931</td>\n",
       "      <td>4c3f2750e7540ab7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.482324</td>\n",
       "      <td>0.536995</td>\n",
       "      <td>0.479786</td>\n",
       "      <td>0.491129</td>\n",
       "      <td>0.490094</td>\n",
       "      <td>bfd7270f57530991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.273144</td>\n",
       "      <td>0.073328</td>\n",
       "      <td>0.005082</td>\n",
       "      <td>0.483306</td>\n",
       "      <td>0.472632</td>\n",
       "      <td>cc96541d4987b399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pred0     pred1     pred2     pred3     pred4                id\n",
       "0  0.000880  0.003149  0.000215  0.003350  0.009445  54c1e3b9184cb5b6\n",
       "1  0.236394  0.247720  0.241680  0.315298  0.285991  ef2d4c2e6bbb208d\n",
       "2  0.428095  0.501632  0.503771  0.448882  0.504931  4c3f2750e7540ab7\n",
       "3  0.482324  0.536995  0.479786  0.491129  0.490094  bfd7270f57530991\n",
       "4  0.273144  0.073328  0.005082  0.483306  0.472632  cc96541d4987b399"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_dfs.columns = [c+str(i) for i, c in enumerate(oof_dfs.columns)]\n",
    "oof_dfs[\"id\"] = preds[\"id\"]\n",
    "oof_dfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bc2921e-c181-44e2-8888-d8d2d50b6eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof_dfs[oof_dfs.columns[:-1]].mean(axis=1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797a487a",
   "metadata": {
    "id": "cb3d8e1e",
    "papermill": {
     "duration": 0.032565,
     "end_time": "2022-04-25T02:02:45.542692",
     "exception": false,
     "start_time": "2022-04-25T02:02:45.510127",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20c0c7f9",
   "metadata": {
    "executionInfo": {
     "elapsed": 2627,
     "status": "ok",
     "timestamp": 1644920084001,
     "user": {
      "displayName": "Yasufumi Nakama",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17486303986134302670"
     },
     "user_tz": -540
    },
    "id": "bef012d3",
    "outputId": "d4d60dbc-510c-4f34-8d64-dd1d88c4808c",
    "papermill": {
     "duration": 0.067187,
     "end_time": "2022-04-25T02:02:45.643625",
     "exception": false,
     "start_time": "2022-04-25T02:02:45.576438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ====================================================\n",
    "# # Data Loading\n",
    "# # ====================================================\n",
    "# test = pd.read_csv(INPUT_DIR+'test.csv')\n",
    "# submission = pd.read_csv(INPUT_DIR+'sample_submission.csv')\n",
    "# print(f\"test.shape: {test.shape}\")\n",
    "# print(f\"submission.shape: {submission.shape}\")\n",
    "# display(test.head())\n",
    "# display(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe0d7d5e",
   "metadata": {
    "papermill": {
     "duration": 0.056389,
     "end_time": "2022-04-25T02:02:45.732708",
     "exception": false,
     "start_time": "2022-04-25T02:02:45.676319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ====================================================\n",
    "# # CPC Data\n",
    "# # ====================================================\n",
    "# cpc_texts = torch.load(CFG.cpc_path)\n",
    "# test['context_text'] = test['context'].map(cpc_texts)\n",
    "# display(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b535693",
   "metadata": {
    "papermill": {
     "duration": 0.048277,
     "end_time": "2022-04-25T02:02:45.813270",
     "exception": false,
     "start_time": "2022-04-25T02:02:45.764993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\n",
    "# display(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77973fe5",
   "metadata": {
    "id": "918a28aa",
    "papermill": {
     "duration": 0.032365,
     "end_time": "2022-04-25T02:02:45.879432",
     "exception": false,
     "start_time": "2022-04-25T02:02:45.847067",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d1a9015",
   "metadata": {
    "papermill": {
     "duration": 0.098292,
     "end_time": "2022-04-25T02:02:46.011077",
     "exception": false,
     "start_time": "2022-04-25T02:02:45.912785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ====================================================\n",
    "# # tokenizer\n",
    "# # ====================================================\n",
    "# # CFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')\n",
    "# # CFG.tokenizer = AutoTokenizer.from_pretrained(\"../input/roberta-large-tokenizer/tokenizer/\", use_fast=False)\n",
    "\n",
    "# CFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+\"tokenizer/\",use_fast=False)\n",
    "# # CFG.path+'tokenizer/'\n",
    "# # AutoTokenizer.from_pretrained('../input/robertalarge/roberta-large/2022-04-23-20-31-47tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2fd7ccab",
   "metadata": {
    "papermill": {
     "duration": 0.038287,
     "end_time": "2022-04-25T02:02:46.082450",
     "exception": false,
     "start_time": "2022-04-25T02:02:46.044163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# AutoTokenizer.from_pretrained('../input/robertalarge/roberta-large/2022-04-23-20-31-47tokenizer', use_fast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc35f544",
   "metadata": {
    "id": "14da40cf",
    "papermill": {
     "duration": 0.031196,
     "end_time": "2022-04-25T02:02:46.145129",
     "exception": false,
     "start_time": "2022-04-25T02:02:46.113933",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4fad9a45",
   "metadata": {
    "id": "9f791a19",
    "papermill": {
     "duration": 0.040757,
     "end_time": "2022-04-25T02:02:46.217480",
     "exception": false,
     "start_time": "2022-04-25T02:02:46.176723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ====================================================\n",
    "# # Dataset\n",
    "# # ====================================================\n",
    "# def prepare_input(cfg, text):\n",
    "#     inputs = cfg.tokenizer(text,\n",
    "#                            add_special_tokens=True,\n",
    "#                            max_length=cfg.max_len,\n",
    "#                            padding=\"max_length\",\n",
    "#                            return_offsets_mapping=False)\n",
    "#     for k, v in inputs.items():\n",
    "#         inputs[k] = torch.tensor(v, dtype=torch.long)\n",
    "#     return inputs\n",
    "\n",
    "\n",
    "# class TestDataset(Dataset):\n",
    "#     def __init__(self, cfg, df):\n",
    "#         self.cfg = cfg\n",
    "#         self.texts = df['text'].values\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.texts)\n",
    "\n",
    "#     def __getitem__(self, item):\n",
    "#         inputs = prepare_input(self.cfg, self.texts[item])\n",
    "#         return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789fdaae",
   "metadata": {
    "id": "e04d6363",
    "papermill": {
     "duration": 0.031567,
     "end_time": "2022-04-25T02:02:46.280695",
     "exception": false,
     "start_time": "2022-04-25T02:02:46.249128",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d25f0409",
   "metadata": {
    "id": "4c5bab44",
    "papermill": {
     "duration": 0.048817,
     "end_time": "2022-04-25T02:02:46.361092",
     "exception": false,
     "start_time": "2022-04-25T02:02:46.312275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ====================================================\n",
    "# # Model\n",
    "# # ====================================================\n",
    "# class CustomModel(nn.Module):\n",
    "#     def __init__(self, cfg, config_path=None, pretrained=False):\n",
    "#         super().__init__()\n",
    "#         self.cfg = cfg\n",
    "#         if config_path is None:\n",
    "#             self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n",
    "#         else:\n",
    "#             self.config = torch.load(config_path)\n",
    "#         if pretrained:\n",
    "#             self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n",
    "#         else:\n",
    "#             self.model = AutoModel.from_config(self.config)\n",
    "#         self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n",
    "#         self.fc = nn.Linear(self.config.hidden_size, self.cfg.target_size)\n",
    "#         self._init_weights(self.fc)\n",
    "#         self.attention = nn.Sequential(\n",
    "#             nn.Linear(self.config.hidden_size, cfg.hidden_state),\n",
    "#             nn.Tanh(),\n",
    "#             nn.Linear(cfg.hidden_state, 1),\n",
    "#             nn.Softmax(dim=1)\n",
    "#         )\n",
    "#         self._init_weights(self.attention)\n",
    "        \n",
    "#     def _init_weights(self, module):\n",
    "#         if isinstance(module, nn.Linear):\n",
    "#             module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "#             if module.bias is not None:\n",
    "#                 module.bias.data.zero_()\n",
    "#         elif isinstance(module, nn.Embedding):\n",
    "#             module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "#             if module.padding_idx is not None:\n",
    "#                 module.weight.data[module.padding_idx].zero_()\n",
    "#         elif isinstance(module, nn.LayerNorm):\n",
    "#             module.bias.data.zero_()\n",
    "#             module.weight.data.fill_(1.0)\n",
    "        \n",
    "#     def feature(self, inputs):\n",
    "#         outputs = self.model(**inputs)\n",
    "#         last_hidden_states = outputs[0]\n",
    "#         # feature = torch.mean(last_hidden_states, 1)\n",
    "#         weights = self.attention(last_hidden_states)\n",
    "#         feature = torch.sum(weights * last_hidden_states, dim=1)\n",
    "#         return feature\n",
    "\n",
    "#     def forward(self, inputs):\n",
    "#         feature = self.feature(inputs)\n",
    "#         output = self.fc(self.fc_dropout(feature))\n",
    "#         return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef93248",
   "metadata": {
    "id": "deee9675",
    "papermill": {
     "duration": 0.031361,
     "end_time": "2022-04-25T02:02:46.424301",
     "exception": false,
     "start_time": "2022-04-25T02:02:46.392940",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00d0a1b8",
   "metadata": {
    "papermill": {
     "duration": 0.040764,
     "end_time": "2022-04-25T02:02:46.496721",
     "exception": false,
     "start_time": "2022-04-25T02:02:46.455957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ====================================================\n",
    "# # inference\n",
    "# # ====================================================\n",
    "# def inference_fn(test_loader, model, device):\n",
    "#     preds = []\n",
    "#     model.eval()\n",
    "#     model.to(device)\n",
    "#     tk0 = tqdm(test_loader, total=len(test_loader))\n",
    "#     for inputs in tk0:\n",
    "#         for k, v in inputs.items():\n",
    "#             inputs[k] = v.to(device)\n",
    "#         with torch.no_grad():\n",
    "#             y_preds = model(inputs)\n",
    "#         preds.append(y_preds.sigmoid().to('cpu').numpy())\n",
    "#     predictions = np.concatenate(preds)\n",
    "#     return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab3a7fc6-3bfb-40af-b209-cd2b3065a834",
   "metadata": {
    "papermill": {
     "duration": 126.145328,
     "end_time": "2022-04-25T02:04:52.675061",
     "exception": false,
     "start_time": "2022-04-25T02:02:46.529733",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# all_predictions = pd.DataFrame()\n",
    "# for exp_num in range(len(CFG.EXP_NAMES)):\n",
    "#     test_dataset = TestDataset(CFG, test)\n",
    "#     test_loader = DataLoader(test_dataset,\n",
    "#                              batch_size=CFG.batch_size,\n",
    "#                              shuffle=False,\n",
    "#                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "#     predictions = []\n",
    "#     for fold in CFG.trn_fold:\n",
    "#         if fold in CFG.pass_fold:\n",
    "#             continue\n",
    "#         model = CustomModel(CFG, config_path=CFG.config_paths[exp_num], pretrained=False)\n",
    "#         if local:\n",
    "#             state = torch.load(CFG.model_paths[exp_num]+f\"{CFG.models[exp_num].replace('/', '-')}_fold{fold}_best.pth\",\n",
    "#                            map_location=torch.device('cpu'))\n",
    "#         else:\n",
    "#             state = torch.load(CFG.model_paths[exp_num]+f\"{CFG.EXP_NAMES[exp_name]}/{CFG.models[exp_name].replace('/', '-')}_fold{fold}_best.pth\",\n",
    "#                            map_location=torch.device('cpu'))\n",
    "#         model.load_state_dict(state['model'])\n",
    "#         prediction = inference_fn(test_loader, model, device)\n",
    "#         predictions.append(prediction)\n",
    "#         del model, state, prediction; gc.collect()\n",
    "#         torch.cuda.empty_cache()\n",
    "#     predictions = np.mean(predictions, axis=0)\n",
    "#     all_predictions = pd.concat([all_predictions,pd.DataFrame(predictions)], axis=1)\n",
    "\n",
    "# # pd.concat([pd.DataFrame(predictions),pd.DataFrame(predictions)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edf90c5-604b-4ac7-befe-28b31ae6ab97",
   "metadata": {},
   "source": [
    "# 1DCNN data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ce518e-f568-4363-8065-fe5db15ce751",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41b536ce-71b8-43be-b9e1-d438ff12f82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class oneDCNN(nn.Module):\n",
    "#https://www.kaggle.com/code/lililycai/1dcnn-pytorch-moa\n",
    "        def __init__(self, num_features, num_targets, hidden_size, cfg=None):\n",
    "            self. model_name=\"1dcnn\"\n",
    "            super(oneDCNN, self).__init__()\n",
    "            hidden_size = 1024\n",
    "            cha_1 = 256\n",
    "            cha_2 = 512\n",
    "            cha_3 = 512\n",
    "\n",
    "            cha_1_reshape = int(hidden_size/cha_1)\n",
    "            cha_po_1 = int(hidden_size/cha_1/2)\n",
    "            cha_po_2 = int(hidden_size/cha_1/2/2) * cha_3\n",
    "\n",
    "            self.cha_1 = cha_1\n",
    "            self.cha_2 = cha_2\n",
    "            self.cha_3 = cha_3\n",
    "            self.cha_1_reshape = cha_1_reshape\n",
    "            self.cha_po_1 = cha_po_1\n",
    "            self.cha_po_2 = cha_po_2\n",
    "\n",
    "            self.batch_norm1 = nn.BatchNorm1d(num_features)\n",
    "            self.dropout1 = nn.Dropout(0.1)\n",
    "            self.dense1 = nn.utils.weight_norm(nn.Linear(num_features, hidden_size))\n",
    "\n",
    "            self.batch_norm_c1 = nn.BatchNorm1d(cha_1)\n",
    "            self.dropout_c1 = nn.Dropout(0.1)\n",
    "            self.conv1 = nn.utils.weight_norm(nn.Conv1d(cha_1,cha_2, kernel_size = 5, stride = 1, padding=2,  bias=False),dim=None)\n",
    "\n",
    "            self.ave_po_c1 = nn.AdaptiveAvgPool1d(output_size = cha_po_1)\n",
    "\n",
    "            self.batch_norm_c2 = nn.BatchNorm1d(cha_2)\n",
    "            self.dropout_c2 = nn.Dropout(0.1)\n",
    "            self.conv2 = nn.utils.weight_norm(nn.Conv1d(cha_2,cha_2, kernel_size = 3, stride = 1, padding=1, bias=True),dim=None)\n",
    "\n",
    "            self.batch_norm_c2_1 = nn.BatchNorm1d(cha_2)\n",
    "            self.dropout_c2_1 = nn.Dropout(0.3)\n",
    "            self.conv2_1 = nn.utils.weight_norm(nn.Conv1d(cha_2,cha_2, kernel_size = 3, stride = 1, padding=1, bias=True),dim=None)\n",
    "\n",
    "            self.batch_norm_c2_2 = nn.BatchNorm1d(cha_2)\n",
    "            self.dropout_c2_2 = nn.Dropout(0.2)\n",
    "            self.conv2_2 = nn.utils.weight_norm(nn.Conv1d(cha_2,cha_3, kernel_size = 5, stride = 1, padding=2, bias=True),dim=None)\n",
    "\n",
    "            self.max_po_c2 = nn.MaxPool1d(kernel_size=4, stride=2, padding=1)\n",
    "\n",
    "            self.flt = nn.Flatten()\n",
    "\n",
    "            self.batch_norm3 = nn.BatchNorm1d(cha_po_2)\n",
    "            self.dropout3 = nn.Dropout(0.2)\n",
    "            self.dense3 = nn.utils.weight_norm(nn.Linear(cha_po_2, num_targets))\n",
    "\n",
    "        def forward(self, x):\n",
    "\n",
    "            x = self.batch_norm1(x)\n",
    "            x = self.dropout1(x)\n",
    "            x = F.celu(self.dense1(x), alpha=0.06)\n",
    "\n",
    "            x = x.reshape(x.shape[0],self.cha_1,\n",
    "                          self.cha_1_reshape)\n",
    "\n",
    "            x = self.batch_norm_c1(x)\n",
    "            x = self.dropout_c1(x)\n",
    "            x = F.relu(self.conv1(x))\n",
    "\n",
    "            x = self.ave_po_c1(x)\n",
    "\n",
    "            x = self.batch_norm_c2(x)\n",
    "            x = self.dropout_c2(x)\n",
    "            x = F.relu(self.conv2(x))\n",
    "            x_s = x\n",
    "\n",
    "            x = self.batch_norm_c2_1(x)\n",
    "            x = self.dropout_c2_1(x)\n",
    "            x = F.relu(self.conv2_1(x))\n",
    "\n",
    "            x = self.batch_norm_c2_2(x)\n",
    "            x = self.dropout_c2_2(x)\n",
    "            x = F.relu(self.conv2_2(x))\n",
    "            x =  x * x_s\n",
    "\n",
    "            x = self.max_po_c2(x)\n",
    "\n",
    "            x = self.flt(x)\n",
    "\n",
    "            x = self.batch_norm3(x)\n",
    "            x = self.dropout3(x)\n",
    "            x = self.dense3(x)\n",
    "\n",
    "            return x\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8f2ed33-a8b6-4c95-90cc-c6eba5c8a88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackingDataset(Dataset):\n",
    "    def __init__(self, df, features, labels=None, model_name=None):\n",
    "        self.df = df[features].values\n",
    "        if model_name == \"2dcnn\":\n",
    "            # [N, Models, Labels, Channel] -> [N, Channel, Models, Labels]\n",
    "            self.df = self.df.reshape(-1, len(features), 1, 1)\n",
    "            self.df = self.df.transpose(0,3,1,2)\n",
    "\n",
    "        self.labels = labels.values\n",
    "        \n",
    "    def __len__(self, ):\n",
    "        return len(self.df)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        inputs =  torch.FloatTensor(self.df[item]).float()\n",
    "        \n",
    "        if self.labels is None:\n",
    "            return inputs\n",
    "        labels = torch.tensor(self.labels[item]).float()\n",
    "        return inputs, labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1de090ce-2a99-4af6-9b4d-e2d6be02e76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class twoDCNN(nn.Module):\n",
    "#     def __init__(self, num_features, num_targets, hidden_size):\n",
    "#         self.model_name = \"2dcnn\"\n",
    "#         self.num_features = num_features\n",
    "#         self.num_targets = num_targets\n",
    "#         super(twoDCNN, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(3, 1), bias=False)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "#         self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(2, 1), bias=False)\n",
    "#         self.relu2 = nn.ReLU()\n",
    "        \n",
    "#         self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(2, 1), bias=False)\n",
    "#         self.relu3 = nn.ReLU()\n",
    "#         self.conv4 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 1), bias=False)\n",
    "#         self.relu4 = nn.ReLU()\n",
    "        \n",
    "#         self.conv5 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(2, 1), bias=False)\n",
    "#         self.relu5 = nn.ReLU()\n",
    "#         self.conv6 = nn.Conv2d(in_channels=128, out_channels=1024, kernel_size=(1, 1), bias=False)\n",
    "#         self.relu6 = nn.ReLU()\n",
    "            \n",
    "#         self.flatten = nn.Flatten()\n",
    "#         self.fc1 = nn.Linear(in_features=1024, out_features=512)\n",
    "#         self.relu3 = nn.ReLU()\n",
    "#         self.fc2 = nn.Linear(in_features=512, out_features=num_targets)\n",
    "        \n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.relu1(x)\n",
    "#         x = self.conv2(x)\n",
    "#         x = self.relu2(x)\n",
    "        \n",
    "#         x = self.conv3(x)\n",
    "#         x = self.relu3(x)\n",
    "#         x = self.conv4(x)\n",
    "#         x = self.relu4(x)\n",
    "        \n",
    "#         x = self.conv5(x)\n",
    "#         x = self.relu5(x)\n",
    "#         x = self.conv6(x)\n",
    "#         x = self.relu6(x)\n",
    "\n",
    "#         x = self.flatten(x)\n",
    "#         x = self.fc1(x)\n",
    "#         x = self.relu3(x)\n",
    "#         x = self.fc2(x)\n",
    "#         return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56be473d-deba-414e-bdcc-5411f48c8e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class twoDCNN(nn.Module):\n",
    "#     def __init__(self, num_features, num_targets, hidden_size, cfg):\n",
    "#         self.model_name = \"2dcnn\"\n",
    "#         self.num_features = num_features\n",
    "#         self.num_targets = num_targets\n",
    "#         super(twoDCNN, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(3, 1), bias=False)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "#         self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(2, 1), bias=False)\n",
    "#         self.relu2 = nn.ReLU()\n",
    "        \n",
    "#         # self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(2, 1), bias=False)\n",
    "#         # self.relu3 = nn.ReLU()\n",
    "#         # self.conv4 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 1), bias=False)\n",
    "#         # self.relu4 = nn.ReLU()\n",
    "        \n",
    "# #         self.conv5 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(2, 1), bias=False)\n",
    "# #         self.relu5 = nn.ReLU()\n",
    "# #         self.conv6 = nn.Conv2d(in_channels=128, out_channels=1024, kernel_size=(1, 1), bias=False)\n",
    "# #         self.relu6 = nn.ReLU()\n",
    "            \n",
    "#         self.flatten = nn.Flatten()\n",
    "#         self.fc1 = nn.Linear(in_features=80, out_features=512)\n",
    "#         # self.fc1 = nn.Linear(in_features=80, out_features=512)\n",
    "#         self.relu3 = nn.ReLU()\n",
    "#         self.fc2 = nn.Linear(in_features=512, out_features=num_targets)\n",
    "        \n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.relu1(x)\n",
    "#         x = self.conv2(x)\n",
    "#         x = self.relu2(x)\n",
    "        \n",
    "# #         x = self.conv3(x)\n",
    "# #         x = self.relu3(x)\n",
    "# #         x = self.conv4(x)\n",
    "# #         x = self.relu4(x)\n",
    "        \n",
    "# #         x = self.conv5(x)\n",
    "# #         x = self.relu5(x)\n",
    "# #         x = self.conv6(x)\n",
    "# #         x = self.relu6(x)\n",
    "\n",
    "#         x = self.flatten(x)\n",
    "#         x = self.fc1(x)\n",
    "#         x = self.relu3(x)\n",
    "#         x = self.fc2(x)\n",
    "#         return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d23a770b-3abd-4b6e-b02d-b4a707676f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class twoDCNN(nn.Module):#input5\n",
    "    def __init__(self, num_features, num_targets, hidden_size, cfg):\n",
    "        self.model_name = \"2dcnn\"\n",
    "        self.num_features = num_features\n",
    "        self.num_targets = num_targets\n",
    "        super(twoDCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(3, 1), bias=False)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(2, 1), bias=False)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        # self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(2, 1), bias=False)\n",
    "        # self.relu3 = nn.ReLU()\n",
    "        # self.conv4 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 1), bias=False)\n",
    "        # self.relu4 = nn.ReLU()\n",
    "        \n",
    "#         self.conv5 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(2, 1), bias=False)\n",
    "#         self.relu5 = nn.ReLU()\n",
    "#         self.conv6 = nn.Conv2d(in_channels=128, out_channels=1024, kernel_size=(1, 1), bias=False)\n",
    "#         self.relu6 = nn.ReLU()\n",
    "            \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(in_features=32, out_features=512)\n",
    "        # self.fc1 = nn.Linear(in_features=80, out_features=512)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(in_features=512, out_features=num_targets)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        \n",
    "#         x = self.conv3(x)\n",
    "#         x = self.relu3(x)\n",
    "#         x = self.conv4(x)\n",
    "#         x = self.relu4(x)\n",
    "        \n",
    "#         x = self.conv5(x)\n",
    "#         x = self.relu5(x)\n",
    "#         x = self.conv6(x)\n",
    "#         x = self.relu6(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e9325e36-6b64-42ab-91c2-adb4b90db434",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackingMLP(nn.Module):\n",
    "    def __init__(self, num_features, num_targets, hidden_size, cfg):\n",
    "        super().__init__()\n",
    "        self.model_name = \"mlp\"\n",
    "        cfg.num_features = num_features\n",
    "        cfg.hidden_size = hidden_size\n",
    "    \n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.BatchNorm1d((num_features)),\n",
    "            nn.Dropout(cfg.dropout),\n",
    "            nn.utils.weight_norm(nn.Linear((cfg.num_features), cfg.hidden_size)),\n",
    "            nn.PReLU(),\n",
    "\n",
    "            \n",
    "            nn.BatchNorm1d(cfg.hidden_size),\n",
    "            nn.Dropout(cfg.dropout),\n",
    "            nn.utils.weight_norm(nn.Linear(cfg.hidden_size, cfg.hidden_size)),\n",
    "            nn.PReLU(),\n",
    "\n",
    "                        \n",
    "            nn.BatchNorm1d(cfg.hidden_size),\n",
    "            nn.Dropout(cfg.dropout),\n",
    "            nn.utils.weight_norm(nn.Linear(cfg.hidden_size, num_targets)),\n",
    "\n",
    "        )\n",
    "        \n",
    "        self.shallow_mlp = nn.Sequential(\n",
    "        \n",
    "                          nn.Linear((cfg.num_features), cfg.hidden_size),\n",
    "                          nn.BatchNorm1d(cfg.hidden_size),\n",
    "                          nn.Dropout(cfg.dropout),\n",
    "                          nn.PReLU(),\n",
    "                          nn.Linear(cfg.hidden_size, cfg.hidden_size),\n",
    "                          nn.BatchNorm1d(cfg.hidden_size),\n",
    "                          nn.Dropout(cfg.dropout),\n",
    "                          nn.PReLU(),\n",
    "                          nn.Linear(cfg.hidden_size, num_targets),\n",
    "                          )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # if \"shallow\" in  stacking_exp_name:\n",
    "        x = self.shallow_mlp(x)\n",
    "        # else:\n",
    "        #     x = self.mlp(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6cca6e86-dabb-4da9-8d48-241b8eced4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.path.append(\"../../\")\n",
    "# from models.graphconv import GraphConv\n",
    "# !python -m pip install --upgrade pip setuptools\n",
    "# !pip uninstall torch -y\n",
    "# !pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric\n",
    "# !pip install torch -f https://pytorch-geometric.com/whl/torch-1.11.0+cu102.html\n",
    "\n",
    "# tg.GraphConv\n",
    "# a = torch.randn(3, 4).to_sparse_csr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "456fe646-c098-4c49-bec6-69c938cc0467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn.functional as F\n",
    "# from torch_geometric.nn import GCNConv\n",
    "\n",
    "# class GCN(nn.Module):\n",
    "#     def __init__(self, num_features, num_targets, hidden_size, cfg):\n",
    "#         self.model_name=\"gcn\"\n",
    "#         self.num_features = num_features\n",
    "#         self.num_targets = num_targets\n",
    "#         super().__init__()\n",
    "        \n",
    "#         self.gc1 = GCNConv(num_features, 16)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "#         self.gc2= GCNConv(num_features, 16)\n",
    "#         self.relu2= nn.ReLU()\n",
    "#         self.gc3= GCNConv(num_features, 16)\n",
    "#         self.relu3= nn.ReLU()\n",
    "#         self.gc4= GCNConv(num_features, 16)\n",
    "#         self.relu4= nn.ReLU()\n",
    "#         self.fc1 = nn.Linear(3296, 2048)\n",
    "#         self.relu5 = nn.ReLU()\n",
    "#         self.fc2 = nn.Linear(2048, num_targets)\n",
    "        \n",
    "#         adj_mat = torch.ones(num_targets, num_targets) / num_targets\n",
    "#         self.A = adj_mat.float().to(device)\n",
    "#         # else:\n",
    "#         #     adj_mat = (1 - torch.eye(n_classes, n_classes)) / (n_classes - 1) \n",
    "#         # self.register_buffer(\"A\", adj_mat.float())\n",
    "#     def forward(self, x):\n",
    "#         x = x.unsqueeze(1)\n",
    "#         x = self.relu1(self.gc1(x, self.A[None, ...]))\n",
    "#         x = self.relu2(self.gc2(x))\n",
    "#         x = self.relu3(self.gc3(x))\n",
    "#         x = self.relu4(self.gc4(x))\n",
    "#         x = self.relu5(self.fc1(x))\n",
    "#         x = self.fc2(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2715622a-087d-461d-87c5-15ea9ffb9384",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! pip install --verbose --no-cache-dir torch-scatter\n",
    "# ! pip install --verbose --no-cache-dir torch-sparse\n",
    "# ! pip install --verbose --no-cache-dir torch-cluster\n",
    "# ! pip install --verbose --no-cache-dir torch-spline-conv (optional)\n",
    "# ! pip install torch-geometric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3994cbab-44d4-4dfd-af6d-40131ff62cfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import typing as tp\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"Stacked Dense layers\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, n_features_list: tp.List[int], use_tail_as_out: bool=False,\n",
    "        drop_rate: float=0.0, use_bn: bool=False, use_wn: bool=False,\n",
    "        activ:str=\"relu\", block_name: str=\"LBAD\"\n",
    "    ):\n",
    "        \"\"\"\"\"\"\n",
    "        super(MLP, self).__init__()\n",
    "        n_layers = len(n_features_list) - 1\n",
    "        block_class = {\n",
    "            \"LBAD\": LBAD, \"BDLA\": BDLA, \"LABD\": LABD}[block_name]\n",
    "        layers = []\n",
    "        for i in range(n_layers):\n",
    "            in_feats, out_feats = n_features_list[i: i + 2]\n",
    "            if i == n_layers - 1 and use_tail_as_out:\n",
    "                if block_name in [\"BDLA\"]:\n",
    "                    layer = block_class(in_feats, out_feats, drop_rate, use_bn,  use_wn, \"identity\")\n",
    "                else:\n",
    "                    layer = nn.Linear(in_feats, out_feats)\n",
    "                    if use_wn:\n",
    "                        layer = nn.utils.weight_norm(layer)\n",
    "            else:\n",
    "                layer = block_class(in_feats, out_feats, drop_rate, use_bn,  use_wn, activ)\n",
    "            layers.append(layer)\n",
    "                \n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\"\"\"\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "class CNNStacking1d(nn.Module):\n",
    "    \"\"\"1D-CNN for Stacking.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, n_models: int,\n",
    "        n_channels_list: tp.List[int], use_bias: bool=False,\n",
    "        kwargs_head: tp.Dict={},\n",
    "    ):\n",
    "        \"\"\"\"\"\"\n",
    "        super(CNNStacking1d, self).__init__()\n",
    "        self.n_conv_layers = len(n_channels_list) - 1\n",
    "        for i in range(self.n_conv_layers):\n",
    "            in_ch = n_channels_list[i]\n",
    "            out_ch = n_channels_list[i + 1]\n",
    "            layer = nn.Sequential(\n",
    "                nn.Conv1d(\n",
    "                    in_ch, out_ch, kernel_size=3, stride=1, padding=0, bias=use_bias),\n",
    "                # nn.BatchNorm1d(out_ch),\n",
    "                nn.ReLU(inplace=True))\n",
    "            setattr(self, \"conv{}\".format(i + 1), layer)\n",
    "        \n",
    "        kwargs_head[\"n_features_list\"][0] = (n_models - 2 * self.n_conv_layers) * n_channels_list[-1]\n",
    "        self.head = MLP(**kwargs_head)\n",
    "    \n",
    "    def forward(self, x: torch.FloatTensor) -> torch.Tensor:\n",
    "        \"\"\"\"\"\"\n",
    "        bs = x.shape[0]\n",
    "        h = x  # shape: (bs, n_classes, n_models)\n",
    "        for i in range(self.n_conv_layers):\n",
    "            h = getattr(self, \"conv{}\".format(i + 1))(h)\n",
    "            \n",
    "        h = torch.reshape(h, (bs, -1))\n",
    "        h = self.head(h)\n",
    "        return h\n",
    "    \n",
    "    \n",
    "    \n",
    "def get_activation(activ_name: str=\"relu\"):\n",
    "    \"\"\"\"\"\"\n",
    "    act_dict = {\n",
    "        \"relu\": nn.ReLU(),\n",
    "        \"tanh\": nn.Tanh(),\n",
    "        \"sigmoid\": nn.Sigmoid(),\n",
    "        \"identity\": nn.Identity()}\n",
    "    if activ_name in act_dict:\n",
    "        return act_dict[activ_name]\n",
    "    elif re.match(r\"^htanh\\_\\d{4}$\", activ_name):\n",
    "        bound = int(activ_name[-4:]) / 1000\n",
    "        return nn.Hardtanh(-bound, bound)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "class LBAD(nn.Module):\n",
    "    \"\"\"Linear (-> BN) -> Activation (-> Dropout)\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, in_features: int, out_features: int, drop_rate: float=0.0,\n",
    "        use_bn: bool=False, use_wn: bool=False, activ: str=\"relu\"\n",
    "    ):\n",
    "        \"\"\"\"\"\"\n",
    "        super(LBAD, self).__init__()\n",
    "        layers = [nn.Linear(in_features, out_features)]\n",
    "        if use_wn:\n",
    "            layers[0] = nn.utils.weight_norm(layers[0])\n",
    "        \n",
    "        if use_bn:\n",
    "            layers.append(nn.BatchNorm1d(out_features))\n",
    "        \n",
    "        layers.append(get_activation(activ))\n",
    "        \n",
    "        if drop_rate > 0:\n",
    "            layers.append(nn.Dropout(drop_rate))\n",
    "        \n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\"\"\"\n",
    "        return self.layers(x)\n",
    "    \n",
    "    \n",
    "class BDLA(nn.Module):\n",
    "    \"\"\"(BN -> Dropout ->) Linear -> Activation\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, in_features: int, out_features: int, drop_rate: float=0.0,\n",
    "        use_bn: bool=False, use_wn: bool=False, activ: str=\"relu\"\n",
    "    ):\n",
    "        \"\"\"\"\"\"\n",
    "        super(BDLA, self).__init__()\n",
    "        layers = []\n",
    "        if use_bn:\n",
    "            layers.append(nn.BatchNorm1d(in_features))\n",
    "            \n",
    "        if drop_rate > 0:\n",
    "            layers.append(nn.Dropout(drop_rate))\n",
    "        \n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        if use_wn:\n",
    "            layers[-1] = nn.utils.weight_norm(layers[-1])\n",
    "            \n",
    "        layers.append(get_activation(activ))\n",
    "        \n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\"\"\"\n",
    "        return self.layers(x)\n",
    "    \n",
    "\n",
    "class LABD(nn.Module):\n",
    "    \"\"\"Linear -> Activation (-> BN -> Dropout) \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, in_features: int, out_features: int, drop_rate: float=0.0,\n",
    "        use_bn: bool=False, use_wn: bool=False, activ: str=\"relu\"\n",
    "    ):\n",
    "        \"\"\"\"\"\"\n",
    "        super(LABD, self).__init__()\n",
    "        layers = [nn.Linear(in_features, out_features), get_activation(activ)]\n",
    "        \n",
    "        if use_wn:\n",
    "            layers[0] = nn.utils.weight_norm(layers[0])\n",
    "        \n",
    "        if use_bn:\n",
    "            layers.append(nn.BatchNorm1d(out_features))\n",
    "        \n",
    "        if drop_rate > 0:\n",
    "            layers.append(nn.Dropout(drop_rate))\n",
    "        \n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\"\"\"\n",
    "        return self.layers(x)\n",
    "# # for GCNs\n",
    "def vector_wise_matmul(X: torch.Tensor, W: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    See input matrixes X as bags of vectors, and multiply corresponding weight matrices by vector.\n",
    "    \n",
    "    Args:\n",
    "        X: Input Tensor, shape: (batch_size, **n_vectors**, in_features)\n",
    "        W: Weight Tensor, shape: (**n_vectors**, out_features, in_features)\n",
    "    \"\"\"\n",
    "\n",
    "    X = torch.transpose(X, 0, 1)  # shape: (n_vectors, batch_size, in_features)\n",
    "    W = torch.transpose(W, 1, 2)  # shape: (n_vectors, in_features, out_features)\n",
    "    H = torch.matmul(X, W)        # shape: (n_vectors, batch_size, out_features)\n",
    "    H = torch.transpose(H, 0, 1)  # shape: (batch_size, n_vectors, out_features)\n",
    "    \n",
    "    return H\n",
    "\n",
    "\n",
    "def vector_wise_shared_matmul(X: torch.Tensor, W: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    See input matrixes X as bags of vectors, and multiply **shared** weight matrices.\n",
    "    \n",
    "    Args:\n",
    "        X: Input Tensor, shape: (batch_size, **n_vectors**, in_features)\n",
    "        W: Weight Tensor, shape: (out_features, in_features)\n",
    "    \"\"\"\n",
    "    # W = torch.transpose(W, 0, 1)  # shape: (in_features, out_features)\n",
    "    # H = torch.matmul(X, W)        # shape: (batch_size, n_vectors, out_features)\n",
    "    \n",
    "    H = nn.functional.linear(X, W)  # shape: (batch_size, n_vectors, out_features)\n",
    "    \n",
    "    return H\n",
    "def _calculate_fan_in_and_fan_out_for_vwl(tensor) -> tp.Tuple[int]:\n",
    "    \"\"\"\n",
    "    Input tensor: (n_vectors, out_features, in_features) or (out_features, in_features)\n",
    "    \"\"\"\n",
    "    dimensions = tensor.dim()\n",
    "    if dimensions < 2:\n",
    "        raise ValueError(\"Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\")\n",
    "\n",
    "    fan_in = tensor.size(-1)\n",
    "    fan_out = tensor.size(-2)\n",
    "\n",
    "    return fan_in, fan_out\n",
    "    \n",
    "\n",
    "def _calculate_correct_fan_for_vwl(tensor, mode) -> int:\n",
    "    \"\"\"\"\"\"\n",
    "    mode = mode.lower()\n",
    "    valid_modes = ['fan_in', 'fan_out']\n",
    "    if mode not in valid_modes:\n",
    "        raise ValueError(\"Mode {} not supported, please use one of {}\".format(mode, valid_modes))\n",
    "\n",
    "    fan_in, fan_out = _calculate_fan_in_and_fan_out_for_vwl(tensor)\n",
    "    return fan_in if mode == 'fan_in' else fan_out\n",
    "\n",
    "\n",
    "def kaiming_uniform_for_vwl(tensor, a=0, mode='fan_in', nonlinearity='leaky_relu'):\n",
    "    \"\"\"\"\"\"\n",
    "    fan = _calculate_correct_fan_for_vwl(tensor, mode)\n",
    "    gain = nn.init.calculate_gain(nonlinearity, a)\n",
    "    std = gain / np.sqrt(fan)\n",
    "    bound = np.sqrt(3.0) * std  # Calculate uniform bounds from standard deviation\n",
    "    with torch.no_grad():\n",
    "        return tensor.uniform_(-bound, bound)\n",
    "class VectorWiseLinear(nn.Module):\n",
    "    \"\"\"\n",
    "    For mini batch which have several matrices,\n",
    "    see as these matrixes as bags of vectors, and multiply weight matrices by vector.\n",
    "    \n",
    "    input    X: (batch_size, **n_vectors**, in_features)\n",
    "    weight W: (**n_vector**, out_features, in_features)\n",
    "    output  Y: (batch_size, **n_vectors**, out_features)\n",
    "\n",
    "    **Note**: For simplicity, bias is not described.\n",
    "    \n",
    "    X and W are can be seen as below.\n",
    "    X: [\n",
    "            [vec_{ 1, 1}, vec_{ 1, 2}, ... vec_{ 1, n_vectors}],\n",
    "            [vec_{ 2, 1}, vec_{ 2, 2}, ... vec_{ 2, n_vectors}],\n",
    "                                            .\n",
    "                                            .\n",
    "            [vec_{bs, 1}, vec_{bs, 2}, ... vec_{bs, n_vectors}]\n",
    "        ]\n",
    "    W: [\n",
    "            Mat_{1}, Mat_{2}, ... , Mat_{n_vectors}\n",
    "        ]\n",
    "    Then Y is calclauted as:\n",
    "    Y: [\n",
    "        [ Mat_{1} vec_{ 1, 1}, Mat_{2} vec_{ 1, 2}, ... Mat_{n_vectors} vec_{ 1, n_vectors}],\n",
    "        [ Mat_{1} vec_{ 2, 1}, Mat_{2} vec_{ 2, 2}, ... Mat_{n_vectors} vec_{ 2, n_vectors}],\n",
    "        .\n",
    "        .\n",
    "        [ Mat_{1} vec_{bs, 1}, Mat_{2} vec_{bs, 2}, ... Mat_{n_vectors} vec_{bs, n_vectors}],\n",
    "    ]\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features: int, out_features: int, n_vectors: int,\n",
    "        bias: bool=True, weight_shared: bool=True\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize.\"\"\"\n",
    "        super(VectorWiseLinear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.n_vectors = n_vectors\n",
    "        self.weight_shared = weight_shared\n",
    "        \n",
    "        if self.weight_shared:\n",
    "            self.weight = nn.Parameter(\n",
    "                torch.Tensor(self.out_features, self.in_features)).to(device)\n",
    "            self.matmul_func = vector_wise_shared_matmul\n",
    "        else:\n",
    "            self.weight = nn.Parameter(\n",
    "                torch.Tensor(self.n_vectors, self.out_features, self.in_features))\n",
    "            self.matmul_func = vector_wise_matmul\n",
    "            \n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "            \n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self) -> None:\n",
    "        \"\"\"Initialize weight and bias.\"\"\"\n",
    "        kaiming_uniform_for_vwl(self.weight, a=np.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = _calculate_fan_in_and_fan_out_for_vwl(self.weight)\n",
    "            bound = 1 / np.sqrt(fan_in)\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "             \n",
    "    def forward(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward.\"\"\"\n",
    "        H = self.matmul_func(X, self.weight)\n",
    "        if self.bias is not None:\n",
    "            H = H + self.bias\n",
    "        \n",
    "        return H\n",
    "class GraphConv(nn.Module):\n",
    "    \"\"\"Basic Graph Convolution Layer.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        in_channels: int, out_channels: int, n_nodes: int, shrare_msg: bool=True,\n",
    "        model_self: bool=True, share_model_self: bool=True,\n",
    "        bias: bool=True, share_bias: bool=True\n",
    "    ) -> None:\n",
    "        \"\"\"Intialize.\"\"\"\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.n_nodes = n_nodes\n",
    "        self.model_self = model_self\n",
    "        super(GraphConv, self).__init__()\n",
    "        \n",
    "        # # message\n",
    "        self.msg = VectorWiseLinear(\n",
    "            in_channels, out_channels, n_nodes, False, shrare_msg)\n",
    "\n",
    "        # # self-modeling\n",
    "        if model_self:\n",
    "            self.model_self = VectorWiseLinear(\n",
    "                in_channels, out_channels, n_nodes, False, share_model_self)\n",
    "        \n",
    "        # # bias\n",
    "        if bias:\n",
    "            if share_bias:\n",
    "                self.bias = nn.Parameter(torch.Tensor(out_channels))\n",
    "            else:\n",
    "                self.bias = nn.Parameter(torch.Tensor(n_nodes, out_channels))\n",
    "            bound = 1 / np.sqrt(out_channels)\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "            \n",
    "    \n",
    "    def forward(self, X: torch.Tensor, A: torch.Tensor, W: torch.Tensor=None) -> torch.Tensor:\n",
    "        \"\"\"Forward.\n",
    "        \n",
    "        Args:\n",
    "            X: (batch_size, n_nodes, n_channels)\n",
    "                Array which represents bags of vectors.\n",
    "                X[:, i, :] are corresponded to feature vectors of node i.\n",
    "            A: (batch_size, n_nodes, n_nodes)\n",
    "                Array which represents adjacency matrices.\n",
    "                A[:, i, j] are corresponded to weights (scalar) of edges from node j to node i.\n",
    "            W: (batch_size, n_nodes, n_nodes)\n",
    "                Array which represents weight matrices between nodes.\n",
    "        \"\"\"\n",
    "        if W is not None:\n",
    "            A = A * W  # shape: (batch_size, n_nodes, n_nodes)\n",
    "        \n",
    "        # # update message\n",
    "        M = X  #  shape: (batch_size, n_nodes, in_channels)\n",
    "        # # # send message\n",
    "        M = self.msg(M)  # shape: (batch_size, n_nodes, out_channels)\n",
    "        # # # aggregate\n",
    "        M = torch.matmul(A, M)  # shape: (batch_size, n_nodes, out_channels)\n",
    "            \n",
    "        # # update node\n",
    "        # # # self-modeling\n",
    "        H = M\n",
    "        if self.model_self:\n",
    "            H = H + self.model_self(X)\n",
    "        if self.bias is not None:\n",
    "            H = H + self.bias\n",
    "        \n",
    "        return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dabebab9-8094-4afe-bc9c-93643134b92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    \"\"\"GCN for Stacking.\"\"\"\n",
    "    \n",
    "    # def __init__(\n",
    "    #     self, n_classes: int,\n",
    "    #     n_channels_list: tp.List[int],\n",
    "    #     add_self_loop: bool=False,\n",
    "    #     kwargs_head: tp.Dict={},\n",
    "    # ):\n",
    "    def __init__(self, num_features, num_targets, hidden_size, cfg):\n",
    "        self.model_name = \"GCN\"\n",
    "        n_classes = 1\n",
    "        n_channels_list =  [5, 16, 16, 16, 16, 16,16]#[8, 16, 16, 16, 16, 16, 16,]\n",
    "        add_self_loop = True\n",
    "        kwargs_head = {\n",
    "            \"n_features_list\": [-1, 768, 1],# [-1, 2048, 1]\n",
    "            \"use_tail_as_out\": True,\n",
    "            \"drop_rate\": 0.8,\n",
    "            \"use_bn\": False,\n",
    "            \"use_wn\": True,\n",
    "            \"block_name\": \"LABD\",\n",
    "        }\n",
    "        \n",
    "        \n",
    "        super().__init__()\n",
    "        self.n_conv_layers = len(n_channels_list) - 1\n",
    "        for i in range(self.n_conv_layers):\n",
    "            in_ch = n_channels_list[i]\n",
    "            out_ch = n_channels_list[i + 1]\n",
    "            # layer = CustomGraphConv(in_ch, out_ch, n_classes)\n",
    "            layer = GraphConv(\n",
    "                in_ch, out_ch, n_classes,\n",
    "                shrare_msg=False, share_model_self=False, share_bias=False)\n",
    "            setattr(self, \"conv{}\".format(i + 1), layer)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        if add_self_loop:\n",
    "            adj_mat = torch.ones(n_classes, n_classes) / n_classes\n",
    "        else:\n",
    "            adj_mat = (1 - torch.eye(n_classes, n_classes)) / (n_classes - 1) \n",
    "        self.register_buffer(\"A\", adj_mat.float())\n",
    "               \n",
    "        kwargs_head[\"n_features_list\"][0] = n_classes * n_channels_list[-1]\n",
    "        self.head = MLP(**kwargs_head)\n",
    "    \n",
    "    def forward(self, X: torch.FloatTensor) -> torch.Tensor:\n",
    "        \"\"\"\"\"\"\n",
    "        X = X.unsqueeze(1)\n",
    "        bs, n_classes = X.shape[:2]\n",
    "        H = X  # shape: (bs, n_classes, n_models)\n",
    "        for i in range(self.n_conv_layers):\n",
    "            H = getattr(self, \"conv{}\".format(i + 1))(H, self.A[None, ...])\n",
    "            H = self.relu(H)\n",
    "        \n",
    "        h = torch.reshape(H, (bs, -1))\n",
    "        h = self.head(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352231bb-0147-4d21-844a-9ae3e5cad093",
   "metadata": {},
   "source": [
    "# TabNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a468545-191c-47e5-9aae-6ade479108ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-tabnet in /opt/conda/lib/python3.7/site-packages (3.1.1)\n",
      "Requirement already satisfied: scikit_learn>0.21 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (1.0.2)\n",
      "Requirement already satisfied: scipy>1.4 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (1.7.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (1.21.5)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.36 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (4.63.0)\n",
      "Requirement already satisfied: torch<2.0,>=1.2 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (1.9.0+cu111)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit_learn>0.21->pytorch-tabnet) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit_learn>0.21->pytorch-tabnet) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch<2.0,>=1.2->pytorch-tabnet) (4.1.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "df1869f9-fb73-4205-b8ef-72394b2298aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetClassifier, TabNetRegressor\n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "# from pytorch_tabnet.augmentations import RegressionSMOTE\n",
    "\n",
    "def train_tabnet(X_train, y_train, X_valid, y_valid, MODEL, save_dir, fold_num, seed, max_epochs=200):\n",
    "    print(\"start unsupervised fitting\")\n",
    "    unsupervised_model = TabNetPretrainer(\n",
    "        optimizer_fn=torch.optim.Adam,\n",
    "        optimizer_params=dict(lr=2e-2),\n",
    "        mask_type='entmax', # \"sparsemax\",\n",
    "        verbose=10,\n",
    "        device_name=\"cuda\"\n",
    "        # n_shared_decoder=1, # nb shared glu for decoding\n",
    "        # n_indep_decoder=1, # nb independent glu for decoding\n",
    "    )\n",
    "    unsupervised_model.fit(\n",
    "        X_train=X_train,\n",
    "        eval_set=[X_valid],\n",
    "        max_epochs=max_epochs , patience=5,\n",
    "        batch_size=2048, virtual_batch_size=128,\n",
    "        num_workers=0,\n",
    "        drop_last=False,\n",
    "        pretraining_ratio=0.8,\n",
    "    )\n",
    "    unsupervised_model_path =  f\"{save_dir}unsupervised_fold{fold_num}_seed{seed}\"\n",
    "    unsupervised_model.save_model(unsupervised_model_path)\n",
    "    # loaded_pretrain = TabNetPretrainer()\n",
    "    # loaded_pretrain.load_model('./test_pretrain.zip')\n",
    "    \n",
    "    model = MODEL(optimizer_fn=torch.optim.Adam,\n",
    "                       optimizer_params=dict(lr=2e-2),\n",
    "                       scheduler_params={\"step_size\":10, # how to use learning rate scheduler\n",
    "                                         \"gamma\":0.9,\n",
    "                                        },\n",
    "                     scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "                    \n",
    "                  # scheduler_params=dict(mode=\"min\",\n",
    "                  #                          patience=5,\n",
    "                  #                          min_lr=1e-5,\n",
    "                  #                          factor=0.9,),\n",
    "                  #   scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "\n",
    "                    verbose=10,\n",
    "                  device_name=\"cuda\"\n",
    "\n",
    "                      )\n",
    "    print(\"end unsupervised fitting\")\n",
    "    print(\"start model fitting\")\n",
    "    # aug = RegressionSMOTE(p=0.2)\n",
    "\n",
    "    model.fit(\n",
    "        X_train=X_train, y_train=y_train,\n",
    "        eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "        eval_name=['train', 'valid'],\n",
    "        eval_metric=['rmsle', 'mae', 'rmse', 'mse'],\n",
    "        max_epochs=max_epochs,\n",
    "        patience=50,\n",
    "        batch_size=1024, virtual_batch_size=128,\n",
    "        num_workers=0,\n",
    "        drop_last=False,\n",
    "        # augmentations=aug, #aug\n",
    "        from_unsupervised=unsupervised_model,\n",
    "    )\n",
    "    model_path =  f\"{save_dir}tabnet_fold{fold_num}_seed{seed}\"\n",
    "    print(model.save_model(model_path))\n",
    "    \n",
    "    print(\"end model fitting\")\n",
    "    return model\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1a282706-8068-44b2-af98-20b4c2f77132",
   "metadata": {},
   "outputs": [],
   "source": [
    "class oneDCNNCFG:\n",
    "    max_grad_norm=1000\n",
    "    gradient_accumulation_steps=1\n",
    "    hidden_size=256\n",
    "    dropout=0.3\n",
    "    lr=1e-4\n",
    "    batch_size=128\n",
    "    epochs=50\n",
    "    weight_decay=1e-5\n",
    "    n_fold = 5\n",
    "    \n",
    "    features = oof_dfs.columns[:-1]\n",
    "   \n",
    "\n",
    "    \n",
    "train =  pd.read_csv(INPUT_DIR+'train.csv')\n",
    "# train['score_map'] = train['score'].map({0.00: 0, 0.25: 1, 0.50: 2, 0.75: 3, 1.00: 4})\n",
    "# Fold = StratifiedKFold(n_splits=oneDCNNCFG.n_fold, shuffle=True, random_state=CFG.seed)\n",
    "# for n, (train_index, val_index) in enumerate(Fold.split(train, train['score_map'])):\n",
    "#     train.loc[val_index, 'fold'] = int(n)\n",
    "# train['fold'] = train['fold'].astype(int)\n",
    "# folds = train\n",
    "# display(train.groupby('fold').size())\n",
    "\n",
    "# train = train.merge(oof_dfs ,on=\"id\")#\n",
    "# target = train[\"score\"]\n",
    "# train = train[oof_dfs.columns[:-1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "85e291ea-73b4-4c1e-8978-a8338a0b5c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folds(data, num_splits):\n",
    "    # we create a new column called kfold and fill it with -1\n",
    "    data[\"fold\"] = -1\n",
    "    \n",
    "    # the next step is to randomize the rows of the data\n",
    "    data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # calculate number of bins by Sturge's rule\n",
    "    # I take the floor of the value, you can also\n",
    "    # just round it\n",
    "    num_bins = int(np.floor(1 + np.log2(len(data))))\n",
    "    \n",
    "    # bin targets\n",
    "    data.loc[:, \"bins\"] = pd.cut(\n",
    "        data[\"score\"], bins=num_bins, labels=False\n",
    "    )\n",
    "    \n",
    "    # initiate the kfold class from model_selection module\n",
    "    kf = model_selection.StratifiedKFold(n_splits=num_splits, shuffle=True, random_state=42)\n",
    "    # kf = model_selection.StratifiedGroupKFold(n_splits=num_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # fill the new kfold column\n",
    "    # note that, instead of targets, we use bins!\n",
    "    for f, (t_, v_) in enumerate(kf.split(X=data, y=data.bins.values)):\n",
    "        data.loc[v_, 'fold'] = f\n",
    "    \n",
    "    # drop the bins column\n",
    "    data = data.drop(\"bins\", axis=1)\n",
    "\n",
    "    # return dataframe with folds\n",
    "    return data\n",
    "\n",
    "\n",
    "folds = create_folds(train, oneDCNNCFG.n_fold)\n",
    "target = train[\"score\"]\n",
    "train = train.merge(oof_dfs, on=\"id\")[oof_dfs.columns[:-1]]\n",
    "# train\n",
    "# display(oof_dfs.head())\n",
    "# display(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc13526-8abc-4e76-9b00-884abd3f4380",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40df3c3-cd13-401e-8470-29a19a0c2d18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "024d7b5d-8058-4e76-8f24-b7b9c814a2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7897f034-f5e2-49d6-a42f-7653d9f90aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_stack(train_loader, model, optimizer, epoch, scheduler, device,CFG):\n",
    "    \n",
    "    losses = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for step, (x, y) in enumerate(train_loader):\n",
    "        x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "        batch_size = x.size(0)\n",
    "        pred = model(x)\n",
    "        loss = nn.BCEWithLogitsLoss()(pred, y.unsqueeze(1))\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "\n",
    "        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "            scheduler.step()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "    return losses.avg\n",
    "\n",
    "\n",
    "def valid_stack(valid_loader, model, device, CFG):\n",
    "    \n",
    "    losses = AverageMeter()\n",
    "\n",
    "    model.eval()\n",
    "    val_preds = []\n",
    "    y_true =[]\n",
    "    for step, (x, y) in enumerate(valid_loader):\n",
    "        \n",
    "        x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = model(x)\n",
    "            \n",
    "        loss = nn.BCEWithLogitsLoss()(pred, y.unsqueeze(1))\n",
    "        losses.update(loss.item(), batch_size)\n",
    "\n",
    "        # print(sum(pred))\n",
    "        val_preds.append(pred.sigmoid().detach().cpu().numpy())\n",
    "        y_true.append(y.detach().cpu().numpy())\n",
    "#         val_preds.append(pred.tanh().detach().cpu().numpy())\n",
    "\n",
    "        if CFG.gradient_accumulation_steps> 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "    val_preds = np.concatenate(val_preds)\n",
    "    y_true= np.concatenate(y_true)\n",
    "    try:\n",
    "        score = get_score(y_true, val_preds.reshape(-1,))\n",
    "    except:\n",
    "        score = None\n",
    "    return losses.avg, val_preds, score\n",
    "\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "febc9e84-6d41-4fad-ae17-22df7a19f748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_nn(cfg, train, folds, features, target, device, fold_num, seed, MODEL,save_dir,):\n",
    "    seed_everything(seed=seed)\n",
    "    trn_idx = folds[folds[\"fold\"]!=fold_num].index\n",
    "    val_idx = folds[folds[\"fold\"]==fold_num].index\n",
    "    \n",
    "    train_target = target[trn_idx]\n",
    "    valid_target = target[val_idx]\n",
    "    \n",
    "    train_folds = train.loc[trn_idx].reset_index(drop=True)\n",
    "    valid_folds = train.loc[val_idx].reset_index(drop=True)\n",
    "    \n",
    "    # s = QuantileTransformer(n_quantiles=50, random_state=seed, output_distribution=\"normal\")\n",
    "    # train_folds[features] = s.fit_transform(train_folds[features])\n",
    "    # valid_folds[features] = s.transform(valid_folds[features])\n",
    "    if cfg.like_sklearn:\n",
    "       \n",
    "        model = train_tabnet(train_folds.values, train_target.values.reshape(-1,1), valid_folds.values, valid_target.values.reshape(-1,1), MODEL, save_dir, fold_num, seed,)\n",
    "        tra_pred = model.predict(train_folds.values)\n",
    "        val_pred = model.predict(valid_folds.values)\n",
    "        oof = np.zeros((len(train), 1))\n",
    "        oof[val_idx] = val_pred\n",
    "        \n",
    "        tra_score = get_score(train_target.values, tra_pred)\n",
    "        val_score = get_score(valid_target.values, val_pred)\n",
    "        LOGGER.info(f\"train[{tra_score}], val[{val_score}]\")\n",
    "        # save tabnet model\n",
    "        \n",
    "        # # define new model with basic parameters and load state dict weights\n",
    "        # loaded_clf = TabNetClassifier()\n",
    "        # loaded_clf.load_model(saved_filepath)\n",
    "    else:\n",
    "        model = MODEL(\n",
    "                num_features=len(cfg.features), num_targets=1, hidden_size=cfg.hidden_size, cfg=cfg\n",
    "        )\n",
    "        model.to(device)#, non_blocking=True)\n",
    "\n",
    "        train_dataset = StackingDataset(train_folds, features, train_target, model_name=model.model_name)\n",
    "        valid_dataset = StackingDataset(valid_folds, features, valid_target, model_name=model.model_name)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=cfg.batch_size, shuffle=True, \n",
    "                                  num_workers=4, pin_memory=False, drop_last=True)\n",
    "        valid_loader = DataLoader(valid_dataset, batch_size=cfg.batch_size, shuffle=False, \n",
    "                                  num_workers=4, pin_memory=False, drop_last=False)\n",
    "\n",
    "\n",
    "        optimizer = optim.Adam(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
    "        scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n",
    "                                                  max_lr=1e-2, epochs=cfg.epochs, steps_per_epoch=len(train_loader))\n",
    "\n",
    "        # train & validate\n",
    "        best_score = -np.inf\n",
    "        improve_count = 0\n",
    "        for epoch in range(cfg.epochs):\n",
    "            train_loss = train_stack(train_loader, model, optimizer, epoch, scheduler, device, cfg)\n",
    "            valid_loss, val_pred, score = valid_stack(valid_loader, model, device, cfg)\n",
    "            if score is None:\n",
    "                break\n",
    "            if score>best_score:\n",
    "                LOGGER.info(f\"epoch [{epoch}] update {best_score} to {score}\")\n",
    "                best_score = score\n",
    "                oof = np.zeros((len(train), 1))\n",
    "                oof[val_idx] = val_pred\n",
    "                torch.save(model.state_dict(),f\"{save_dir}{model.model_name}_fold{fold_num}_seed{seed}.pth\")\n",
    "                improve_count=0\n",
    "            else:\n",
    "                print(f\"not improve {score}\")\n",
    "                improve_count+=1\n",
    "\n",
    "            if improve_count>10:\n",
    "                break\n",
    "    return oof\n",
    "def run_kfold_nn(cfg, train, folds, features, target, device, n_fold, seed,MODEL, save_dir,):\n",
    "    print(\"run kfold nn\")\n",
    "    oof = np.zeros((len(train), 1))\n",
    "    for fold_num in range(n_fold):\n",
    "        LOGGER.info(f\"fold {fold_num}\")\n",
    "        _oof = run_single_nn(cfg, train, folds, features, target, device, fold_num, seed, MODEL,save_dir,)\n",
    "        oof += _oof\n",
    "    score = get_score(target.values, oof)\n",
    "    LOGGER.info(\"=\"*10)\n",
    "    LOGGER.info(f\"oof score {score}\")\n",
    "    return oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "214c1b18-7b9d-44cf-9ac8-7d174de32fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "like_sklearn = False\n",
    "if \"1dcnn\" in stacking_exp_name:\n",
    "    stacking_model = oneDCNN\n",
    "elif \"2dcnn\" in stacking_exp_name:\n",
    "    stacking_model = twoDCNN\n",
    "elif \"mlp\" in stacking_exp_name:\n",
    "    stacking_model = StackingMLP\n",
    "elif \"gcn\" in stacking_exp_name:# \n",
    "    device = torch.device(\"cpu\")\n",
    "    stacking_model = GCN\n",
    "elif \"tabnet\" in stacking_exp_name:\n",
    "    stacking_model = TabNetRegressor\n",
    "    like_sklearn = True#学習をmodel.fitで行う\n",
    "    \n",
    "oneDCNNCFG.like_sklearn = like_sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcc511b-1155-4996-a249-3582409b4ae6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "set seed 42\n",
      "fold 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run kfold nn\n",
      "start unsupervised fitting\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 4.95063 | val_0_unsup_loss: 1.72963 |  0:00:05s\n",
      "epoch 10 | loss: 0.47164 | val_0_unsup_loss: 0.91527 |  0:00:13s\n",
      "epoch 20 | loss: 0.46692 | val_0_unsup_loss: 0.38222 |  0:00:20s\n",
      "epoch 30 | loss: 0.45665 | val_0_unsup_loss: 0.14806 |  0:00:27s\n",
      "\n",
      "Early stopping occurred at epoch 39 with best_epoch = 34 and best_val_0_unsup_loss = 0.10561\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at ./output/5model_stacking/tabnet//unsupervised_fold0_seed42.zip\n",
      "Device used : cuda\n",
      "end unsupervised fitting\n",
      "start model fitting\n",
      "Loading weights from unsupervised pretraining\n",
      "epoch 0  | loss: 0.08418 | train_rmsle: 0.05139 | train_mae: 0.29883 | train_rmse: 0.39043 | train_mse: 0.15243 | valid_rmsle: 0.05323 | valid_mae: 0.30575 | valid_rmse: 0.39873 | valid_mse: 0.15899 |  0:00:01s\n",
      "epoch 10 | loss: 0.01741 | train_rmsle: 0.00926 | train_mae: 0.08588 | train_rmse: 0.12839 | train_mse: 0.01648 | valid_rmsle: 0.00947 | valid_mae: 0.08669 | valid_rmse: 0.13047 | valid_mse: 0.01702 |  0:00:12s\n",
      "epoch 20 | loss: 0.01681 | train_rmsle: 0.00894 | train_mae: 0.08566 | train_rmse: 0.12666 | train_mse: 0.01604 | valid_rmsle: 0.00921 | valid_mae: 0.08662 | valid_rmse: 0.12906 | valid_mse: 0.01666 |  0:00:24s\n",
      "epoch 30 | loss: 0.01665 | train_rmsle: 0.00885 | train_mae: 0.08299 | train_rmse: 0.12629 | train_mse: 0.01595 | valid_rmsle: 0.00907 | valid_mae: 0.08363 | valid_rmse: 0.12837 | valid_mse: 0.01648 |  0:00:36s\n",
      "epoch 40 | loss: 0.01646 | train_rmsle: 0.00896 | train_mae: 0.08319 | train_rmse: 0.12659 | train_mse: 0.01603 | valid_rmsle: 0.00923 | valid_mae: 0.08402 | valid_rmse: 0.12898 | valid_mse: 0.01663 |  0:00:47s\n"
     ]
    }
   ],
   "source": [
    "oof = np.zeros((len(train), 1))\n",
    "SEED = [42, 1999, 2022]\n",
    "\n",
    "for i, seed in enumerate(SEED):\n",
    "    LOGGER.info(f\"set seed {seed}\")\n",
    "    _oof = run_kfold_nn(oneDCNNCFG, train, folds, oneDCNNCFG.features, target, device,\n",
    "                        n_fold=oneDCNNCFG.n_fold, seed=seed,MODEL=stacking_model, save_dir=OUTPUT_DIR,\n",
    "                       )\n",
    "    oof += _oof/len(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f1bd9e-9256-4b0a-92dd-247c3d45ed91",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"score\"] = oof\n",
    "\n",
    "train.to_csv(f\"{OUTPUT_DIR}oof_df.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c77a4e0b",
   "metadata": {
    "papermill": {
     "duration": 0.034772,
     "end_time": "2022-04-25T02:04:53.110111",
     "exception": false,
     "start_time": "2022-04-25T02:04:53.075339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8708905335770041"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_score(target.values, oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c88953-079b-43e3-afb9-9d203da5ab1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f16bb9-cd02-41d9-847c-e4dae61f47ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# array([0.8718436039273738], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1a76e5-fef7-4d64-a8d7-5d727b9302f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!touch trained_list/stacking.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8df5e3a-f636-4283-a087-f29b5e2715fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc5a6cb-28e9-446d-9abd-31d4b1dde597",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 167.448867,
   "end_time": "2022-04-25T02:04:56.616136",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-25T02:02:09.167269",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "00ed04aedf6f4635bafcc3ecf63b5453": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "06704fce9b104c83be0c4d9dcc14253d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7af07d8ad39f409c80781095cff15a23",
       "max": 2,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_8966fc685abe40cb93332a83ec0ebf0e",
       "value": 2
      }
     },
     "090d940514d34c8aa9246c3f62be1874": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0e7bfa3c36d84115bd968902f95f47b1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "11440f4fa3cd41c3a6dd76229484ef9f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "152a216e8092498c839953a970ea1ac9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3a148dec85c743739bca06eaad740d9a",
       "placeholder": "​",
       "style": "IPY_MODEL_0e7bfa3c36d84115bd968902f95f47b1",
       "value": "100%"
      }
     },
     "1dbd0d59e4c7462d994fd5fb42769b92": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1dd5730f38f04241aa75050ade94dccb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_11440f4fa3cd41c3a6dd76229484ef9f",
       "placeholder": "​",
       "style": "IPY_MODEL_00ed04aedf6f4635bafcc3ecf63b5453",
       "value": "100%"
      }
     },
     "2585d7b40e83478e9c7ede2e9ff433b4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "25e986904e8646179a28a643f662e1b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "307a152a6e1f48288197ee8ab54e8d96": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9be4cf7a883245a29d84a4dc6b73438d",
       "placeholder": "​",
       "style": "IPY_MODEL_63c2c1c8130544739bd49bb52fa1bb45",
       "value": " 2/2 [00:01&lt;00:00,  1.11it/s]"
      }
     },
     "3876d875bb1f4f1ab830159475f97746": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2585d7b40e83478e9c7ede2e9ff433b4",
       "max": 2,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_76bf6b030110461da76d39919f487b86",
       "value": 2
      }
     },
     "3a148dec85c743739bca06eaad740d9a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3b068bb9eda24d62991332b3a8861aa6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3e4860070cfc40679fad11dc41008f1e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6db019c6e4214dfb81ca8264956b8882",
        "IPY_MODEL_3876d875bb1f4f1ab830159475f97746",
        "IPY_MODEL_307a152a6e1f48288197ee8ab54e8d96"
       ],
       "layout": "IPY_MODEL_090d940514d34c8aa9246c3f62be1874"
      }
     },
     "4bc4c2fa917443b7b9c0a7a1a0a607ad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1dd5730f38f04241aa75050ade94dccb",
        "IPY_MODEL_7bbcdaae15a24c5bba6abbabefafd97d",
        "IPY_MODEL_fa9543f6fa7f439f9b9ded5af71cf103"
       ],
       "layout": "IPY_MODEL_ae6eb523ef2b4ec0a9e25c7dc52faad7"
      }
     },
     "537f816d39c34b1bb4091336be12d45e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "54c7532b2945407fb9bf00ef87b6be5e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "63c2c1c8130544739bd49bb52fa1bb45": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "6478a2b82b424ad3ae34d13af4dc7b65": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "656b0b2b7aee443b9d35092f71c71cd9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_bb3779b43cf54e27ab6b3300f439fec8",
       "max": 2,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_54c7532b2945407fb9bf00ef87b6be5e",
       "value": 2
      }
     },
     "698993eed8a24f04b9886c7e7eac7771": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d36030275f624a98b2e80aac60d3386a",
       "placeholder": "​",
       "style": "IPY_MODEL_25e986904e8646179a28a643f662e1b0",
       "value": " 2/2 [00:01&lt;00:00,  1.04it/s]"
      }
     },
     "6db019c6e4214dfb81ca8264956b8882": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a5a7fdce793247c29e23d33572236d69",
       "placeholder": "​",
       "style": "IPY_MODEL_1dbd0d59e4c7462d994fd5fb42769b92",
       "value": "100%"
      }
     },
     "6eed889d136f4f4c82a507139ce3e8a8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "76bf6b030110461da76d39919f487b86": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7af07d8ad39f409c80781095cff15a23": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7bbcdaae15a24c5bba6abbabefafd97d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_537f816d39c34b1bb4091336be12d45e",
       "max": 2,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_dfc9fa0446e240db9bac1d43093a06d8",
       "value": 2
      }
     },
     "8966fc685abe40cb93332a83ec0ebf0e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "8b301a2b9ff84b05a588fea0ca0ebbce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_152a216e8092498c839953a970ea1ac9",
        "IPY_MODEL_656b0b2b7aee443b9d35092f71c71cd9",
        "IPY_MODEL_698993eed8a24f04b9886c7e7eac7771"
       ],
       "layout": "IPY_MODEL_6eed889d136f4f4c82a507139ce3e8a8"
      }
     },
     "9663ba1f888d41f78603c231cd38b8a0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3b068bb9eda24d62991332b3a8861aa6",
       "placeholder": "​",
       "style": "IPY_MODEL_e3eb538dddb54bb983288bd738a98a36",
       "value": " 2/2 [00:01&lt;00:00,  1.04it/s]"
      }
     },
     "9a546834df8c4a078475275908aefd1b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e8a991afabe44ea1835dbbd66ada9b10",
       "placeholder": "​",
       "style": "IPY_MODEL_cc8e422cd9d94152aef3394c99aedaf5",
       "value": "100%"
      }
     },
     "9be4cf7a883245a29d84a4dc6b73438d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a5a7fdce793247c29e23d33572236d69": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "adcd99378d10497b91caae7bd8d7835e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9a546834df8c4a078475275908aefd1b",
        "IPY_MODEL_06704fce9b104c83be0c4d9dcc14253d",
        "IPY_MODEL_9663ba1f888d41f78603c231cd38b8a0"
       ],
       "layout": "IPY_MODEL_d594ea0d03b24c2ba27423f6a929e95d"
      }
     },
     "ae6eb523ef2b4ec0a9e25c7dc52faad7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bb3779b43cf54e27ab6b3300f439fec8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cc8e422cd9d94152aef3394c99aedaf5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d36030275f624a98b2e80aac60d3386a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d594ea0d03b24c2ba27423f6a929e95d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dfc9fa0446e240db9bac1d43093a06d8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e3eb538dddb54bb983288bd738a98a36": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e8a991afabe44ea1835dbbd66ada9b10": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fa9543f6fa7f439f9b9ded5af71cf103": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fbfd259a6eb34db0bc022a4026fef22b",
       "placeholder": "​",
       "style": "IPY_MODEL_6478a2b82b424ad3ae34d13af4dc7b65",
       "value": " 2/2 [00:01&lt;00:00,  1.66s/it]"
      }
     },
     "fbfd259a6eb34db0bc022a4026fef22b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
